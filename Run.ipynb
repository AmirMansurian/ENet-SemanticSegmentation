{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemanticSegmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Segmentation"
      ],
      "metadata": {
        "id": "7i-6SZAXHEiM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements"
      ],
      "metadata": {
        "id": "J5hdyjORHIzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/Enet/\n",
        "!ls\n",
        "\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8emTfBE-WhL9",
        "outputId": "9333efbf-714e-4ebb-a706-a2eb1fe01454"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Enet\n",
            "args.py  Dockerfile  metric\t  README.md\t\tsave\t  transforms.py\n",
            "CamVid2  LICENSE     models\t  requirements_dev.txt\ttest.py   utils.py\n",
            "data\t main.py     __pycache__  requirements.txt\ttrain.py\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.21.6)\n",
            "Requirement already satisfied: Pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (3.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.7.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (2022.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.15.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->-r requirements.txt (line 2)) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.2.2->-r requirements.txt (line 11)) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->-r requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->-r requirements.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->-r requirements.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->-r requirements.txt (line 11)) (2021.10.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# E net with 300 epoches"
      ],
      "metadata": {
        "id": "RrAlVbzOHK_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py -m train --save-dir save/ENet_CamVid/ --dataset camvid --dataset-dir ../CamVid2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiAhRS4Obg1_",
        "outputId": "9947eb5a-fd7e-4555-c877-79362cf53ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: ../CamVid2/\n",
            "Save directory: save/ENet_CamVid/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 360, 480])\n",
            "Label size: torch.Size([10, 360, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0217,  3.4469, 15.9119,  9.0202, 32.0138, 32.4789,\n",
            "        13.2071, 38.3877, 44.1345,  0.0000], device='cuda:0')\n",
            "\n",
            "Training...\n",
            "\n",
            "ENet(\n",
            "  (initial_block): InitialBlock(\n",
            "    (main_branch): Conv2d(3, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (ext_branch): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (downsample1_0): DownsamplingBottleneck(\n",
            "    (main_max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(16, 4, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (downsample2_0): DownsamplingBottleneck(\n",
            "    (main_max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular2_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric2_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular2_5): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_6): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric2_7): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_8): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular3_0): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric3_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular3_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_5): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric3_6): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_7): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (upsample4_0): UpsamplingBottleneck(\n",
            "    (main_conv1): Sequential(\n",
            "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (main_unpool1): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_tconv1): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "    (ext_tconv1_bnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (ext_tconv1_activation): ReLU()\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular4_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular4_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (upsample5_0): UpsamplingBottleneck(\n",
            "    (main_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (main_unpool1): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_tconv1): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "    (ext_tconv1_bnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (ext_tconv1_activation): ReLU()\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular5_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (transposed_conv): ConvTranspose2d(16, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            ")\n",
            "\n",
            ">>>> [Epoch: 0] Training\n",
            ">>>> [Epoch: 0] Avg. loss: 2.3403 | Mean IoU: 0.0681\n",
            ">>>> [Epoch: 1] Training\n",
            ">>>> [Epoch: 1] Avg. loss: 1.9978 | Mean IoU: 0.1453\n",
            ">>>> [Epoch: 2] Training\n",
            ">>>> [Epoch: 2] Avg. loss: 1.6976 | Mean IoU: 0.2308\n",
            ">>>> [Epoch: 3] Training\n",
            ">>>> [Epoch: 3] Avg. loss: 1.4954 | Mean IoU: 0.2831\n",
            ">>>> [Epoch: 4] Training\n",
            ">>>> [Epoch: 4] Avg. loss: 1.3579 | Mean IoU: 0.3102\n",
            ">>>> [Epoch: 5] Training\n",
            ">>>> [Epoch: 5] Avg. loss: 1.2677 | Mean IoU: 0.3251\n",
            ">>>> [Epoch: 6] Training\n",
            ">>>> [Epoch: 6] Avg. loss: 1.2130 | Mean IoU: 0.3330\n",
            ">>>> [Epoch: 7] Training\n",
            ">>>> [Epoch: 7] Avg. loss: 1.1206 | Mean IoU: 0.3491\n",
            ">>>> [Epoch: 8] Training\n",
            ">>>> [Epoch: 8] Avg. loss: 1.0585 | Mean IoU: 0.3645\n",
            ">>>> [Epoch: 9] Training\n",
            ">>>> [Epoch: 9] Avg. loss: 1.0086 | Mean IoU: 0.3762\n",
            ">>>> [Epoch: 9] Validation\n",
            ">>>> [Epoch: 9] Avg. loss: 1.1697 | Mean IoU: 0.4079\n",
            "sky: 0.9259\n",
            "building: 0.7295\n",
            "pole: 0.0026\n",
            "road: 0.9054\n",
            "pavement: 0.6537\n",
            "tree: 0.8221\n",
            "sign_symbol: 0.0023\n",
            "fence: 0.1932\n",
            "car: 0.2450\n",
            "pedestrian: 0.0072\n",
            "bicyclist: 0.0000\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 10] Training\n",
            ">>>> [Epoch: 10] Avg. loss: 0.9612 | Mean IoU: 0.3889\n",
            ">>>> [Epoch: 11] Training\n",
            ">>>> [Epoch: 11] Avg. loss: 0.9291 | Mean IoU: 0.3996\n",
            ">>>> [Epoch: 12] Training\n",
            ">>>> [Epoch: 12] Avg. loss: 0.9014 | Mean IoU: 0.4060\n",
            ">>>> [Epoch: 13] Training\n",
            ">>>> [Epoch: 13] Avg. loss: 0.8638 | Mean IoU: 0.4172\n",
            ">>>> [Epoch: 14] Training\n",
            ">>>> [Epoch: 14] Avg. loss: 0.8295 | Mean IoU: 0.4283\n",
            ">>>> [Epoch: 15] Training\n",
            ">>>> [Epoch: 15] Avg. loss: 0.7930 | Mean IoU: 0.4415\n",
            ">>>> [Epoch: 16] Training\n",
            ">>>> [Epoch: 16] Avg. loss: 0.7727 | Mean IoU: 0.4444\n",
            ">>>> [Epoch: 17] Training\n",
            ">>>> [Epoch: 17] Avg. loss: 0.7507 | Mean IoU: 0.4513\n",
            ">>>> [Epoch: 18] Training\n",
            ">>>> [Epoch: 18] Avg. loss: 0.7321 | Mean IoU: 0.4577\n",
            ">>>> [Epoch: 19] Training\n",
            ">>>> [Epoch: 19] Avg. loss: 0.7031 | Mean IoU: 0.4711\n",
            ">>>> [Epoch: 19] Validation\n",
            ">>>> [Epoch: 19] Avg. loss: 0.7600 | Mean IoU: 0.4732\n",
            "sky: 0.9349\n",
            "building: 0.7226\n",
            "pole: 0.0004\n",
            "road: 0.9345\n",
            "pavement: 0.7635\n",
            "tree: 0.8785\n",
            "sign_symbol: 0.0729\n",
            "fence: 0.2789\n",
            "car: 0.5655\n",
            "pedestrian: 0.0533\n",
            "bicyclist: 0.0002\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 20] Training\n",
            ">>>> [Epoch: 20] Avg. loss: 0.6926 | Mean IoU: 0.4709\n",
            ">>>> [Epoch: 21] Training\n",
            ">>>> [Epoch: 21] Avg. loss: 0.6771 | Mean IoU: 0.4782\n",
            ">>>> [Epoch: 22] Training\n",
            ">>>> [Epoch: 22] Avg. loss: 0.6690 | Mean IoU: 0.4819\n",
            ">>>> [Epoch: 23] Training\n",
            ">>>> [Epoch: 23] Avg. loss: 0.6466 | Mean IoU: 0.4961\n",
            ">>>> [Epoch: 24] Training\n",
            ">>>> [Epoch: 24] Avg. loss: 0.6173 | Mean IoU: 0.5075\n",
            ">>>> [Epoch: 25] Training\n",
            ">>>> [Epoch: 25] Avg. loss: 0.6192 | Mean IoU: 0.5062\n",
            ">>>> [Epoch: 26] Training\n",
            ">>>> [Epoch: 26] Avg. loss: 0.5875 | Mean IoU: 0.5240\n",
            ">>>> [Epoch: 27] Training\n",
            ">>>> [Epoch: 27] Avg. loss: 0.5804 | Mean IoU: 0.5264\n",
            ">>>> [Epoch: 28] Training\n",
            ">>>> [Epoch: 28] Avg. loss: 0.5675 | Mean IoU: 0.5347\n",
            ">>>> [Epoch: 29] Training\n",
            ">>>> [Epoch: 29] Avg. loss: 0.5414 | Mean IoU: 0.5457\n",
            ">>>> [Epoch: 29] Validation\n",
            ">>>> [Epoch: 29] Avg. loss: 0.6426 | Mean IoU: 0.5316\n",
            "sky: 0.9245\n",
            "building: 0.7566\n",
            "pole: 0.0358\n",
            "road: 0.9459\n",
            "pavement: 0.7334\n",
            "tree: 0.8746\n",
            "sign_symbol: 0.2082\n",
            "fence: 0.5358\n",
            "car: 0.6899\n",
            "pedestrian: 0.1309\n",
            "bicyclist: 0.0120\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 30] Training\n",
            ">>>> [Epoch: 30] Avg. loss: 0.5360 | Mean IoU: 0.5498\n",
            ">>>> [Epoch: 31] Training\n",
            ">>>> [Epoch: 31] Avg. loss: 0.5315 | Mean IoU: 0.5497\n",
            ">>>> [Epoch: 32] Training\n",
            ">>>> [Epoch: 32] Avg. loss: 0.5125 | Mean IoU: 0.5582\n",
            ">>>> [Epoch: 33] Training\n",
            ">>>> [Epoch: 33] Avg. loss: 0.5219 | Mean IoU: 0.5546\n",
            ">>>> [Epoch: 34] Training\n",
            ">>>> [Epoch: 34] Avg. loss: 0.5035 | Mean IoU: 0.5614\n",
            ">>>> [Epoch: 35] Training\n",
            ">>>> [Epoch: 35] Avg. loss: 0.4863 | Mean IoU: 0.5717\n",
            ">>>> [Epoch: 36] Training\n",
            ">>>> [Epoch: 36] Avg. loss: 0.4663 | Mean IoU: 0.5812\n",
            ">>>> [Epoch: 37] Training\n",
            ">>>> [Epoch: 37] Avg. loss: 0.4702 | Mean IoU: 0.5796\n",
            ">>>> [Epoch: 38] Training\n",
            ">>>> [Epoch: 38] Avg. loss: 0.4587 | Mean IoU: 0.5814\n",
            ">>>> [Epoch: 39] Training\n",
            ">>>> [Epoch: 39] Avg. loss: 0.4547 | Mean IoU: 0.5887\n",
            ">>>> [Epoch: 39] Validation\n",
            ">>>> [Epoch: 39] Avg. loss: 0.5235 | Mean IoU: 0.5536\n",
            "sky: 0.9275\n",
            "building: 0.7590\n",
            "pole: 0.0454\n",
            "road: 0.9487\n",
            "pavement: 0.7974\n",
            "tree: 0.8840\n",
            "sign_symbol: 0.2368\n",
            "fence: 0.6325\n",
            "car: 0.6713\n",
            "pedestrian: 0.1361\n",
            "bicyclist: 0.0509\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 40] Training\n",
            ">>>> [Epoch: 40] Avg. loss: 0.4458 | Mean IoU: 0.5965\n",
            ">>>> [Epoch: 41] Training\n",
            ">>>> [Epoch: 41] Avg. loss: 0.4314 | Mean IoU: 0.5969\n",
            ">>>> [Epoch: 42] Training\n",
            ">>>> [Epoch: 42] Avg. loss: 0.4207 | Mean IoU: 0.6042\n",
            ">>>> [Epoch: 43] Training\n",
            ">>>> [Epoch: 43] Avg. loss: 0.4181 | Mean IoU: 0.6094\n",
            ">>>> [Epoch: 44] Training\n",
            ">>>> [Epoch: 44] Avg. loss: 0.3979 | Mean IoU: 0.6187\n",
            ">>>> [Epoch: 45] Training\n",
            ">>>> [Epoch: 45] Avg. loss: 0.3934 | Mean IoU: 0.6206\n",
            ">>>> [Epoch: 46] Training\n",
            ">>>> [Epoch: 46] Avg. loss: 0.3922 | Mean IoU: 0.6229\n",
            ">>>> [Epoch: 47] Training\n",
            ">>>> [Epoch: 47] Avg. loss: 0.3837 | Mean IoU: 0.6372\n",
            ">>>> [Epoch: 48] Training\n",
            ">>>> [Epoch: 48] Avg. loss: 0.3827 | Mean IoU: 0.6304\n",
            ">>>> [Epoch: 49] Training\n",
            ">>>> [Epoch: 49] Avg. loss: 0.3731 | Mean IoU: 0.6410\n",
            ">>>> [Epoch: 49] Validation\n",
            ">>>> [Epoch: 49] Avg. loss: 0.4712 | Mean IoU: 0.6211\n",
            "sky: 0.9366\n",
            "building: 0.7919\n",
            "pole: 0.0696\n",
            "road: 0.9525\n",
            "pavement: 0.8141\n",
            "tree: 0.8922\n",
            "sign_symbol: 0.2878\n",
            "fence: 0.6112\n",
            "car: 0.6702\n",
            "pedestrian: 0.2321\n",
            "bicyclist: 0.5739\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 50] Training\n",
            ">>>> [Epoch: 50] Avg. loss: 0.3598 | Mean IoU: 0.6509\n",
            ">>>> [Epoch: 51] Training\n",
            ">>>> [Epoch: 51] Avg. loss: 0.3656 | Mean IoU: 0.6455\n",
            ">>>> [Epoch: 52] Training\n",
            ">>>> [Epoch: 52] Avg. loss: 0.3546 | Mean IoU: 0.6541\n",
            ">>>> [Epoch: 53] Training\n",
            ">>>> [Epoch: 53] Avg. loss: 0.3505 | Mean IoU: 0.6587\n",
            ">>>> [Epoch: 54] Training\n",
            ">>>> [Epoch: 54] Avg. loss: 0.3384 | Mean IoU: 0.6680\n",
            ">>>> [Epoch: 55] Training\n",
            ">>>> [Epoch: 55] Avg. loss: 0.3309 | Mean IoU: 0.6706\n",
            ">>>> [Epoch: 56] Training\n",
            ">>>> [Epoch: 56] Avg. loss: 0.3332 | Mean IoU: 0.6697\n",
            ">>>> [Epoch: 57] Training\n",
            ">>>> [Epoch: 57] Avg. loss: 0.3380 | Mean IoU: 0.6692\n",
            ">>>> [Epoch: 58] Training\n",
            ">>>> [Epoch: 58] Avg. loss: 0.3211 | Mean IoU: 0.6837\n",
            ">>>> [Epoch: 59] Training\n",
            ">>>> [Epoch: 59] Avg. loss: 0.3214 | Mean IoU: 0.6821\n",
            ">>>> [Epoch: 59] Validation\n",
            ">>>> [Epoch: 59] Avg. loss: 0.4674 | Mean IoU: 0.6368\n",
            "sky: 0.9292\n",
            "building: 0.8197\n",
            "pole: 0.0788\n",
            "road: 0.9557\n",
            "pavement: 0.8118\n",
            "tree: 0.8912\n",
            "sign_symbol: 0.2889\n",
            "fence: 0.6088\n",
            "car: 0.7117\n",
            "pedestrian: 0.2882\n",
            "bicyclist: 0.6209\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 60] Training\n",
            ">>>> [Epoch: 60] Avg. loss: 0.3272 | Mean IoU: 0.6780\n",
            ">>>> [Epoch: 61] Training\n",
            ">>>> [Epoch: 61] Avg. loss: 0.3173 | Mean IoU: 0.6838\n",
            ">>>> [Epoch: 62] Training\n",
            ">>>> [Epoch: 62] Avg. loss: 0.3092 | Mean IoU: 0.6951\n",
            ">>>> [Epoch: 63] Training\n",
            ">>>> [Epoch: 63] Avg. loss: 0.3032 | Mean IoU: 0.6961\n",
            ">>>> [Epoch: 64] Training\n",
            ">>>> [Epoch: 64] Avg. loss: 0.2894 | Mean IoU: 0.7037\n",
            ">>>> [Epoch: 65] Training\n",
            ">>>> [Epoch: 65] Avg. loss: 0.2929 | Mean IoU: 0.7055\n",
            ">>>> [Epoch: 66] Training\n",
            ">>>> [Epoch: 66] Avg. loss: 0.2933 | Mean IoU: 0.7024\n",
            ">>>> [Epoch: 67] Training\n",
            ">>>> [Epoch: 67] Avg. loss: 0.2873 | Mean IoU: 0.7043\n",
            ">>>> [Epoch: 68] Training\n",
            ">>>> [Epoch: 68] Avg. loss: 0.2847 | Mean IoU: 0.7117\n",
            ">>>> [Epoch: 69] Training\n",
            ">>>> [Epoch: 69] Avg. loss: 0.2807 | Mean IoU: 0.7139\n",
            ">>>> [Epoch: 69] Validation\n",
            ">>>> [Epoch: 69] Avg. loss: 0.4673 | Mean IoU: 0.6479\n",
            "sky: 0.9253\n",
            "building: 0.8229\n",
            "pole: 0.0902\n",
            "road: 0.9599\n",
            "pavement: 0.8345\n",
            "tree: 0.8818\n",
            "sign_symbol: 0.2987\n",
            "fence: 0.6382\n",
            "car: 0.7305\n",
            "pedestrian: 0.2930\n",
            "bicyclist: 0.6522\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 70] Training\n",
            ">>>> [Epoch: 70] Avg. loss: 0.2757 | Mean IoU: 0.7193\n",
            ">>>> [Epoch: 71] Training\n",
            ">>>> [Epoch: 71] Avg. loss: 0.2734 | Mean IoU: 0.7199\n",
            ">>>> [Epoch: 72] Training\n",
            ">>>> [Epoch: 72] Avg. loss: 0.2676 | Mean IoU: 0.7192\n",
            ">>>> [Epoch: 73] Training\n",
            ">>>> [Epoch: 73] Avg. loss: 0.2679 | Mean IoU: 0.7221\n",
            ">>>> [Epoch: 74] Training\n",
            ">>>> [Epoch: 74] Avg. loss: 0.2707 | Mean IoU: 0.7173\n",
            ">>>> [Epoch: 75] Training\n",
            ">>>> [Epoch: 75] Avg. loss: 0.2604 | Mean IoU: 0.7303\n",
            ">>>> [Epoch: 76] Training\n",
            ">>>> [Epoch: 76] Avg. loss: 0.2625 | Mean IoU: 0.7177\n",
            ">>>> [Epoch: 77] Training\n",
            ">>>> [Epoch: 77] Avg. loss: 0.2598 | Mean IoU: 0.7268\n",
            ">>>> [Epoch: 78] Training\n",
            ">>>> [Epoch: 78] Avg. loss: 0.2617 | Mean IoU: 0.7265\n",
            ">>>> [Epoch: 79] Training\n",
            ">>>> [Epoch: 79] Avg. loss: 0.2641 | Mean IoU: 0.7239\n",
            ">>>> [Epoch: 79] Validation\n",
            ">>>> [Epoch: 79] Avg. loss: 0.4218 | Mean IoU: 0.6449\n",
            ">>>> [Epoch: 80] Training\n",
            ">>>> [Epoch: 80] Avg. loss: 0.2671 | Mean IoU: 0.7198\n",
            ">>>> [Epoch: 81] Training\n",
            ">>>> [Epoch: 81] Avg. loss: 0.2549 | Mean IoU: 0.7302\n",
            ">>>> [Epoch: 82] Training\n",
            ">>>> [Epoch: 82] Avg. loss: 0.2510 | Mean IoU: 0.7342\n",
            ">>>> [Epoch: 83] Training\n",
            ">>>> [Epoch: 83] Avg. loss: 0.2522 | Mean IoU: 0.7328\n",
            ">>>> [Epoch: 84] Training\n",
            ">>>> [Epoch: 84] Avg. loss: 0.2459 | Mean IoU: 0.7366\n",
            ">>>> [Epoch: 85] Training\n",
            ">>>> [Epoch: 85] Avg. loss: 0.2358 | Mean IoU: 0.7440\n",
            ">>>> [Epoch: 86] Training\n",
            ">>>> [Epoch: 86] Avg. loss: 0.2392 | Mean IoU: 0.7401\n",
            ">>>> [Epoch: 87] Training\n",
            ">>>> [Epoch: 87] Avg. loss: 0.2357 | Mean IoU: 0.7436\n",
            ">>>> [Epoch: 88] Training\n",
            ">>>> [Epoch: 88] Avg. loss: 0.2313 | Mean IoU: 0.7468\n",
            ">>>> [Epoch: 89] Training\n",
            ">>>> [Epoch: 89] Avg. loss: 0.2320 | Mean IoU: 0.7466\n",
            ">>>> [Epoch: 89] Validation\n",
            ">>>> [Epoch: 89] Avg. loss: 0.4657 | Mean IoU: 0.6407\n",
            ">>>> [Epoch: 90] Training\n",
            ">>>> [Epoch: 90] Avg. loss: 0.2433 | Mean IoU: 0.7419\n",
            ">>>> [Epoch: 91] Training\n",
            ">>>> [Epoch: 91] Avg. loss: 0.2354 | Mean IoU: 0.7442\n",
            ">>>> [Epoch: 92] Training\n",
            ">>>> [Epoch: 92] Avg. loss: 0.2249 | Mean IoU: 0.7507\n",
            ">>>> [Epoch: 93] Training\n",
            ">>>> [Epoch: 93] Avg. loss: 0.2241 | Mean IoU: 0.7518\n",
            ">>>> [Epoch: 94] Training\n",
            ">>>> [Epoch: 94] Avg. loss: 0.2226 | Mean IoU: 0.7527\n",
            ">>>> [Epoch: 95] Training\n",
            ">>>> [Epoch: 95] Avg. loss: 0.2180 | Mean IoU: 0.7582\n",
            ">>>> [Epoch: 96] Training\n",
            ">>>> [Epoch: 96] Avg. loss: 0.2292 | Mean IoU: 0.7474\n",
            ">>>> [Epoch: 97] Training\n",
            ">>>> [Epoch: 97] Avg. loss: 0.2253 | Mean IoU: 0.7504\n",
            ">>>> [Epoch: 98] Training\n",
            ">>>> [Epoch: 98] Avg. loss: 0.2247 | Mean IoU: 0.7538\n",
            ">>>> [Epoch: 99] Training\n",
            ">>>> [Epoch: 99] Avg. loss: 0.2323 | Mean IoU: 0.7438\n",
            ">>>> [Epoch: 99] Validation\n",
            ">>>> [Epoch: 99] Avg. loss: 0.4608 | Mean IoU: 0.6452\n",
            ">>>> [Epoch: 100] Training\n",
            ">>>> [Epoch: 100] Avg. loss: 0.2160 | Mean IoU: 0.7580\n",
            ">>>> [Epoch: 101] Training\n",
            ">>>> [Epoch: 101] Avg. loss: 0.2031 | Mean IoU: 0.7680\n",
            ">>>> [Epoch: 102] Training\n",
            ">>>> [Epoch: 102] Avg. loss: 0.1981 | Mean IoU: 0.7735\n",
            ">>>> [Epoch: 103] Training\n",
            ">>>> [Epoch: 103] Avg. loss: 0.1992 | Mean IoU: 0.7728\n",
            ">>>> [Epoch: 104] Training\n",
            ">>>> [Epoch: 104] Avg. loss: 0.1975 | Mean IoU: 0.7725\n",
            ">>>> [Epoch: 105] Training\n",
            ">>>> [Epoch: 105] Avg. loss: 0.1988 | Mean IoU: 0.7748\n",
            ">>>> [Epoch: 106] Training\n",
            ">>>> [Epoch: 106] Avg. loss: 0.1943 | Mean IoU: 0.7765\n",
            ">>>> [Epoch: 107] Training\n",
            ">>>> [Epoch: 107] Avg. loss: 0.1946 | Mean IoU: 0.7781\n",
            ">>>> [Epoch: 108] Training\n",
            ">>>> [Epoch: 108] Avg. loss: 0.1934 | Mean IoU: 0.7791\n",
            ">>>> [Epoch: 109] Training\n",
            ">>>> [Epoch: 109] Avg. loss: 0.1917 | Mean IoU: 0.7760\n",
            ">>>> [Epoch: 109] Validation\n",
            ">>>> [Epoch: 109] Avg. loss: 0.4556 | Mean IoU: 0.6631\n",
            "sky: 0.9319\n",
            "building: 0.8429\n",
            "pole: 0.0814\n",
            "road: 0.9642\n",
            "pavement: 0.8485\n",
            "tree: 0.8952\n",
            "sign_symbol: 0.3389\n",
            "fence: 0.6590\n",
            "car: 0.7082\n",
            "pedestrian: 0.3539\n",
            "bicyclist: 0.6704\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 110] Training\n",
            ">>>> [Epoch: 110] Avg. loss: 0.1945 | Mean IoU: 0.7806\n",
            ">>>> [Epoch: 111] Training\n",
            ">>>> [Epoch: 111] Avg. loss: 0.1923 | Mean IoU: 0.7770\n",
            ">>>> [Epoch: 112] Training\n",
            ">>>> [Epoch: 112] Avg. loss: 0.1900 | Mean IoU: 0.7803\n",
            ">>>> [Epoch: 113] Training\n",
            ">>>> [Epoch: 113] Avg. loss: 0.1914 | Mean IoU: 0.7796\n",
            ">>>> [Epoch: 114] Training\n",
            ">>>> [Epoch: 114] Avg. loss: 0.1880 | Mean IoU: 0.7805\n",
            ">>>> [Epoch: 115] Training\n",
            ">>>> [Epoch: 115] Avg. loss: 0.1885 | Mean IoU: 0.7817\n",
            ">>>> [Epoch: 116] Training\n",
            ">>>> [Epoch: 116] Avg. loss: 0.1901 | Mean IoU: 0.7814\n",
            ">>>> [Epoch: 117] Training\n",
            ">>>> [Epoch: 117] Avg. loss: 0.1905 | Mean IoU: 0.7808\n",
            ">>>> [Epoch: 118] Training\n",
            ">>>> [Epoch: 118] Avg. loss: 0.1885 | Mean IoU: 0.7817\n",
            ">>>> [Epoch: 119] Training\n",
            ">>>> [Epoch: 119] Avg. loss: 0.1900 | Mean IoU: 0.7822\n",
            ">>>> [Epoch: 119] Validation\n",
            ">>>> [Epoch: 119] Avg. loss: 0.4573 | Mean IoU: 0.6666\n",
            "sky: 0.9330\n",
            "building: 0.8474\n",
            "pole: 0.0789\n",
            "road: 0.9640\n",
            "pavement: 0.8495\n",
            "tree: 0.8976\n",
            "sign_symbol: 0.3396\n",
            "fence: 0.6668\n",
            "car: 0.7285\n",
            "pedestrian: 0.3515\n",
            "bicyclist: 0.6759\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 120] Training\n",
            ">>>> [Epoch: 120] Avg. loss: 0.1882 | Mean IoU: 0.7803\n",
            ">>>> [Epoch: 121] Training\n",
            ">>>> [Epoch: 121] Avg. loss: 0.1885 | Mean IoU: 0.7836\n",
            ">>>> [Epoch: 122] Training\n",
            ">>>> [Epoch: 122] Avg. loss: 0.1881 | Mean IoU: 0.7830\n",
            ">>>> [Epoch: 123] Training\n",
            ">>>> [Epoch: 123] Avg. loss: 0.1905 | Mean IoU: 0.7799\n",
            ">>>> [Epoch: 124] Training\n",
            ">>>> [Epoch: 124] Avg. loss: 0.1875 | Mean IoU: 0.7827\n",
            ">>>> [Epoch: 125] Training\n",
            ">>>> [Epoch: 125] Avg. loss: 0.1858 | Mean IoU: 0.7840\n",
            ">>>> [Epoch: 126] Training\n",
            ">>>> [Epoch: 126] Avg. loss: 0.1863 | Mean IoU: 0.7850\n",
            ">>>> [Epoch: 127] Training\n",
            ">>>> [Epoch: 127] Avg. loss: 0.1833 | Mean IoU: 0.7843\n",
            ">>>> [Epoch: 128] Training\n",
            ">>>> [Epoch: 128] Avg. loss: 0.1848 | Mean IoU: 0.7831\n",
            ">>>> [Epoch: 129] Training\n",
            ">>>> [Epoch: 129] Avg. loss: 0.1856 | Mean IoU: 0.7839\n",
            ">>>> [Epoch: 129] Validation\n",
            ">>>> [Epoch: 129] Avg. loss: 0.4361 | Mean IoU: 0.6671\n",
            "sky: 0.9312\n",
            "building: 0.8432\n",
            "pole: 0.0782\n",
            "road: 0.9638\n",
            "pavement: 0.8488\n",
            "tree: 0.8961\n",
            "sign_symbol: 0.3401\n",
            "fence: 0.6626\n",
            "car: 0.7186\n",
            "pedestrian: 0.3580\n",
            "bicyclist: 0.6967\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 130] Training\n",
            ">>>> [Epoch: 130] Avg. loss: 0.1823 | Mean IoU: 0.7864\n",
            ">>>> [Epoch: 131] Training\n",
            ">>>> [Epoch: 131] Avg. loss: 0.1845 | Mean IoU: 0.7844\n",
            ">>>> [Epoch: 132] Training\n",
            ">>>> [Epoch: 132] Avg. loss: 0.1793 | Mean IoU: 0.7880\n",
            ">>>> [Epoch: 133] Training\n",
            ">>>> [Epoch: 133] Avg. loss: 0.1829 | Mean IoU: 0.7877\n",
            ">>>> [Epoch: 134] Training\n",
            ">>>> [Epoch: 134] Avg. loss: 0.1819 | Mean IoU: 0.7872\n",
            ">>>> [Epoch: 135] Training\n",
            ">>>> [Epoch: 135] Avg. loss: 0.1835 | Mean IoU: 0.7844\n",
            ">>>> [Epoch: 136] Training\n",
            ">>>> [Epoch: 136] Avg. loss: 0.1852 | Mean IoU: 0.7867\n",
            ">>>> [Epoch: 137] Training\n",
            ">>>> [Epoch: 137] Avg. loss: 0.1818 | Mean IoU: 0.7865\n",
            ">>>> [Epoch: 138] Training\n",
            ">>>> [Epoch: 138] Avg. loss: 0.1823 | Mean IoU: 0.7870\n",
            ">>>> [Epoch: 139] Training\n",
            ">>>> [Epoch: 139] Avg. loss: 0.1835 | Mean IoU: 0.7814\n",
            ">>>> [Epoch: 139] Validation\n",
            ">>>> [Epoch: 139] Avg. loss: 0.4529 | Mean IoU: 0.6671\n",
            "sky: 0.9329\n",
            "building: 0.8464\n",
            "pole: 0.0755\n",
            "road: 0.9646\n",
            "pavement: 0.8506\n",
            "tree: 0.8956\n",
            "sign_symbol: 0.3398\n",
            "fence: 0.6567\n",
            "car: 0.7148\n",
            "pedestrian: 0.3679\n",
            "bicyclist: 0.6938\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 140] Training\n",
            ">>>> [Epoch: 140] Avg. loss: 0.1799 | Mean IoU: 0.7897\n",
            ">>>> [Epoch: 141] Training\n",
            ">>>> [Epoch: 141] Avg. loss: 0.1815 | Mean IoU: 0.7863\n",
            ">>>> [Epoch: 142] Training\n",
            ">>>> [Epoch: 142] Avg. loss: 0.1814 | Mean IoU: 0.7877\n",
            ">>>> [Epoch: 143] Training\n",
            ">>>> [Epoch: 143] Avg. loss: 0.1815 | Mean IoU: 0.7883\n",
            ">>>> [Epoch: 144] Training\n",
            ">>>> [Epoch: 144] Avg. loss: 0.1796 | Mean IoU: 0.7878\n",
            ">>>> [Epoch: 145] Training\n",
            ">>>> [Epoch: 145] Avg. loss: 0.1780 | Mean IoU: 0.7906\n",
            ">>>> [Epoch: 146] Training\n",
            ">>>> [Epoch: 146] Avg. loss: 0.1800 | Mean IoU: 0.7884\n",
            ">>>> [Epoch: 147] Training\n",
            ">>>> [Epoch: 147] Avg. loss: 0.1810 | Mean IoU: 0.7888\n",
            ">>>> [Epoch: 148] Training\n",
            ">>>> [Epoch: 148] Avg. loss: 0.1819 | Mean IoU: 0.7844\n",
            ">>>> [Epoch: 149] Training\n",
            ">>>> [Epoch: 149] Avg. loss: 0.1826 | Mean IoU: 0.7890\n",
            ">>>> [Epoch: 149] Validation\n",
            ">>>> [Epoch: 149] Avg. loss: 0.4715 | Mean IoU: 0.6666\n",
            ">>>> [Epoch: 150] Training\n",
            ">>>> [Epoch: 150] Avg. loss: 0.1784 | Mean IoU: 0.7884\n",
            ">>>> [Epoch: 151] Training\n",
            ">>>> [Epoch: 151] Avg. loss: 0.1789 | Mean IoU: 0.7901\n",
            ">>>> [Epoch: 152] Training\n",
            ">>>> [Epoch: 152] Avg. loss: 0.1789 | Mean IoU: 0.7913\n",
            ">>>> [Epoch: 153] Training\n",
            ">>>> [Epoch: 153] Avg. loss: 0.1783 | Mean IoU: 0.7897\n",
            ">>>> [Epoch: 154] Training\n",
            ">>>> [Epoch: 154] Avg. loss: 0.1803 | Mean IoU: 0.7865\n",
            ">>>> [Epoch: 155] Training\n",
            ">>>> [Epoch: 155] Avg. loss: 0.1775 | Mean IoU: 0.7892\n",
            ">>>> [Epoch: 156] Training\n",
            ">>>> [Epoch: 156] Avg. loss: 0.1759 | Mean IoU: 0.7925\n",
            ">>>> [Epoch: 157] Training\n",
            ">>>> [Epoch: 157] Avg. loss: 0.1778 | Mean IoU: 0.7899\n",
            ">>>> [Epoch: 158] Training\n",
            ">>>> [Epoch: 158] Avg. loss: 0.1777 | Mean IoU: 0.7896\n",
            ">>>> [Epoch: 159] Training\n",
            ">>>> [Epoch: 159] Avg. loss: 0.1787 | Mean IoU: 0.7900\n",
            ">>>> [Epoch: 159] Validation\n",
            ">>>> [Epoch: 159] Avg. loss: 0.4519 | Mean IoU: 0.6702\n",
            "sky: 0.9341\n",
            "building: 0.8494\n",
            "pole: 0.0784\n",
            "road: 0.9644\n",
            "pavement: 0.8504\n",
            "tree: 0.8979\n",
            "sign_symbol: 0.3435\n",
            "fence: 0.6678\n",
            "car: 0.7130\n",
            "pedestrian: 0.3750\n",
            "bicyclist: 0.6986\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 160] Training\n",
            ">>>> [Epoch: 160] Avg. loss: 0.1766 | Mean IoU: 0.7900\n",
            ">>>> [Epoch: 161] Training\n",
            ">>>> [Epoch: 161] Avg. loss: 0.1764 | Mean IoU: 0.7910\n",
            ">>>> [Epoch: 162] Training\n",
            ">>>> [Epoch: 162] Avg. loss: 0.1760 | Mean IoU: 0.7910\n",
            ">>>> [Epoch: 163] Training\n",
            ">>>> [Epoch: 163] Avg. loss: 0.1759 | Mean IoU: 0.7910\n",
            ">>>> [Epoch: 164] Training\n",
            ">>>> [Epoch: 164] Avg. loss: 0.1763 | Mean IoU: 0.7920\n",
            ">>>> [Epoch: 165] Training\n",
            ">>>> [Epoch: 165] Avg. loss: 0.1768 | Mean IoU: 0.7911\n",
            ">>>> [Epoch: 166] Training\n",
            ">>>> [Epoch: 166] Avg. loss: 0.1761 | Mean IoU: 0.7913\n",
            ">>>> [Epoch: 167] Training\n",
            ">>>> [Epoch: 167] Avg. loss: 0.1752 | Mean IoU: 0.7919\n",
            ">>>> [Epoch: 168] Training\n",
            ">>>> [Epoch: 168] Avg. loss: 0.1760 | Mean IoU: 0.7912\n",
            ">>>> [Epoch: 169] Training\n",
            ">>>> [Epoch: 169] Avg. loss: 0.1739 | Mean IoU: 0.7926\n",
            ">>>> [Epoch: 169] Validation\n",
            ">>>> [Epoch: 169] Avg. loss: 0.4758 | Mean IoU: 0.6659\n",
            ">>>> [Epoch: 170] Training\n",
            ">>>> [Epoch: 170] Avg. loss: 0.1736 | Mean IoU: 0.7940\n",
            ">>>> [Epoch: 171] Training\n",
            ">>>> [Epoch: 171] Avg. loss: 0.1768 | Mean IoU: 0.7912\n",
            ">>>> [Epoch: 172] Training\n",
            ">>>> [Epoch: 172] Avg. loss: 0.1733 | Mean IoU: 0.7937\n",
            ">>>> [Epoch: 173] Training\n",
            ">>>> [Epoch: 173] Avg. loss: 0.1710 | Mean IoU: 0.7958\n",
            ">>>> [Epoch: 174] Training\n",
            ">>>> [Epoch: 174] Avg. loss: 0.1760 | Mean IoU: 0.7927\n",
            ">>>> [Epoch: 175] Training\n",
            ">>>> [Epoch: 175] Avg. loss: 0.1767 | Mean IoU: 0.7917\n",
            ">>>> [Epoch: 176] Training\n",
            ">>>> [Epoch: 176] Avg. loss: 0.1767 | Mean IoU: 0.7912\n",
            ">>>> [Epoch: 177] Training\n",
            ">>>> [Epoch: 177] Avg. loss: 0.1766 | Mean IoU: 0.7890\n",
            ">>>> [Epoch: 178] Training\n",
            ">>>> [Epoch: 178] Avg. loss: 0.1715 | Mean IoU: 0.7943\n",
            ">>>> [Epoch: 179] Training\n",
            ">>>> [Epoch: 179] Avg. loss: 0.1738 | Mean IoU: 0.7938\n",
            ">>>> [Epoch: 179] Validation\n",
            ">>>> [Epoch: 179] Avg. loss: 0.4884 | Mean IoU: 0.6659\n",
            ">>>> [Epoch: 180] Training\n",
            ">>>> [Epoch: 180] Avg. loss: 0.1711 | Mean IoU: 0.7941\n",
            ">>>> [Epoch: 181] Training\n",
            ">>>> [Epoch: 181] Avg. loss: 0.1713 | Mean IoU: 0.7950\n",
            ">>>> [Epoch: 182] Training\n",
            ">>>> [Epoch: 182] Avg. loss: 0.1711 | Mean IoU: 0.7960\n",
            ">>>> [Epoch: 183] Training\n",
            ">>>> [Epoch: 183] Avg. loss: 0.1736 | Mean IoU: 0.7914\n",
            ">>>> [Epoch: 184] Training\n",
            ">>>> [Epoch: 184] Avg. loss: 0.1725 | Mean IoU: 0.7928\n",
            ">>>> [Epoch: 185] Training\n",
            ">>>> [Epoch: 185] Avg. loss: 0.1727 | Mean IoU: 0.7924\n",
            ">>>> [Epoch: 186] Training\n",
            ">>>> [Epoch: 186] Avg. loss: 0.1733 | Mean IoU: 0.7944\n",
            ">>>> [Epoch: 187] Training\n",
            ">>>> [Epoch: 187] Avg. loss: 0.1693 | Mean IoU: 0.7977\n",
            ">>>> [Epoch: 188] Training\n",
            ">>>> [Epoch: 188] Avg. loss: 0.1693 | Mean IoU: 0.7965\n",
            ">>>> [Epoch: 189] Training\n",
            ">>>> [Epoch: 189] Avg. loss: 0.1691 | Mean IoU: 0.7965\n",
            ">>>> [Epoch: 189] Validation\n",
            ">>>> [Epoch: 189] Avg. loss: 0.4876 | Mean IoU: 0.6631\n",
            ">>>> [Epoch: 190] Training\n",
            ">>>> [Epoch: 190] Avg. loss: 0.1695 | Mean IoU: 0.7945\n",
            ">>>> [Epoch: 191] Training\n",
            ">>>> [Epoch: 191] Avg. loss: 0.1686 | Mean IoU: 0.7968\n",
            ">>>> [Epoch: 192] Training\n",
            ">>>> [Epoch: 192] Avg. loss: 0.1719 | Mean IoU: 0.7946\n",
            ">>>> [Epoch: 193] Training\n",
            ">>>> [Epoch: 193] Avg. loss: 0.1701 | Mean IoU: 0.7959\n",
            ">>>> [Epoch: 194] Training\n",
            ">>>> [Epoch: 194] Avg. loss: 0.1715 | Mean IoU: 0.7953\n",
            ">>>> [Epoch: 195] Training\n",
            ">>>> [Epoch: 195] Avg. loss: 0.1677 | Mean IoU: 0.7980\n",
            ">>>> [Epoch: 196] Training\n",
            ">>>> [Epoch: 196] Avg. loss: 0.1701 | Mean IoU: 0.7947\n",
            ">>>> [Epoch: 197] Training\n",
            ">>>> [Epoch: 197] Avg. loss: 0.1664 | Mean IoU: 0.8002\n",
            ">>>> [Epoch: 198] Training\n",
            ">>>> [Epoch: 198] Avg. loss: 0.1692 | Mean IoU: 0.7968\n",
            ">>>> [Epoch: 199] Training\n",
            ">>>> [Epoch: 199] Avg. loss: 0.1701 | Mean IoU: 0.7956\n",
            ">>>> [Epoch: 199] Validation\n",
            ">>>> [Epoch: 199] Avg. loss: 0.4901 | Mean IoU: 0.6670\n",
            ">>>> [Epoch: 200] Training\n",
            ">>>> [Epoch: 200] Avg. loss: 0.1683 | Mean IoU: 0.7967\n",
            ">>>> [Epoch: 201] Training\n",
            ">>>> [Epoch: 201] Avg. loss: 0.1663 | Mean IoU: 0.7990\n",
            ">>>> [Epoch: 202] Training\n",
            ">>>> [Epoch: 202] Avg. loss: 0.1687 | Mean IoU: 0.7985\n",
            ">>>> [Epoch: 203] Training\n",
            ">>>> [Epoch: 203] Avg. loss: 0.1673 | Mean IoU: 0.7979\n",
            ">>>> [Epoch: 204] Training\n",
            ">>>> [Epoch: 204] Avg. loss: 0.1679 | Mean IoU: 0.7976\n",
            ">>>> [Epoch: 205] Training\n",
            ">>>> [Epoch: 205] Avg. loss: 0.1668 | Mean IoU: 0.7987\n",
            ">>>> [Epoch: 206] Training\n",
            ">>>> [Epoch: 206] Avg. loss: 0.1673 | Mean IoU: 0.7981\n",
            ">>>> [Epoch: 207] Training\n",
            ">>>> [Epoch: 207] Avg. loss: 0.1681 | Mean IoU: 0.7989\n",
            ">>>> [Epoch: 208] Training\n",
            ">>>> [Epoch: 208] Avg. loss: 0.1654 | Mean IoU: 0.7994\n",
            ">>>> [Epoch: 209] Training\n",
            ">>>> [Epoch: 209] Avg. loss: 0.1631 | Mean IoU: 0.7999\n",
            ">>>> [Epoch: 209] Validation\n",
            ">>>> [Epoch: 209] Avg. loss: 0.4824 | Mean IoU: 0.6672\n",
            ">>>> [Epoch: 210] Training\n",
            ">>>> [Epoch: 210] Avg. loss: 0.1673 | Mean IoU: 0.7981\n",
            ">>>> [Epoch: 211] Training\n",
            ">>>> [Epoch: 211] Avg. loss: 0.1677 | Mean IoU: 0.7984\n",
            ">>>> [Epoch: 212] Training\n",
            ">>>> [Epoch: 212] Avg. loss: 0.1647 | Mean IoU: 0.7989\n",
            ">>>> [Epoch: 213] Training\n",
            ">>>> [Epoch: 213] Avg. loss: 0.1657 | Mean IoU: 0.7998\n",
            ">>>> [Epoch: 214] Training\n",
            ">>>> [Epoch: 214] Avg. loss: 0.1655 | Mean IoU: 0.7984\n",
            ">>>> [Epoch: 215] Training\n",
            ">>>> [Epoch: 215] Avg. loss: 0.1679 | Mean IoU: 0.7989\n",
            ">>>> [Epoch: 216] Training\n",
            ">>>> [Epoch: 216] Avg. loss: 0.1662 | Mean IoU: 0.7991\n",
            ">>>> [Epoch: 217] Training\n",
            ">>>> [Epoch: 217] Avg. loss: 0.1646 | Mean IoU: 0.7999\n",
            ">>>> [Epoch: 218] Training\n",
            ">>>> [Epoch: 218] Avg. loss: 0.1662 | Mean IoU: 0.7990\n",
            ">>>> [Epoch: 219] Training\n",
            ">>>> [Epoch: 219] Avg. loss: 0.1669 | Mean IoU: 0.8001\n",
            ">>>> [Epoch: 219] Validation\n",
            ">>>> [Epoch: 219] Avg. loss: 0.4844 | Mean IoU: 0.6680\n",
            ">>>> [Epoch: 220] Training\n",
            ">>>> [Epoch: 220] Avg. loss: 0.1668 | Mean IoU: 0.7988\n",
            ">>>> [Epoch: 221] Training\n",
            ">>>> [Epoch: 221] Avg. loss: 0.1679 | Mean IoU: 0.7988\n",
            ">>>> [Epoch: 222] Training\n",
            ">>>> [Epoch: 222] Avg. loss: 0.1674 | Mean IoU: 0.7979\n",
            ">>>> [Epoch: 223] Training\n",
            ">>>> [Epoch: 223] Avg. loss: 0.1642 | Mean IoU: 0.8000\n",
            ">>>> [Epoch: 224] Training\n",
            ">>>> [Epoch: 224] Avg. loss: 0.1668 | Mean IoU: 0.7981\n",
            ">>>> [Epoch: 225] Training\n",
            ">>>> [Epoch: 225] Avg. loss: 0.1643 | Mean IoU: 0.8005\n",
            ">>>> [Epoch: 226] Training\n",
            ">>>> [Epoch: 226] Avg. loss: 0.1648 | Mean IoU: 0.8006\n",
            ">>>> [Epoch: 227] Training\n",
            ">>>> [Epoch: 227] Avg. loss: 0.1663 | Mean IoU: 0.7983\n",
            ">>>> [Epoch: 228] Training\n",
            ">>>> [Epoch: 228] Avg. loss: 0.1654 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 229] Training\n",
            ">>>> [Epoch: 229] Avg. loss: 0.1674 | Mean IoU: 0.7970\n",
            ">>>> [Epoch: 229] Validation\n",
            ">>>> [Epoch: 229] Avg. loss: 0.4852 | Mean IoU: 0.6679\n",
            ">>>> [Epoch: 230] Training\n",
            ">>>> [Epoch: 230] Avg. loss: 0.1664 | Mean IoU: 0.7992\n",
            ">>>> [Epoch: 231] Training\n",
            ">>>> [Epoch: 231] Avg. loss: 0.1656 | Mean IoU: 0.7995\n",
            ">>>> [Epoch: 232] Training\n",
            ">>>> [Epoch: 232] Avg. loss: 0.1640 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 233] Training\n",
            ">>>> [Epoch: 233] Avg. loss: 0.1641 | Mean IoU: 0.8004\n",
            ">>>> [Epoch: 234] Training\n",
            ">>>> [Epoch: 234] Avg. loss: 0.1637 | Mean IoU: 0.8004\n",
            ">>>> [Epoch: 235] Training\n",
            ">>>> [Epoch: 235] Avg. loss: 0.1657 | Mean IoU: 0.7994\n",
            ">>>> [Epoch: 236] Training\n",
            ">>>> [Epoch: 236] Avg. loss: 0.1671 | Mean IoU: 0.7982\n",
            ">>>> [Epoch: 237] Training\n",
            ">>>> [Epoch: 237] Avg. loss: 0.1661 | Mean IoU: 0.7993\n",
            ">>>> [Epoch: 238] Training\n",
            ">>>> [Epoch: 238] Avg. loss: 0.1652 | Mean IoU: 0.7999\n",
            ">>>> [Epoch: 239] Training\n",
            ">>>> [Epoch: 239] Avg. loss: 0.1662 | Mean IoU: 0.7995\n",
            ">>>> [Epoch: 239] Validation\n",
            ">>>> [Epoch: 239] Avg. loss: 0.4925 | Mean IoU: 0.6660\n",
            ">>>> [Epoch: 240] Training\n",
            ">>>> [Epoch: 240] Avg. loss: 0.1643 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 241] Training\n",
            ">>>> [Epoch: 241] Avg. loss: 0.1678 | Mean IoU: 0.7994\n",
            ">>>> [Epoch: 242] Training\n",
            ">>>> [Epoch: 242] Avg. loss: 0.1653 | Mean IoU: 0.7996\n",
            ">>>> [Epoch: 243] Training\n",
            ">>>> [Epoch: 243] Avg. loss: 0.1653 | Mean IoU: 0.7993\n",
            ">>>> [Epoch: 244] Training\n",
            ">>>> [Epoch: 244] Avg. loss: 0.1651 | Mean IoU: 0.8009\n",
            ">>>> [Epoch: 245] Training\n",
            ">>>> [Epoch: 245] Avg. loss: 0.1645 | Mean IoU: 0.8000\n",
            ">>>> [Epoch: 246] Training\n",
            ">>>> [Epoch: 246] Avg. loss: 0.1644 | Mean IoU: 0.8001\n",
            ">>>> [Epoch: 247] Training\n",
            ">>>> [Epoch: 247] Avg. loss: 0.1668 | Mean IoU: 0.7977\n",
            ">>>> [Epoch: 248] Training\n",
            ">>>> [Epoch: 248] Avg. loss: 0.1654 | Mean IoU: 0.7992\n",
            ">>>> [Epoch: 249] Training\n",
            ">>>> [Epoch: 249] Avg. loss: 0.1681 | Mean IoU: 0.7987\n",
            ">>>> [Epoch: 249] Validation\n",
            ">>>> [Epoch: 249] Avg. loss: 0.4888 | Mean IoU: 0.6687\n",
            ">>>> [Epoch: 250] Training\n",
            ">>>> [Epoch: 250] Avg. loss: 0.1639 | Mean IoU: 0.8004\n",
            ">>>> [Epoch: 251] Training\n",
            ">>>> [Epoch: 251] Avg. loss: 0.1689 | Mean IoU: 0.7977\n",
            ">>>> [Epoch: 252] Training\n",
            ">>>> [Epoch: 252] Avg. loss: 0.1646 | Mean IoU: 0.8005\n",
            ">>>> [Epoch: 253] Training\n",
            ">>>> [Epoch: 253] Avg. loss: 0.1636 | Mean IoU: 0.8006\n",
            ">>>> [Epoch: 254] Training\n",
            ">>>> [Epoch: 254] Avg. loss: 0.1670 | Mean IoU: 0.7993\n",
            ">>>> [Epoch: 255] Training\n",
            ">>>> [Epoch: 255] Avg. loss: 0.1666 | Mean IoU: 0.7983\n",
            ">>>> [Epoch: 256] Training\n",
            ">>>> [Epoch: 256] Avg. loss: 0.1652 | Mean IoU: 0.7991\n",
            ">>>> [Epoch: 257] Training\n",
            ">>>> [Epoch: 257] Avg. loss: 0.1678 | Mean IoU: 0.7982\n",
            ">>>> [Epoch: 258] Training\n",
            ">>>> [Epoch: 258] Avg. loss: 0.1644 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 259] Training\n",
            ">>>> [Epoch: 259] Avg. loss: 0.1653 | Mean IoU: 0.7995\n",
            ">>>> [Epoch: 259] Validation\n",
            ">>>> [Epoch: 259] Avg. loss: 0.4866 | Mean IoU: 0.6657\n",
            ">>>> [Epoch: 260] Training\n",
            ">>>> [Epoch: 260] Avg. loss: 0.1666 | Mean IoU: 0.7999\n",
            ">>>> [Epoch: 261] Training\n",
            ">>>> [Epoch: 261] Avg. loss: 0.1671 | Mean IoU: 0.7993\n",
            ">>>> [Epoch: 262] Training\n",
            ">>>> [Epoch: 262] Avg. loss: 0.1660 | Mean IoU: 0.7988\n",
            ">>>> [Epoch: 263] Training\n",
            ">>>> [Epoch: 263] Avg. loss: 0.1656 | Mean IoU: 0.7989\n",
            ">>>> [Epoch: 264] Training\n",
            ">>>> [Epoch: 264] Avg. loss: 0.1651 | Mean IoU: 0.7995\n",
            ">>>> [Epoch: 265] Training\n",
            ">>>> [Epoch: 265] Avg. loss: 0.1641 | Mean IoU: 0.7993\n",
            ">>>> [Epoch: 266] Training\n",
            ">>>> [Epoch: 266] Avg. loss: 0.1660 | Mean IoU: 0.8024\n",
            ">>>> [Epoch: 267] Training\n",
            ">>>> [Epoch: 267] Avg. loss: 0.1627 | Mean IoU: 0.8009\n",
            ">>>> [Epoch: 268] Training\n",
            ">>>> [Epoch: 268] Avg. loss: 0.1649 | Mean IoU: 0.7994\n",
            ">>>> [Epoch: 269] Training\n",
            ">>>> [Epoch: 269] Avg. loss: 0.1644 | Mean IoU: 0.8021\n",
            ">>>> [Epoch: 269] Validation\n",
            ">>>> [Epoch: 269] Avg. loss: 0.4908 | Mean IoU: 0.6670\n",
            ">>>> [Epoch: 270] Training\n",
            ">>>> [Epoch: 270] Avg. loss: 0.1641 | Mean IoU: 0.8016\n",
            ">>>> [Epoch: 271] Training\n",
            ">>>> [Epoch: 271] Avg. loss: 0.1648 | Mean IoU: 0.7987\n",
            ">>>> [Epoch: 272] Training\n",
            ">>>> [Epoch: 272] Avg. loss: 0.1686 | Mean IoU: 0.7976\n",
            ">>>> [Epoch: 273] Training\n",
            ">>>> [Epoch: 273] Avg. loss: 0.1617 | Mean IoU: 0.8019\n",
            ">>>> [Epoch: 274] Training\n",
            ">>>> [Epoch: 274] Avg. loss: 0.1648 | Mean IoU: 0.8020\n",
            ">>>> [Epoch: 275] Training\n",
            ">>>> [Epoch: 275] Avg. loss: 0.1675 | Mean IoU: 0.7978\n",
            ">>>> [Epoch: 276] Training\n",
            ">>>> [Epoch: 276] Avg. loss: 0.1644 | Mean IoU: 0.7999\n",
            ">>>> [Epoch: 277] Training\n",
            ">>>> [Epoch: 277] Avg. loss: 0.1636 | Mean IoU: 0.8006\n",
            ">>>> [Epoch: 278] Training\n",
            ">>>> [Epoch: 278] Avg. loss: 0.1663 | Mean IoU: 0.8007\n",
            ">>>> [Epoch: 279] Training\n",
            ">>>> [Epoch: 279] Avg. loss: 0.1632 | Mean IoU: 0.8016\n",
            ">>>> [Epoch: 279] Validation\n",
            ">>>> [Epoch: 279] Avg. loss: 0.4813 | Mean IoU: 0.6664\n",
            ">>>> [Epoch: 280] Training\n",
            ">>>> [Epoch: 280] Avg. loss: 0.1619 | Mean IoU: 0.8022\n",
            ">>>> [Epoch: 281] Training\n",
            ">>>> [Epoch: 281] Avg. loss: 0.1663 | Mean IoU: 0.7993\n",
            ">>>> [Epoch: 282] Training\n",
            ">>>> [Epoch: 282] Avg. loss: 0.1642 | Mean IoU: 0.8013\n",
            ">>>> [Epoch: 283] Training\n",
            ">>>> [Epoch: 283] Avg. loss: 0.1654 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 284] Training\n",
            ">>>> [Epoch: 284] Avg. loss: 0.1646 | Mean IoU: 0.8005\n",
            ">>>> [Epoch: 285] Training\n",
            ">>>> [Epoch: 285] Avg. loss: 0.1634 | Mean IoU: 0.8018\n",
            ">>>> [Epoch: 286] Training\n",
            ">>>> [Epoch: 286] Avg. loss: 0.1635 | Mean IoU: 0.8006\n",
            ">>>> [Epoch: 287] Training\n",
            ">>>> [Epoch: 287] Avg. loss: 0.1636 | Mean IoU: 0.8030\n",
            ">>>> [Epoch: 288] Training\n",
            ">>>> [Epoch: 288] Avg. loss: 0.1636 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 289] Training\n",
            ">>>> [Epoch: 289] Avg. loss: 0.1655 | Mean IoU: 0.8001\n",
            ">>>> [Epoch: 289] Validation\n",
            ">>>> [Epoch: 289] Avg. loss: 0.4880 | Mean IoU: 0.6663\n",
            ">>>> [Epoch: 290] Training\n",
            ">>>> [Epoch: 290] Avg. loss: 0.1627 | Mean IoU: 0.8012\n",
            ">>>> [Epoch: 291] Training\n",
            ">>>> [Epoch: 291] Avg. loss: 0.1649 | Mean IoU: 0.8016\n",
            ">>>> [Epoch: 292] Training\n",
            ">>>> [Epoch: 292] Avg. loss: 0.1665 | Mean IoU: 0.7979\n",
            ">>>> [Epoch: 293] Training\n",
            ">>>> [Epoch: 293] Avg. loss: 0.1627 | Mean IoU: 0.8009\n",
            ">>>> [Epoch: 294] Training\n",
            ">>>> [Epoch: 294] Avg. loss: 0.1668 | Mean IoU: 0.7996\n",
            ">>>> [Epoch: 295] Training\n",
            ">>>> [Epoch: 295] Avg. loss: 0.1621 | Mean IoU: 0.8017\n",
            ">>>> [Epoch: 296] Training\n",
            ">>>> [Epoch: 296] Avg. loss: 0.1620 | Mean IoU: 0.8020\n",
            ">>>> [Epoch: 297] Training\n",
            ">>>> [Epoch: 297] Avg. loss: 0.1619 | Mean IoU: 0.8026\n",
            ">>>> [Epoch: 298] Training\n",
            ">>>> [Epoch: 298] Avg. loss: 0.1633 | Mean IoU: 0.8031\n",
            ">>>> [Epoch: 299] Training\n",
            ">>>> [Epoch: 299] Avg. loss: 0.1697 | Mean IoU: 0.7952\n",
            ">>>> [Epoch: 299] Validation\n",
            ">>>> [Epoch: 299] Avg. loss: 0.4820 | Mean IoU: 0.6669\n",
            "sky: 0.9326\n",
            "building: 0.8492\n",
            "pole: 0.0750\n",
            "road: 0.9654\n",
            "pavement: 0.8542\n",
            "tree: 0.8965\n",
            "sign_symbol: 0.3345\n",
            "fence: 0.6706\n",
            "car: 0.7146\n",
            "pedestrian: 0.3598\n",
            "bicyclist: 0.6834\n",
            "unlabeled: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -m test --save-dir save/ENet_CamVid/ --dataset camvid --dataset-dir ../CamVid2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-MMm-fYw2g8",
        "outputId": "9b509c51-8c9d-49cf-bd8e-40891a210c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: ../CamVid2/\n",
            "Save directory: save/ENet_CamVid/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 360, 480])\n",
            "Label size: torch.Size([10, 360, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0217,  3.4469, 15.9119,  9.0202, 32.0138, 32.4789,\n",
            "        13.2071, 38.3877, 44.1345,  0.0000], device='cuda:0')\n",
            "ENet(\n",
            "  (initial_block): InitialBlock(\n",
            "    (main_branch): Conv2d(3, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (ext_branch): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (downsample1_0): DownsamplingBottleneck(\n",
            "    (main_max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(16, 4, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (downsample2_0): DownsamplingBottleneck(\n",
            "    (main_max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular2_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric2_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular2_5): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_6): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric2_7): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_8): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular3_0): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric3_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular3_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_5): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric3_6): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_7): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (upsample4_0): UpsamplingBottleneck(\n",
            "    (main_conv1): Sequential(\n",
            "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (main_unpool1): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_tconv1): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "    (ext_tconv1_bnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (ext_tconv1_activation): ReLU()\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular4_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular4_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (upsample5_0): UpsamplingBottleneck(\n",
            "    (main_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (main_unpool1): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_tconv1): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "    (ext_tconv1_bnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (ext_tconv1_activation): ReLU()\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular5_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (transposed_conv): ConvTranspose2d(16, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            ")\n",
            "\n",
            "Testing...\n",
            "\n",
            ">>>> Running test dataset\n",
            ">>>> Avg. loss: 1.0176 | Mean IoU: 0.5277\n",
            "sky: 0.9008\n",
            "building: 0.6868\n",
            "pole: 0.2110\n",
            "road: 0.9205\n",
            "pavement: 0.7441\n",
            "tree: 0.6543\n",
            "sign_symbol: 0.2131\n",
            "fence: 0.1291\n",
            "car: 0.6907\n",
            "pedestrian: 0.2882\n",
            "bicyclist: 0.3662\n",
            "unlabeled: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/Enet/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aSoQxdqgop4",
        "outputId": "8ed885ba-e476-4f6f-fed8-e46af6915b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Enet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PSPNet with resnet 18 backbone"
      ],
      "metadata": {
        "id": "zawaP8iwHTC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py -m train --save-dir save/ --dataset camvid --dataset-dir ../CamVid2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "999c8a17-5258-452b-c2cc-59d533eb69e1",
        "id": "-JPOvfmWgo3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: ../CamVid2/\n",
            "Save directory: save/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 360, 480])\n",
            "Label size: torch.Size([10, 360, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 305, in <module>\n",
            "    loaders, w_class, class_encoding = load_dataset(dataset)\n",
            "  File \"main.py\", line 124, in load_dataset\n",
            "    class_weights = enet_weighing(train_loader, num_classes)\n",
            "  File \"/content/drive/My Drive/Enet/data/utils.py\", line 114, in enet_weighing\n",
            "    for _, label in dataloader:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 530, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1207, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1173, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1011, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\", line 295, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 85, in get_connection\n",
            "    from .connection import Client\n",
            "  File \"<frozen importlib._bootstrap>\", line 416, in parent\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -m test --save-dir save/ENet_CamVid/ --dataset camvid --dataset-dir ../CamVid2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A4LuIVWm8gT",
        "outputId": "fba26c64-d42f-4dd7-f83e-0a886ccaf5b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: ../CamVid2/\n",
            "Save directory: save/ENet_CamVid/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 360, 480])\n",
            "Label size: torch.Size([10, 360, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0217,  3.4469, 15.9119,  9.0202, 32.0138, 32.4789,\n",
            "        13.2071, 38.3877, 44.1345,  0.0000], device='cuda:0')\n",
            "PSPNet(\n",
            "  (feats): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (psp): PSPModule(\n",
            "    (stages): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(2, 2))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(3, 3))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck): Conv2d(2560, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (drop_1): Dropout2d(p=0.3, inplace=False)\n",
            "  (up_1): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (up_2): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (up_3): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (drop_2): Dropout2d(p=0.15, inplace=False)\n",
            "  (final): Sequential(\n",
            "    (0): Conv2d(64, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): LogSoftmax(dim=None)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=256, out_features=12, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "Testing...\n",
            "\n",
            ">>>> Running test dataset\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            ">>>> Avg. loss: 1.1493 | Mean IoU: 0.5488\n",
            "sky: 0.8942\n",
            "building: 0.7516\n",
            "pole: 0.2247\n",
            "road: 0.9107\n",
            "pavement: 0.7199\n",
            "tree: 0.6670\n",
            "sign_symbol: 0.2570\n",
            "fence: 0.1488\n",
            "car: 0.7134\n",
            "pedestrian: 0.3887\n",
            "bicyclist: 0.3606\n",
            "unlabeled: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PSPNet with resnet 101 backbone"
      ],
      "metadata": {
        "id": "_Gp3RcdZHZqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py -m train --save-dir save/ --dataset camvid --dataset-dir CamVid2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoVzcSejHmxz",
        "outputId": "3cec9f1c-5b33-46af-8df1-2a70a3017589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: CamVid2/\n",
            "Save directory: save/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 360, 480])\n",
            "Label size: torch.Size([10, 360, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0217,  3.4469, 15.9119,  9.0202, 32.0138, 32.4789,\n",
            "        13.2071, 38.3877, 44.1345,  0.0000], device='cuda:0')\n",
            "\n",
            "Training...\n",
            "\n",
            "PSPNet(\n",
            "  (feats): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (4): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (5): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (psp): PSPModule(\n",
            "    (stages): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(2, 2))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(3, 3))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck): Conv2d(2560, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (drop_1): Dropout2d(p=0.3, inplace=False)\n",
            "  (up_1): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (up_2): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (up_3): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (drop_2): Dropout2d(p=0.15, inplace=False)\n",
            "  (final): Sequential(\n",
            "    (0): Conv2d(64, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): LogSoftmax(dim=None)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=256, out_features=12, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            ">>>> [Epoch: 0] Training\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            ">>>> [Epoch: 0] Avg. loss: 1.6345 | Mean IoU: 0.2455\n",
            ">>>> [Epoch: 1] Training\n",
            ">>>> [Epoch: 1] Avg. loss: 1.2545 | Mean IoU: 0.3177\n",
            ">>>> [Epoch: 2] Training\n",
            ">>>> [Epoch: 2] Avg. loss: 1.1289 | Mean IoU: 0.3488\n",
            ">>>> [Epoch: 3] Training\n",
            ">>>> [Epoch: 3] Avg. loss: 1.0338 | Mean IoU: 0.3749\n",
            ">>>> [Epoch: 4] Training\n",
            ">>>> [Epoch: 4] Avg. loss: 0.9553 | Mean IoU: 0.3947\n",
            ">>>> [Epoch: 5] Training\n",
            ">>>> [Epoch: 5] Avg. loss: 0.9151 | Mean IoU: 0.4043\n",
            ">>>> [Epoch: 6] Training\n",
            ">>>> [Epoch: 6] Avg. loss: 0.8777 | Mean IoU: 0.4200\n",
            ">>>> [Epoch: 7] Training\n",
            ">>>> [Epoch: 7] Avg. loss: 0.8317 | Mean IoU: 0.4340\n",
            ">>>> [Epoch: 8] Training\n",
            ">>>> [Epoch: 8] Avg. loss: 0.7937 | Mean IoU: 0.4508\n",
            ">>>> [Epoch: 9] Training\n",
            ">>>> [Epoch: 9] Avg. loss: 0.7709 | Mean IoU: 0.4570\n",
            ">>>> [Epoch: 9] Validation\n",
            ">>>> [Epoch: 9] Avg. loss: 0.7015 | Mean IoU: 0.4350\n",
            "sky: 0.2129\n",
            "building: 0.6304\n",
            "pole: 0.0001\n",
            "road: 0.8847\n",
            "pavement: 0.7054\n",
            "tree: 0.7036\n",
            "sign_symbol: 0.2402\n",
            "fence: 0.4576\n",
            "car: 0.4859\n",
            "pedestrian: 0.1008\n",
            "bicyclist: 0.3640\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 10] Training\n",
            ">>>> [Epoch: 10] Avg. loss: 0.7151 | Mean IoU: 0.4791\n",
            ">>>> [Epoch: 11] Training\n",
            ">>>> [Epoch: 11] Avg. loss: 0.6750 | Mean IoU: 0.4916\n",
            ">>>> [Epoch: 12] Training\n",
            ">>>> [Epoch: 12] Avg. loss: 0.6645 | Mean IoU: 0.4964\n",
            ">>>> [Epoch: 13] Training\n",
            ">>>> [Epoch: 13] Avg. loss: 0.6325 | Mean IoU: 0.5126\n",
            ">>>> [Epoch: 14] Training\n",
            ">>>> [Epoch: 14] Avg. loss: 0.6143 | Mean IoU: 0.5140\n",
            ">>>> [Epoch: 15] Training\n",
            ">>>> [Epoch: 15] Avg. loss: 0.5945 | Mean IoU: 0.5321\n",
            ">>>> [Epoch: 16] Training\n",
            ">>>> [Epoch: 16] Avg. loss: 0.5441 | Mean IoU: 0.5517\n",
            ">>>> [Epoch: 17] Training\n",
            ">>>> [Epoch: 17] Avg. loss: 0.5111 | Mean IoU: 0.5710\n",
            ">>>> [Epoch: 18] Training\n",
            ">>>> [Epoch: 18] Avg. loss: 0.5032 | Mean IoU: 0.5724\n",
            ">>>> [Epoch: 19] Training\n",
            ">>>> [Epoch: 19] Avg. loss: 0.4992 | Mean IoU: 0.5751\n",
            ">>>> [Epoch: 19] Validation\n",
            ">>>> [Epoch: 19] Avg. loss: 0.5203 | Mean IoU: 0.5752\n",
            "sky: 0.9200\n",
            "building: 0.7033\n",
            "pole: 0.0581\n",
            "road: 0.9469\n",
            "pavement: 0.7621\n",
            "tree: 0.8385\n",
            "sign_symbol: 0.3138\n",
            "fence: 0.5086\n",
            "car: 0.5821\n",
            "pedestrian: 0.1844\n",
            "bicyclist: 0.5096\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 20] Training\n",
            ">>>> [Epoch: 20] Avg. loss: 0.4651 | Mean IoU: 0.5944\n",
            ">>>> [Epoch: 21] Training\n",
            ">>>> [Epoch: 21] Avg. loss: 0.4644 | Mean IoU: 0.5900\n",
            ">>>> [Epoch: 22] Training\n",
            ">>>> [Epoch: 22] Avg. loss: 0.4514 | Mean IoU: 0.6003\n",
            ">>>> [Epoch: 23] Training\n",
            ">>>> [Epoch: 23] Avg. loss: 0.4119 | Mean IoU: 0.6221\n",
            ">>>> [Epoch: 24] Training\n",
            ">>>> [Epoch: 24] Avg. loss: 0.3828 | Mean IoU: 0.6382\n",
            ">>>> [Epoch: 25] Training\n",
            ">>>> [Epoch: 25] Avg. loss: 0.3562 | Mean IoU: 0.6536\n",
            ">>>> [Epoch: 26] Training\n",
            ">>>> [Epoch: 26] Avg. loss: 0.3581 | Mean IoU: 0.6488\n",
            ">>>> [Epoch: 27] Training\n",
            ">>>> [Epoch: 27] Avg. loss: 0.3551 | Mean IoU: 0.6509\n",
            ">>>> [Epoch: 28] Training\n",
            ">>>> [Epoch: 28] Avg. loss: 0.3620 | Mean IoU: 0.6413\n",
            ">>>> [Epoch: 29] Training\n",
            ">>>> [Epoch: 29] Avg. loss: 0.3540 | Mean IoU: 0.6537\n",
            ">>>> [Epoch: 29] Validation\n",
            ">>>> [Epoch: 29] Avg. loss: 0.6702 | Mean IoU: 0.5834\n",
            "sky: 0.9249\n",
            "building: 0.7454\n",
            "pole: 0.1379\n",
            "road: 0.9595\n",
            "pavement: 0.7923\n",
            "tree: 0.8558\n",
            "sign_symbol: 0.3395\n",
            "fence: 0.2657\n",
            "car: 0.6010\n",
            "pedestrian: 0.2251\n",
            "bicyclist: 0.5699\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 30] Training\n",
            ">>>> [Epoch: 30] Avg. loss: 0.3086 | Mean IoU: 0.6804\n",
            ">>>> [Epoch: 31] Training\n",
            ">>>> [Epoch: 31] Avg. loss: 0.3078 | Mean IoU: 0.6799\n",
            ">>>> [Epoch: 32] Training\n",
            ">>>> [Epoch: 32] Avg. loss: 0.2983 | Mean IoU: 0.6880\n",
            ">>>> [Epoch: 33] Training\n",
            ">>>> [Epoch: 33] Avg. loss: 0.2871 | Mean IoU: 0.6892\n",
            ">>>> [Epoch: 34] Training\n",
            ">>>> [Epoch: 34] Avg. loss: 0.3001 | Mean IoU: 0.6858\n",
            ">>>> [Epoch: 35] Training\n",
            ">>>> [Epoch: 35] Avg. loss: 0.3441 | Mean IoU: 0.6596\n",
            ">>>> [Epoch: 36] Training\n",
            ">>>> [Epoch: 36] Avg. loss: 0.3287 | Mean IoU: 0.6608\n",
            ">>>> [Epoch: 37] Training\n",
            ">>>> [Epoch: 37] Avg. loss: 0.2900 | Mean IoU: 0.6906\n",
            ">>>> [Epoch: 38] Training\n",
            ">>>> [Epoch: 38] Avg. loss: 0.2483 | Mean IoU: 0.7182\n",
            ">>>> [Epoch: 39] Training\n",
            ">>>> [Epoch: 39] Avg. loss: 0.2291 | Mean IoU: 0.7339\n",
            ">>>> [Epoch: 39] Validation\n",
            ">>>> [Epoch: 39] Avg. loss: 0.5900 | Mean IoU: 0.6167\n",
            "sky: 0.9249\n",
            "building: 0.8496\n",
            "pole: 0.0580\n",
            "road: 0.9602\n",
            "pavement: 0.8486\n",
            "tree: 0.8814\n",
            "sign_symbol: 0.2874\n",
            "fence: 0.6156\n",
            "car: 0.7124\n",
            "pedestrian: 0.2340\n",
            "bicyclist: 0.4120\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 40] Training\n",
            ">>>> [Epoch: 40] Avg. loss: 0.2195 | Mean IoU: 0.7424\n",
            ">>>> [Epoch: 41] Training\n",
            ">>>> [Epoch: 41] Avg. loss: 0.2181 | Mean IoU: 0.7439\n",
            ">>>> [Epoch: 42] Training\n",
            ">>>> [Epoch: 42] Avg. loss: 0.2228 | Mean IoU: 0.7342\n",
            ">>>> [Epoch: 43] Training\n",
            ">>>> [Epoch: 43] Avg. loss: 0.2292 | Mean IoU: 0.7329\n",
            ">>>> [Epoch: 44] Training\n",
            ">>>> [Epoch: 44] Avg. loss: 0.2440 | Mean IoU: 0.7186\n",
            ">>>> [Epoch: 45] Training\n",
            ">>>> [Epoch: 45] Avg. loss: 0.2829 | Mean IoU: 0.6916\n",
            ">>>> [Epoch: 46] Training\n",
            ">>>> [Epoch: 46] Avg. loss: 0.3003 | Mean IoU: 0.6811\n",
            ">>>> [Epoch: 47] Training\n",
            ">>>> [Epoch: 47] Avg. loss: 0.2212 | Mean IoU: 0.7370\n",
            ">>>> [Epoch: 48] Training\n",
            ">>>> [Epoch: 48] Avg. loss: 0.2045 | Mean IoU: 0.7513\n",
            ">>>> [Epoch: 49] Training\n",
            ">>>> [Epoch: 49] Avg. loss: 0.1879 | Mean IoU: 0.7652\n",
            ">>>> [Epoch: 49] Validation\n",
            ">>>> [Epoch: 49] Avg. loss: 0.4292 | Mean IoU: 0.6445\n",
            "sky: 0.9276\n",
            "building: 0.8365\n",
            "pole: 0.0565\n",
            "road: 0.9612\n",
            "pavement: 0.8432\n",
            "tree: 0.8862\n",
            "sign_symbol: 0.2856\n",
            "fence: 0.6646\n",
            "car: 0.6222\n",
            "pedestrian: 0.3437\n",
            "bicyclist: 0.6629\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 50] Training\n",
            ">>>> [Epoch: 50] Avg. loss: 0.1870 | Mean IoU: 0.7642\n",
            ">>>> [Epoch: 51] Training\n",
            ">>>> [Epoch: 51] Avg. loss: 0.2459 | Mean IoU: 0.7099\n",
            ">>>> [Epoch: 52] Training\n",
            ">>>> [Epoch: 52] Avg. loss: 0.3287 | Mean IoU: 0.6608\n",
            ">>>> [Epoch: 53] Training\n",
            ">>>> [Epoch: 53] Avg. loss: 0.2993 | Mean IoU: 0.6819\n",
            ">>>> [Epoch: 54] Training\n",
            ">>>> [Epoch: 54] Avg. loss: 0.2443 | Mean IoU: 0.7182\n",
            ">>>> [Epoch: 55] Training\n",
            ">>>> [Epoch: 55] Avg. loss: 0.2205 | Mean IoU: 0.7338\n",
            ">>>> [Epoch: 56] Training\n",
            ">>>> [Epoch: 56] Avg. loss: 0.1947 | Mean IoU: 0.7584\n",
            ">>>> [Epoch: 57] Training\n",
            ">>>> [Epoch: 57] Avg. loss: 0.1728 | Mean IoU: 0.7748\n",
            ">>>> [Epoch: 58] Training\n",
            ">>>> [Epoch: 58] Avg. loss: 0.1664 | Mean IoU: 0.7805\n",
            ">>>> [Epoch: 59] Training\n",
            ">>>> [Epoch: 59] Avg. loss: 0.1652 | Mean IoU: 0.7815\n",
            ">>>> [Epoch: 59] Validation\n",
            ">>>> [Epoch: 59] Avg. loss: 0.4356 | Mean IoU: 0.6465\n",
            "sky: 0.9334\n",
            "building: 0.8094\n",
            "pole: 0.0834\n",
            "road: 0.9601\n",
            "pavement: 0.8318\n",
            "tree: 0.8886\n",
            "sign_symbol: 0.3314\n",
            "fence: 0.6220\n",
            "car: 0.5927\n",
            "pedestrian: 0.4015\n",
            "bicyclist: 0.6569\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 60] Training\n",
            ">>>> [Epoch: 60] Avg. loss: 0.1749 | Mean IoU: 0.7723\n",
            ">>>> [Epoch: 61] Training\n",
            ">>>> [Epoch: 61] Avg. loss: 0.1915 | Mean IoU: 0.7572\n",
            ">>>> [Epoch: 62] Training\n",
            ">>>> [Epoch: 62] Avg. loss: 0.1894 | Mean IoU: 0.7594\n",
            ">>>> [Epoch: 63] Training\n",
            ">>>> [Epoch: 63] Avg. loss: 0.2084 | Mean IoU: 0.7420\n",
            ">>>> [Epoch: 64] Training\n",
            ">>>> [Epoch: 64] Avg. loss: 0.2281 | Mean IoU: 0.7329\n",
            ">>>> [Epoch: 65] Training\n",
            ">>>> [Epoch: 65] Avg. loss: 0.2417 | Mean IoU: 0.7226\n",
            ">>>> [Epoch: 66] Training\n",
            ">>>> [Epoch: 66] Avg. loss: 0.2016 | Mean IoU: 0.7491\n",
            ">>>> [Epoch: 67] Training\n",
            ">>>> [Epoch: 67] Avg. loss: 0.1696 | Mean IoU: 0.7761\n",
            ">>>> [Epoch: 68] Training\n",
            ">>>> [Epoch: 68] Avg. loss: 0.1499 | Mean IoU: 0.7947\n",
            ">>>> [Epoch: 69] Training\n",
            ">>>> [Epoch: 69] Avg. loss: 0.1421 | Mean IoU: 0.8016\n",
            ">>>> [Epoch: 69] Validation\n",
            ">>>> [Epoch: 69] Avg. loss: 0.5031 | Mean IoU: 0.6509\n",
            "sky: 0.9363\n",
            "building: 0.8537\n",
            "pole: 0.0971\n",
            "road: 0.9650\n",
            "pavement: 0.8437\n",
            "tree: 0.9070\n",
            "sign_symbol: 0.2795\n",
            "fence: 0.7109\n",
            "car: 0.6400\n",
            "pedestrian: 0.3329\n",
            "bicyclist: 0.5936\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 70] Training\n",
            ">>>> [Epoch: 70] Avg. loss: 0.1393 | Mean IoU: 0.8056\n",
            ">>>> [Epoch: 71] Training\n",
            ">>>> [Epoch: 71] Avg. loss: 0.1544 | Mean IoU: 0.7930\n",
            ">>>> [Epoch: 72] Training\n",
            ">>>> [Epoch: 72] Avg. loss: 0.1527 | Mean IoU: 0.7904\n",
            ">>>> [Epoch: 73] Training\n",
            ">>>> [Epoch: 73] Avg. loss: 0.1618 | Mean IoU: 0.7850\n",
            ">>>> [Epoch: 74] Training\n",
            ">>>> [Epoch: 74] Avg. loss: 0.1607 | Mean IoU: 0.7840\n",
            ">>>> [Epoch: 75] Training\n",
            ">>>> [Epoch: 75] Avg. loss: 0.1516 | Mean IoU: 0.7934\n",
            ">>>> [Epoch: 76] Training\n",
            ">>>> [Epoch: 76] Avg. loss: 0.1469 | Mean IoU: 0.7986\n",
            ">>>> [Epoch: 77] Training\n",
            ">>>> [Epoch: 77] Avg. loss: 0.1452 | Mean IoU: 0.8001\n",
            ">>>> [Epoch: 78] Training\n",
            ">>>> [Epoch: 78] Avg. loss: 0.1359 | Mean IoU: 0.8054\n",
            ">>>> [Epoch: 79] Training\n",
            ">>>> [Epoch: 79] Avg. loss: 0.1293 | Mean IoU: 0.8130\n",
            ">>>> [Epoch: 79] Validation\n",
            ">>>> [Epoch: 79] Avg. loss: 0.4100 | Mean IoU: 0.6706\n",
            "sky: 0.9306\n",
            "building: 0.8387\n",
            "pole: 0.0937\n",
            "road: 0.9651\n",
            "pavement: 0.8657\n",
            "tree: 0.8890\n",
            "sign_symbol: 0.3108\n",
            "fence: 0.6833\n",
            "car: 0.7093\n",
            "pedestrian: 0.3984\n",
            "bicyclist: 0.6925\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 80] Training\n",
            ">>>> [Epoch: 80] Avg. loss: 0.1266 | Mean IoU: 0.8155\n",
            ">>>> [Epoch: 81] Training\n",
            ">>>> [Epoch: 81] Avg. loss: 0.1236 | Mean IoU: 0.8185\n",
            ">>>> [Epoch: 82] Training\n",
            ">>>> [Epoch: 82] Avg. loss: 0.1224 | Mean IoU: 0.8207\n",
            ">>>> [Epoch: 83] Training\n",
            ">>>> [Epoch: 83] Avg. loss: 0.1412 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 84] Training\n",
            ">>>> [Epoch: 84] Avg. loss: 0.2402 | Mean IoU: 0.7269\n",
            ">>>> [Epoch: 85] Training\n",
            ">>>> [Epoch: 85] Avg. loss: 0.5372 | Mean IoU: 0.5533\n",
            ">>>> [Epoch: 86] Training\n",
            ">>>> [Epoch: 86] Avg. loss: 0.3257 | Mean IoU: 0.6644\n",
            ">>>> [Epoch: 87] Training\n",
            ">>>> [Epoch: 87] Avg. loss: 0.2437 | Mean IoU: 0.7184\n",
            ">>>> [Epoch: 88] Training\n",
            ">>>> [Epoch: 88] Avg. loss: 0.1886 | Mean IoU: 0.7623\n",
            ">>>> [Epoch: 89] Training\n",
            ">>>> [Epoch: 89] Avg. loss: 0.1668 | Mean IoU: 0.7782\n",
            ">>>> [Epoch: 89] Validation\n",
            ">>>> [Epoch: 89] Avg. loss: 0.4507 | Mean IoU: 0.6833\n",
            "sky: 0.9263\n",
            "building: 0.8719\n",
            "pole: 0.1024\n",
            "road: 0.9566\n",
            "pavement: 0.8402\n",
            "tree: 0.8866\n",
            "sign_symbol: 0.2886\n",
            "fence: 0.6883\n",
            "car: 0.7940\n",
            "pedestrian: 0.4531\n",
            "bicyclist: 0.7080\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 90] Training\n",
            ">>>> [Epoch: 90] Avg. loss: 0.1501 | Mean IoU: 0.7964\n",
            ">>>> [Epoch: 91] Training\n",
            ">>>> [Epoch: 91] Avg. loss: 0.1358 | Mean IoU: 0.8070\n",
            ">>>> [Epoch: 92] Training\n",
            ">>>> [Epoch: 92] Avg. loss: 0.1254 | Mean IoU: 0.8177\n",
            ">>>> [Epoch: 93] Training\n",
            ">>>> [Epoch: 93] Avg. loss: 0.1208 | Mean IoU: 0.8214\n",
            ">>>> [Epoch: 94] Training\n",
            ">>>> [Epoch: 94] Avg. loss: 0.1198 | Mean IoU: 0.8231\n",
            ">>>> [Epoch: 95] Training\n",
            ">>>> [Epoch: 95] Avg. loss: 0.1187 | Mean IoU: 0.8248\n",
            ">>>> [Epoch: 96] Training\n",
            ">>>> [Epoch: 96] Avg. loss: 0.1174 | Mean IoU: 0.8254\n",
            ">>>> [Epoch: 97] Training\n",
            ">>>> [Epoch: 97] Avg. loss: 0.1181 | Mean IoU: 0.8250\n",
            ">>>> [Epoch: 98] Training\n",
            ">>>> [Epoch: 98] Avg. loss: 0.1129 | Mean IoU: 0.8288\n",
            ">>>> [Epoch: 99] Training\n",
            ">>>> [Epoch: 99] Avg. loss: 0.1148 | Mean IoU: 0.8281\n",
            ">>>> [Epoch: 99] Validation\n",
            ">>>> [Epoch: 99] Avg. loss: 0.4964 | Mean IoU: 0.6762\n",
            ">>>> [Epoch: 100] Training\n",
            ">>>> [Epoch: 100] Avg. loss: 0.1033 | Mean IoU: 0.8400\n",
            ">>>> [Epoch: 101] Training\n",
            ">>>> [Epoch: 101] Avg. loss: 0.0958 | Mean IoU: 0.8477\n",
            ">>>> [Epoch: 102] Training\n",
            ">>>> [Epoch: 102] Avg. loss: 0.0926 | Mean IoU: 0.8523\n",
            ">>>> [Epoch: 103] Training\n",
            ">>>> [Epoch: 103] Avg. loss: 0.0903 | Mean IoU: 0.8547\n",
            ">>>> [Epoch: 104] Training\n",
            ">>>> [Epoch: 104] Avg. loss: 0.0889 | Mean IoU: 0.8564\n",
            ">>>> [Epoch: 105] Training\n",
            ">>>> [Epoch: 105] Avg. loss: 0.0869 | Mean IoU: 0.8589\n",
            ">>>> [Epoch: 106] Training\n",
            ">>>> [Epoch: 106] Avg. loss: 0.0864 | Mean IoU: 0.8601\n",
            ">>>> [Epoch: 107] Training\n",
            ">>>> [Epoch: 107] Avg. loss: 0.0849 | Mean IoU: 0.8609\n",
            ">>>> [Epoch: 108] Training\n",
            ">>>> [Epoch: 108] Avg. loss: 0.0839 | Mean IoU: 0.8633\n",
            ">>>> [Epoch: 109] Training\n",
            ">>>> [Epoch: 109] Avg. loss: 0.0834 | Mean IoU: 0.8644\n",
            ">>>> [Epoch: 109] Validation\n",
            ">>>> [Epoch: 109] Avg. loss: 0.4720 | Mean IoU: 0.6895\n",
            "sky: 0.9325\n",
            "building: 0.8735\n",
            "pole: 0.1379\n",
            "road: 0.9670\n",
            "pavement: 0.8628\n",
            "tree: 0.9040\n",
            "sign_symbol: 0.3156\n",
            "fence: 0.7338\n",
            "car: 0.6801\n",
            "pedestrian: 0.4540\n",
            "bicyclist: 0.7236\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 110] Training\n",
            ">>>> [Epoch: 110] Avg. loss: 0.0831 | Mean IoU: 0.8637\n",
            ">>>> [Epoch: 111] Training\n",
            ">>>> [Epoch: 111] Avg. loss: 0.0817 | Mean IoU: 0.8665\n",
            ">>>> [Epoch: 112] Training\n",
            ">>>> [Epoch: 112] Avg. loss: 0.0806 | Mean IoU: 0.8670\n",
            ">>>> [Epoch: 113] Training\n",
            ">>>> [Epoch: 113] Avg. loss: 0.0804 | Mean IoU: 0.8680\n",
            ">>>> [Epoch: 114] Training\n",
            ">>>> [Epoch: 114] Avg. loss: 0.0805 | Mean IoU: 0.8677\n",
            ">>>> [Epoch: 115] Training\n",
            ">>>> [Epoch: 115] Avg. loss: 0.0791 | Mean IoU: 0.8687\n",
            ">>>> [Epoch: 116] Training\n",
            ">>>> [Epoch: 116] Avg. loss: 0.0794 | Mean IoU: 0.8695\n",
            ">>>> [Epoch: 117] Training\n",
            ">>>> [Epoch: 117] Avg. loss: 0.0783 | Mean IoU: 0.8703\n",
            ">>>> [Epoch: 118] Training\n",
            ">>>> [Epoch: 118] Avg. loss: 0.0777 | Mean IoU: 0.8712\n",
            ">>>> [Epoch: 119] Training\n",
            ">>>> [Epoch: 119] Avg. loss: 0.0773 | Mean IoU: 0.8719\n",
            ">>>> [Epoch: 119] Validation\n",
            ">>>> [Epoch: 119] Avg. loss: 0.5076 | Mean IoU: 0.6906\n",
            "sky: 0.9306\n",
            "building: 0.8782\n",
            "pole: 0.1379\n",
            "road: 0.9678\n",
            "pavement: 0.8679\n",
            "tree: 0.9060\n",
            "sign_symbol: 0.3023\n",
            "fence: 0.7288\n",
            "car: 0.7137\n",
            "pedestrian: 0.4512\n",
            "bicyclist: 0.7119\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 120] Training\n",
            ">>>> [Epoch: 120] Avg. loss: 0.0766 | Mean IoU: 0.8719\n",
            ">>>> [Epoch: 121] Training\n",
            ">>>> [Epoch: 121] Avg. loss: 0.0763 | Mean IoU: 0.8734\n",
            ">>>> [Epoch: 122] Training\n",
            ">>>> [Epoch: 122] Avg. loss: 0.0760 | Mean IoU: 0.8728\n",
            ">>>> [Epoch: 123] Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -m test --save-dir save/ --dataset camvid --dataset-dir CamVid2/ --name 34ResNet120"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwnrFJ2TkAGw",
        "outputId": "1fadc5ee-a749-4540-8912-33890f17b86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: CamVid2/\n",
            "Save directory: save/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 360, 480])\n",
            "Label size: torch.Size([10, 360, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0217,  3.4469, 15.9119,  9.0202, 32.0138, 32.4789,\n",
            "        13.2071, 38.3877, 44.1345,  0.0000], device='cuda:0')\n",
            "PSPNet(\n",
            "  (feats): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (4): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (5): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (psp): PSPModule(\n",
            "    (stages): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(2, 2))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(3, 3))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck): Conv2d(2560, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (drop_1): Dropout2d(p=0.3, inplace=False)\n",
            "  (up_1): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (up_2): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (up_3): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (drop_2): Dropout2d(p=0.15, inplace=False)\n",
            "  (final): Sequential(\n",
            "    (0): Conv2d(64, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): LogSoftmax(dim=None)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=256, out_features=12, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "Testing...\n",
            "\n",
            ">>>> Running test dataset\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            ">>>> Avg. loss: 1.1613 | Mean IoU: 0.5580\n",
            "sky: 0.8991\n",
            "building: 0.7569\n",
            "pole: 0.2534\n",
            "road: 0.9227\n",
            "pavement: 0.7529\n",
            "tree: 0.6508\n",
            "sign_symbol: 0.2523\n",
            "fence: 0.1573\n",
            "car: 0.7211\n",
            "pedestrian: 0.3953\n",
            "bicyclist: 0.3761\n",
            "unlabeled: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leC5WqbykBZI",
        "outputId": "a22019c1-ca69-44bd-d0c2-ec52e6bec819"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distillation\n",
        " distill from resnet 34(55%) to ENet(52%)"
      ],
      "metadata": {
        "id": "mZiIP6kC3tjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py -m train --save-dir save/ENet_CamVid/ --dataset camvid --dataset-dir ../CamVid2/ --name 18ResNet100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcDVs2kjQlf8",
        "outputId": "cc1d25ef-0ae7-4ba4-c2b1-989abe14383f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "           -3.0338e-01,  3.0129e-01],\n",
            "          [-8.5655e-02,  1.7762e-01, -1.9305e-03,  ...,  9.1998e-02,\n",
            "            3.6828e-02,  4.2610e-01]],\n",
            "\n",
            "         [[-1.0638e-03,  4.2344e-02,  1.5078e-01,  ...,  3.9301e-02,\n",
            "            1.4321e-01, -2.7588e-03],\n",
            "          [-3.1139e-01, -3.8307e-01, -2.9110e-02,  ..., -7.2726e-01,\n",
            "           -1.6441e-02, -1.2823e-01],\n",
            "          [-8.7167e-02, -2.1335e-01,  6.3036e-02,  ...,  4.5007e-02,\n",
            "           -5.6448e-02, -2.6175e-02],\n",
            "          ...,\n",
            "          [ 1.7488e-01, -4.8167e-01, -5.4804e-02,  ..., -1.0285e+00,\n",
            "           -3.8743e-02, -1.5636e-01],\n",
            "          [ 1.5686e-01,  8.5323e-03, -4.6786e-02,  ...,  4.8911e-03,\n",
            "            9.3036e-02, -8.0900e-02],\n",
            "          [-1.9534e-02, -2.4092e-01,  2.1891e-01,  ..., -5.6601e-01,\n",
            "            1.7843e-02, -9.5191e-02]],\n",
            "\n",
            "         [[-2.0334e-01, -5.6476e-02, -2.5241e-02,  ..., -1.4827e-01,\n",
            "           -1.1361e-01,  1.8520e-01],\n",
            "          [-1.3482e-02,  3.3833e-01, -3.5941e-02,  ...,  6.7428e-01,\n",
            "            1.5695e-01,  4.4884e-01],\n",
            "          [-1.4902e-01,  2.6232e-02, -2.8165e-02,  ...,  1.1132e-01,\n",
            "           -1.1729e-01,  4.4010e-02],\n",
            "          ...,\n",
            "          [-1.5202e-01,  3.3228e-01, -3.0821e-02,  ...,  5.5313e-01,\n",
            "            1.4723e-01,  1.9096e-01],\n",
            "          [ 1.1306e-01, -1.5162e-03, -1.9987e-01,  ...,  5.0885e-02,\n",
            "            1.3957e-01,  3.0773e-01],\n",
            "          [ 1.9482e-01,  3.8732e-01,  2.7027e-02,  ...,  2.8032e-01,\n",
            "           -5.9706e-02, -6.4259e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1038e-01,  1.7626e-02, -1.5685e-01,  ...,  1.3238e-01,\n",
            "           -5.0974e-03,  1.4956e-01],\n",
            "          [ 5.8234e-02, -1.1721e-01,  2.4375e-01,  ..., -3.3433e-01,\n",
            "            2.7253e-01, -3.2974e-02],\n",
            "          [ 3.3011e-02,  5.0674e-02,  2.7152e-02,  ...,  1.0906e-01,\n",
            "           -3.6842e-03,  2.8217e-02],\n",
            "          ...,\n",
            "          [ 3.4083e-01,  2.9984e-02,  1.4708e-02,  ..., -1.2038e-01,\n",
            "            7.3961e-02, -9.0782e-02],\n",
            "          [-2.1170e-01,  1.9048e-02,  1.3947e-01,  ..., -1.0078e-01,\n",
            "           -7.6714e-02,  1.3638e-01],\n",
            "          [ 2.6500e-01, -1.6758e-01,  4.9375e-03,  ..., -3.1708e-01,\n",
            "            1.0948e-01, -1.3810e-01]],\n",
            "\n",
            "         [[ 1.0831e-01,  1.0276e-01,  1.5837e-01,  ..., -2.2376e-02,\n",
            "            2.7247e-01, -2.4499e-01],\n",
            "          [ 2.0376e-02,  3.4855e-01,  8.2030e-02,  ...,  3.8403e-01,\n",
            "           -5.0241e-02,  2.2116e-01],\n",
            "          [ 7.5328e-02,  7.5574e-02,  6.6331e-02,  ...,  9.8063e-02,\n",
            "            5.1352e-02,  9.9604e-02],\n",
            "          ...,\n",
            "          [-1.6304e-01,  3.9040e-01, -6.6938e-02,  ...,  2.9360e-02,\n",
            "           -2.9253e-01,  1.6151e-02],\n",
            "          [-7.6141e-02, -1.1195e-01,  2.4504e-01,  ...,  3.4825e-01,\n",
            "           -9.5248e-03,  2.6155e-02],\n",
            "          [-1.6156e-01, -5.0335e-02,  9.4331e-02,  ..., -3.0120e-01,\n",
            "           -1.2412e-01, -2.7077e-01]],\n",
            "\n",
            "         [[ 4.4730e-02,  1.1978e-01,  4.1019e-02,  ...,  5.4429e-01,\n",
            "           -4.6355e-01,  1.7391e-01],\n",
            "          [-8.2196e-02, -4.5839e-02, -2.0442e-01,  ..., -1.2225e-01,\n",
            "           -2.7612e-02, -4.2150e-01],\n",
            "          [-1.1066e-01,  1.8255e-01,  4.6600e-02,  ...,  2.1359e-01,\n",
            "           -6.2479e-02,  7.2640e-02],\n",
            "          ...,\n",
            "          [-2.9994e-01, -2.1177e-01, -1.8256e-01,  ..., -4.9186e-01,\n",
            "            6.9009e-02, -3.3018e-01],\n",
            "          [-1.7998e-01,  2.7657e-01, -5.2480e-01,  ...,  4.6283e-02,\n",
            "           -2.1146e-01,  2.0308e-01],\n",
            "          [ 2.2173e-02, -9.6999e-02, -5.1975e-02,  ..., -3.3495e-01,\n",
            "           -5.9121e-02, -2.0859e-01]]],\n",
            "\n",
            "\n",
            "        [[[-6.7902e-02, -2.4142e-01, -1.9893e-01,  ..., -5.5233e-03,\n",
            "            3.3401e-02, -9.1283e-02],\n",
            "          [ 3.3966e-02,  9.0529e-02,  4.7814e-02,  ...,  6.5979e-01,\n",
            "            1.6958e-01,  9.1339e-02],\n",
            "          [-2.1090e-01, -1.9212e-01, -2.5538e-02,  ..., -4.9570e-02,\n",
            "           -2.4580e-01, -1.0543e-01],\n",
            "          ...,\n",
            "          [ 1.1355e-01,  1.1811e-01, -1.7021e-01,  ..., -5.0770e-03,\n",
            "           -2.9843e-02,  1.5444e-01],\n",
            "          [-6.3572e-02, -1.5407e-01, -9.4679e-02,  ..., -3.0398e-01,\n",
            "           -2.0049e-01,  6.1272e-02],\n",
            "          [-5.3942e-02,  2.3138e-01,  1.0869e-01,  ...,  1.1196e-01,\n",
            "            6.1790e-02,  2.5049e-01]],\n",
            "\n",
            "         [[ 1.8871e-02,  6.6250e-02,  2.5501e-01,  ...,  1.9995e-01,\n",
            "           -4.4533e-02,  9.8013e-02],\n",
            "          [ 1.1183e-01, -4.6730e-01,  4.6305e-02,  ..., -1.0468e-01,\n",
            "            1.0503e-01, -2.1021e-01],\n",
            "          [ 5.5797e-03, -8.4504e-02,  8.3014e-02,  ...,  8.5255e-02,\n",
            "            2.1859e-01,  2.3630e-01],\n",
            "          ...,\n",
            "          [-1.5946e-01, -3.0247e-01,  2.4144e-02,  ..., -6.3657e-01,\n",
            "           -3.3157e-02, -3.4276e-01],\n",
            "          [ 2.7437e-02, -4.8693e-02, -1.2803e-01,  ...,  6.4079e-02,\n",
            "            1.3837e-02,  2.2079e-02],\n",
            "          [-6.7319e-02, -2.7118e-01,  3.3732e-02,  ..., -5.6916e-01,\n",
            "            5.0387e-02, -1.5213e-01]],\n",
            "\n",
            "         [[-1.3029e-01, -1.0117e-01,  5.6350e-02,  ..., -2.3079e-01,\n",
            "            9.3717e-04, -2.4040e-02],\n",
            "          [ 2.5158e-02,  2.0694e-01, -6.0930e-03,  ...,  3.3687e-01,\n",
            "            5.4528e-02,  1.4165e-02],\n",
            "          [-1.5411e-01, -5.5115e-02,  9.8281e-02,  ...,  7.8437e-02,\n",
            "            8.1518e-02,  1.2708e-01],\n",
            "          ...,\n",
            "          [-1.6662e-01,  2.4751e-01,  5.7923e-03,  ...,  1.1005e-01,\n",
            "           -1.0887e-01,  2.0392e-01],\n",
            "          [ 5.7088e-02, -1.9893e-02, -1.3057e-01,  ..., -1.3614e-01,\n",
            "            2.8971e-02,  6.7444e-02],\n",
            "          [ 3.4058e-02,  2.6780e-01, -2.0105e-02,  ...,  3.5962e-01,\n",
            "            7.7718e-02,  2.0067e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4196e-01, -1.0632e-01, -1.4709e-01,  ..., -2.7622e-02,\n",
            "            1.1753e-01, -1.5576e-02],\n",
            "          [ 1.4159e-01, -1.0953e-01,  3.6320e-01,  ...,  9.5728e-02,\n",
            "            2.2354e-01, -4.3850e-02],\n",
            "          [ 2.7849e-02,  1.9540e-02,  3.6593e-02,  ...,  2.8538e-01,\n",
            "           -1.9108e-01,  2.8148e-01],\n",
            "          ...,\n",
            "          [ 2.2454e-01, -1.3831e-01,  5.0071e-02,  ..., -3.8293e-01,\n",
            "            3.0005e-01, -9.9002e-02],\n",
            "          [-4.8076e-02, -9.8623e-02,  1.5895e-01,  ...,  1.3415e-01,\n",
            "            4.6923e-02, -1.2989e-01],\n",
            "          [ 8.4711e-02, -1.1636e-01,  6.2062e-02,  ..., -2.3521e-01,\n",
            "            1.5349e-01, -2.8533e-02]],\n",
            "\n",
            "         [[ 3.6682e-02,  6.2968e-02,  2.9200e-01,  ..., -2.6499e-02,\n",
            "            1.6610e-01, -4.1012e-02],\n",
            "          [-1.3915e-01,  7.0446e-01,  2.5177e-02,  ...,  9.0870e-01,\n",
            "           -2.1388e-01,  3.8030e-01],\n",
            "          [ 2.4593e-01,  8.9991e-02,  1.3591e-01,  ..., -1.0990e-01,\n",
            "            2.3299e-01, -5.8248e-02],\n",
            "          ...,\n",
            "          [ 8.9333e-02,  3.5928e-01,  5.5458e-02,  ...,  5.2948e-01,\n",
            "           -1.0691e-01,  3.6907e-02],\n",
            "          [-3.7941e-02, -8.6420e-02,  9.6575e-02,  ...,  2.8472e-02,\n",
            "           -4.8695e-03,  1.4225e-02],\n",
            "          [-6.7495e-02,  7.0143e-02,  4.5103e-02,  ..., -4.6545e-03,\n",
            "           -1.5467e-01, -3.6762e-02]],\n",
            "\n",
            "         [[-1.2930e-02,  1.3023e-01,  1.1891e-01,  ...,  2.0774e-01,\n",
            "            5.9790e-02, -4.5074e-02],\n",
            "          [-2.9686e-01, -1.9008e-01, -1.5582e-01,  ...,  1.9721e-01,\n",
            "           -5.6243e-02, -1.6795e-01],\n",
            "          [-2.6309e-01,  2.1748e-01, -2.1494e-02,  ...,  1.3362e-01,\n",
            "           -1.3132e-01,  9.6141e-02],\n",
            "          ...,\n",
            "          [-1.2773e-01,  4.0198e-02, -2.2590e-01,  ..., -2.2692e-01,\n",
            "           -2.2432e-01, -2.7464e-01],\n",
            "          [-1.8889e-01,  1.5751e-01, -2.2761e-01,  ...,  3.8704e-01,\n",
            "           -2.9745e-01,  2.1670e-01],\n",
            "          [-4.4609e-02, -5.1890e-03, -1.8312e-02,  ..., -1.8132e-01,\n",
            "            8.5862e-02, -1.2582e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.0375e+00,  4.8406e-03, -3.2463e-01,  ..., -1.3229e-01,\n",
            "           -2.0535e-01, -5.1162e-02],\n",
            "          [ 1.0257e+00,  2.8709e+00,  7.3516e-01,  ...,  2.7514e-01,\n",
            "            2.1033e-01, -6.4755e-02],\n",
            "          [-1.4193e-01, -1.5698e+00, -4.1297e-01,  ..., -1.6192e-01,\n",
            "           -3.7340e-01,  1.3131e-01],\n",
            "          ...,\n",
            "          [ 6.3463e-02,  3.8070e-01, -4.2964e-01,  ...,  1.4247e-01,\n",
            "           -4.6626e-03, -5.2390e-02],\n",
            "          [-4.3912e-02,  3.7773e-01,  1.0130e-01,  ..., -1.6397e-01,\n",
            "           -2.5446e-02, -3.7246e-02],\n",
            "          [ 7.1242e-02,  1.0918e-01, -3.4023e-01,  ...,  1.1844e-01,\n",
            "           -2.0240e-02,  1.3210e-01]],\n",
            "\n",
            "         [[-4.5737e-02, -7.7905e-01, -1.2546e+00,  ..., -2.3041e-02,\n",
            "            1.6344e-01,  6.0427e-02],\n",
            "          [-9.6754e-01, -1.3137e+00,  1.0401e+00,  ..., -1.2950e-01,\n",
            "           -6.4516e-02,  2.0501e-02],\n",
            "          [ 2.4668e-01,  4.6157e-01, -4.9071e-01,  ...,  1.3389e-01,\n",
            "           -4.3047e-02,  5.6772e-02],\n",
            "          ...,\n",
            "          [-1.5350e-01,  3.6780e-01,  3.5088e-01,  ..., -3.5518e-01,\n",
            "            1.3141e-01, -9.6886e-02],\n",
            "          [-5.9436e-02, -1.4007e-01,  1.0548e-01,  ..., -2.3266e-02,\n",
            "            3.1035e-02,  9.6691e-02],\n",
            "          [-1.3599e-02,  1.6379e-01,  2.9624e-01,  ..., -2.0241e-01,\n",
            "            7.2610e-02, -9.2330e-02]],\n",
            "\n",
            "         [[-5.8216e-01,  1.0295e+00, -1.4936e+00,  ...,  8.4729e-02,\n",
            "           -9.7171e-02,  7.3396e-02],\n",
            "          [ 1.9011e-01,  1.1700e+00, -3.5394e-01,  ...,  2.1354e-01,\n",
            "            1.6396e-01,  8.7428e-02],\n",
            "          [ 7.6901e-02,  2.4270e+00,  1.8819e-01,  ...,  2.6874e-01,\n",
            "           -1.0769e-01,  2.1751e-01],\n",
            "          ...,\n",
            "          [-8.1116e-02,  4.1249e-01, -3.2491e-01,  ...,  4.0382e-01,\n",
            "            2.0986e-02,  1.7088e-01],\n",
            "          [-9.7425e-02, -6.8918e-02, -2.7125e-01,  ...,  1.1128e-02,\n",
            "           -1.0894e-01,  4.0729e-02],\n",
            "          [-9.2686e-02,  4.5248e-01, -1.9199e-01,  ...,  4.8563e-01,\n",
            "           -1.2100e-01,  1.8473e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1923e-01, -4.9717e-01,  4.8651e-01,  ...,  3.8778e-02,\n",
            "           -1.8348e-01,  2.2846e-01],\n",
            "          [-7.0143e-01, -2.7307e+00,  2.5881e-01,  ..., -5.9674e-01,\n",
            "            2.4283e-01, -4.6733e-02],\n",
            "          [-8.5556e-01,  2.8291e+00,  6.5791e-01,  ..., -1.3426e-01,\n",
            "           -2.8864e-01,  3.3740e-01],\n",
            "          ...,\n",
            "          [-3.3101e-03,  1.0861e-01, -1.8427e-01,  ..., -1.8009e-01,\n",
            "            2.8606e-02, -5.3660e-02],\n",
            "          [ 2.1809e-02,  2.4202e-01,  1.0770e-01,  ...,  7.2276e-03,\n",
            "            3.6711e-02,  1.8631e-01],\n",
            "          [ 9.4613e-03, -5.2509e-01, -1.5712e-01,  ..., -3.6297e-01,\n",
            "            1.1738e-01, -2.3614e-01]],\n",
            "\n",
            "         [[ 6.9798e-01, -2.4273e+00,  2.2723e+00,  ..., -5.1504e-02,\n",
            "            2.9140e-01,  2.1414e-02],\n",
            "          [ 9.8335e-01,  2.5475e+00,  7.8374e-01,  ...,  2.0606e-01,\n",
            "            2.1729e-01,  3.0506e-01],\n",
            "          [ 8.9122e-01, -3.3444e+00,  1.1896e+00,  ...,  8.9580e-02,\n",
            "            2.1103e-01,  1.8726e-02],\n",
            "          ...,\n",
            "          [ 7.2479e-02,  3.9766e-01, -4.8950e-02,  ...,  6.6072e-01,\n",
            "            1.9243e-02,  2.9571e-01],\n",
            "          [ 5.8969e-02, -3.2971e-01,  4.5916e-01,  ...,  3.6778e-02,\n",
            "            2.6335e-01, -1.1955e-01],\n",
            "          [ 4.9401e-02,  6.8052e-02,  1.1554e-01,  ...,  6.2347e-02,\n",
            "            6.7116e-02,  7.7571e-02]],\n",
            "\n",
            "         [[-1.6197e+00,  1.0847e+00, -7.2419e-01,  ...,  1.2158e-01,\n",
            "            5.7873e-02,  7.7702e-02],\n",
            "          [ 4.4268e-01,  1.0708e+00, -3.0114e-01,  ..., -4.4667e-01,\n",
            "           -2.6151e-02, -8.0002e-02],\n",
            "          [-1.7668e+00,  5.5477e-01,  9.8794e-02,  ...,  8.5490e-02,\n",
            "           -3.3951e-02, -2.0679e-01],\n",
            "          ...,\n",
            "          [-1.0101e-01,  8.5205e-02, -3.4208e-01,  ..., -7.7788e-02,\n",
            "           -2.5937e-01, -2.7534e-01],\n",
            "          [ 7.9620e-02,  2.4835e-01, -3.7018e-01,  ...,  4.5435e-02,\n",
            "           -4.4012e-02,  4.9901e-02],\n",
            "          [-1.8858e-01,  3.4635e-01, -1.8407e-01,  ..., -6.3345e-02,\n",
            "           -1.2551e-01, -6.9309e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.9970e-01, -4.9226e-02, -9.0303e-02,  ..., -6.6639e-02,\n",
            "           -4.4649e-02,  2.7759e-02],\n",
            "          [ 2.9217e-01,  3.1193e-01,  1.6604e-01,  ...,  1.2050e-01,\n",
            "           -7.9751e-03,  8.1087e-02],\n",
            "          [-1.8217e-01, -5.7185e-02,  8.6515e-02,  ..., -5.9133e-02,\n",
            "           -7.4123e-02,  9.7446e-02],\n",
            "          ...,\n",
            "          [ 1.4958e-01, -1.5762e-01,  1.9232e-02,  ..., -1.5244e-01,\n",
            "           -6.0451e-02,  1.2979e-01],\n",
            "          [-1.1220e-01, -1.8550e-01,  1.9848e-01,  ..., -2.4657e-01,\n",
            "           -1.8216e-01,  2.1457e-01],\n",
            "          [-6.5019e-02, -2.5325e-01, -9.7834e-02,  ..., -1.1646e-01,\n",
            "            1.4172e-02,  2.1099e-01]],\n",
            "\n",
            "         [[ 1.2745e-01,  7.1425e-02,  1.1861e-01,  ..., -8.0367e-02,\n",
            "            6.6136e-02,  5.3730e-02],\n",
            "          [-8.3766e-02, -3.6845e-01, -9.6756e-02,  ..., -2.7122e-01,\n",
            "           -5.8297e-02, -1.0129e-01],\n",
            "          [ 1.9813e-01,  6.5388e-02, -1.3404e-01,  ..., -6.2922e-02,\n",
            "            4.1268e-02,  4.1747e-03],\n",
            "          ...,\n",
            "          [ 1.3743e-01, -3.9465e-01,  3.6783e-03,  ..., -7.2867e-01,\n",
            "            1.1057e-01, -6.6890e-02],\n",
            "          [ 2.1472e-01,  6.7228e-02,  4.3561e-02,  ..., -3.5914e-02,\n",
            "            8.0477e-02,  4.7517e-02],\n",
            "          [-1.7191e-02, -2.5054e-01,  5.1845e-02,  ..., -4.6269e-01,\n",
            "            7.8090e-02, -1.0372e-01]],\n",
            "\n",
            "         [[-9.3696e-02, -1.1262e-01, -1.1078e-01,  ..., -6.7153e-02,\n",
            "            4.7306e-02,  1.8206e-02],\n",
            "          [-1.7327e-01,  1.7861e-01, -2.7719e-02,  ...,  2.7047e-01,\n",
            "           -3.0376e-02,  1.0101e-01],\n",
            "          [ 1.2196e-01,  2.2510e-01, -2.1256e-01,  ..., -6.5556e-02,\n",
            "           -1.2642e-02, -2.5195e-02],\n",
            "          ...,\n",
            "          [-2.1147e-01, -2.0469e-01, -1.1166e-02,  ...,  3.1947e-01,\n",
            "           -4.7106e-02,  8.7146e-02],\n",
            "          [-9.3202e-02, -1.5353e-01, -1.7971e-01,  ..., -5.1033e-02,\n",
            "            6.1348e-02,  9.2234e-02],\n",
            "          [-3.9186e-02,  4.9399e-01,  2.5675e-01,  ...,  4.0622e-01,\n",
            "           -4.4909e-02,  3.4815e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.6865e-02, -1.5576e-01, -5.7154e-02,  ..., -8.0778e-02,\n",
            "           -2.3194e-02,  4.1664e-03],\n",
            "          [ 1.3508e-01, -3.6049e-01,  2.8920e-01,  ...,  4.5354e-02,\n",
            "            2.5504e-01,  1.1743e-02],\n",
            "          [-3.3500e-01, -8.7161e-02,  3.5493e-02,  ..., -2.6425e-02,\n",
            "           -3.1318e-02, -5.5277e-02],\n",
            "          ...,\n",
            "          [ 2.6648e-02,  1.7612e-01,  3.2678e-01,  ..., -9.7404e-02,\n",
            "            1.5351e-01,  5.4864e-02],\n",
            "          [-2.1766e-01,  7.1064e-02,  8.9210e-02,  ..., -1.2028e-01,\n",
            "           -1.0988e-01,  1.8955e-02],\n",
            "          [ 1.5685e-01, -3.9488e-01,  1.3274e-01,  ..., -2.0369e-01,\n",
            "            6.9677e-02,  4.1811e-02]],\n",
            "\n",
            "         [[ 2.0930e-01,  2.1950e-02,  4.4152e-01,  ...,  2.0806e-01,\n",
            "            7.9667e-03,  7.5548e-02],\n",
            "          [-3.0712e-01,  6.4676e-01,  2.8512e-01,  ...,  4.2724e-02,\n",
            "           -1.3513e-01,  1.8833e-03],\n",
            "          [-3.8059e-02, -3.2128e-02,  5.6657e-01,  ...,  2.4270e-01,\n",
            "           -1.2586e-03,  1.2221e-01],\n",
            "          ...,\n",
            "          [-2.4577e-01,  5.7887e-01,  1.0525e-02,  ...,  1.0849e-01,\n",
            "           -2.3408e-01,  2.7858e-03],\n",
            "          [ 2.3510e-01, -1.7626e-01,  3.9112e-01,  ...,  4.2118e-01,\n",
            "           -3.6122e-02,  1.3293e-01],\n",
            "          [ 1.3491e-01,  2.0122e-01, -2.3345e-01,  ..., -2.9091e-01,\n",
            "           -9.2983e-02, -1.5665e-01]],\n",
            "\n",
            "         [[-4.1666e-03,  2.9846e-01,  1.0298e-01,  ...,  9.7313e-02,\n",
            "           -1.4517e-02,  3.5562e-02],\n",
            "          [-2.0030e-01,  1.6001e-01, -3.2897e-01,  ..., -2.0177e-01,\n",
            "           -1.2204e-01, -1.6415e-01],\n",
            "          [-1.8444e-01,  3.0889e-01,  1.0332e-01,  ...,  1.1553e-01,\n",
            "           -2.8464e-02,  4.0885e-02],\n",
            "          ...,\n",
            "          [-2.7008e-01,  2.4897e-01, -1.2871e-01,  ..., -1.1427e-01,\n",
            "           -4.6877e-02, -3.7944e-01],\n",
            "          [-1.4658e-01,  3.5445e-01, -2.4641e-01,  ...,  1.5554e-03,\n",
            "           -1.5797e-01,  4.6033e-02],\n",
            "          [-1.5152e-01,  4.4842e-01,  1.3190e-01,  ..., -2.3990e-01,\n",
            "            1.4862e-02, -2.7099e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.4943e-01, -1.4192e-01, -1.6952e-01,  ..., -1.6628e-01,\n",
            "           -1.0442e-01,  8.2456e-02],\n",
            "          [ 2.8563e-01,  1.0112e-01,  3.3214e-02,  ...,  1.0399e-01,\n",
            "            9.5985e-02,  7.6725e-02],\n",
            "          [ 9.2925e-04, -3.6935e-01,  2.9291e-02,  ..., -6.0716e-02,\n",
            "           -1.6053e-01,  1.6208e-01],\n",
            "          ...,\n",
            "          [ 1.7045e-02, -1.3178e-01,  1.7726e-03,  ...,  2.6668e-01,\n",
            "            2.6836e-01, -2.8855e-02],\n",
            "          [-3.2306e-02, -4.0818e-02, -1.1086e-02,  ..., -1.9508e-01,\n",
            "           -2.1823e-01,  8.2695e-02],\n",
            "          [ 8.2242e-02,  1.2553e-01,  4.7600e-02,  ..., -2.7614e-01,\n",
            "            1.1000e-01, -4.9939e-02]],\n",
            "\n",
            "         [[ 1.4754e-01, -8.5579e-02,  3.4045e-02,  ..., -5.0932e-02,\n",
            "            1.4767e-02,  1.3736e-02],\n",
            "          [-2.5051e-01, -5.9862e-01,  3.2129e-01,  ..., -5.5061e-01,\n",
            "            5.9115e-02, -9.4929e-02],\n",
            "          [ 8.3361e-02,  1.9129e-03,  6.5240e-02,  ..., -1.0774e-01,\n",
            "            1.1354e-01, -1.0196e-03],\n",
            "          ...,\n",
            "          [-8.9084e-02, -2.3201e-01,  1.4752e-02,  ..., -2.8426e-01,\n",
            "            4.6712e-02, -4.7902e-02],\n",
            "          [-4.9438e-02, -1.2024e-01, -8.3473e-02,  ...,  1.6128e-01,\n",
            "            2.5843e-01, -1.0019e-01],\n",
            "          [-3.8547e-02, -1.4741e-01,  1.0979e-01,  ..., -4.2575e-01,\n",
            "           -6.0813e-02, -2.7904e-01]],\n",
            "\n",
            "         [[-1.8663e-01, -2.3676e-02, -1.2987e-01,  ..., -3.0388e-02,\n",
            "           -1.2342e-02,  1.0571e-02],\n",
            "          [-1.4309e-01,  1.8132e-01, -5.0341e-02,  ...,  3.2319e-01,\n",
            "            6.6772e-02,  5.1256e-02],\n",
            "          [-6.3769e-02,  3.9268e-02, -8.5924e-03,  ..., -4.6840e-02,\n",
            "           -9.8432e-04, -3.3809e-03],\n",
            "          ...,\n",
            "          [-7.2740e-02,  3.0514e-01, -2.2394e-02,  ...,  2.9387e-01,\n",
            "            8.6726e-02, -1.8981e-01],\n",
            "          [-6.3481e-02, -4.0479e-02, -1.7669e-01,  ..., -1.6489e-01,\n",
            "           -2.7767e-01,  1.1382e-01],\n",
            "          [-9.1215e-03,  2.3601e-01,  5.5898e-02,  ...,  5.9386e-01,\n",
            "            1.2172e-01,  1.8820e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.6364e-02, -9.2995e-02, -5.6863e-02,  ..., -5.5235e-02,\n",
            "            1.3522e-02, -2.5417e-02],\n",
            "          [ 1.9661e-01, -3.8350e-01,  2.0686e-01,  ..., -3.1565e-02,\n",
            "            3.2542e-01,  3.0065e-02],\n",
            "          [-1.1254e-01,  1.9371e-02,  5.3359e-02,  ..., -6.6954e-02,\n",
            "           -1.0404e-01, -4.9724e-02],\n",
            "          ...,\n",
            "          [ 1.9664e-01,  2.9083e-02,  1.9368e-02,  ..., -2.7387e-01,\n",
            "            4.6994e-01,  4.4947e-02],\n",
            "          [ 6.2569e-02, -4.8813e-02,  1.0842e-01,  ...,  1.4465e-01,\n",
            "           -3.7071e-01,  1.2387e-01],\n",
            "          [ 8.7082e-02, -1.7239e-01,  4.2733e-02,  ..., -1.7377e-01,\n",
            "            1.2103e-01,  5.4521e-03]],\n",
            "\n",
            "         [[ 2.3730e-01,  2.8749e-02,  3.6918e-01,  ...,  2.1105e-01,\n",
            "           -1.6775e-02,  1.2869e-01],\n",
            "          [ 2.5821e-01,  6.7600e-01,  5.4822e-02,  ...,  8.8075e-02,\n",
            "           -2.1513e-01, -1.1094e-01],\n",
            "          [ 6.0376e-02,  2.8541e-02,  3.4406e-01,  ...,  2.9670e-01,\n",
            "            3.5082e-02,  1.2831e-01],\n",
            "          ...,\n",
            "          [ 2.0439e-02,  2.0423e-01,  6.9538e-02,  ...,  2.9816e-01,\n",
            "           -2.2995e-01,  2.3194e-01],\n",
            "          [ 6.2309e-02, -8.4380e-02,  1.4451e-01,  ...,  3.2304e-02,\n",
            "            3.3857e-01,  3.0472e-02],\n",
            "          [-1.6750e-02,  4.6589e-02,  5.2889e-02,  ...,  2.1736e-01,\n",
            "            1.7758e-01,  1.9220e-01]],\n",
            "\n",
            "         [[-2.3934e-02,  2.6091e-01,  2.3957e-02,  ...,  2.2348e-01,\n",
            "           -1.2214e-02,  4.5732e-02],\n",
            "          [-2.3517e-01,  2.5125e-01, -1.9095e-01,  ..., -2.5512e-01,\n",
            "           -1.5935e-01, -2.0131e-01],\n",
            "          [-6.7124e-02,  1.8333e-01,  9.6303e-02,  ...,  1.7385e-01,\n",
            "           -9.8315e-02,  5.6041e-02],\n",
            "          ...,\n",
            "          [-1.5685e-01, -5.3444e-02, -1.3421e-01,  ...,  1.3308e-01,\n",
            "           -2.4569e-01, -4.6608e-01],\n",
            "          [-1.5343e-02,  1.0917e-01, -2.2986e-01,  ...,  4.0100e-01,\n",
            "           -2.4942e-01,  1.0062e-01],\n",
            "          [-5.0839e-02,  2.2548e-02, -3.3633e-02,  ..., -7.8592e-02,\n",
            "           -6.5456e-02, -1.3643e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.0842e-01,  3.2720e-03, -1.1285e-01,  ...,  3.2176e-02,\n",
            "           -6.4206e-02,  4.6776e-02],\n",
            "          [ 1.6247e-01,  1.7930e-01, -9.2911e-02,  ...,  4.3517e-01,\n",
            "            4.7625e-03,  8.1181e-02],\n",
            "          [-4.0516e-01, -1.2394e-01, -1.9075e-01,  ...,  4.8844e-02,\n",
            "           -1.2152e-01,  3.5896e-02],\n",
            "          ...,\n",
            "          [ 1.2468e-01, -1.3424e-01,  2.5411e-02,  ...,  3.4101e-01,\n",
            "           -1.2395e-01, -2.3543e-01],\n",
            "          [-7.7546e-02, -1.0767e-01, -1.0519e-01,  ..., -6.6629e-01,\n",
            "           -4.4135e-02, -3.1287e-02],\n",
            "          [-1.8880e-02,  1.8207e-01,  7.1575e-02,  ...,  9.9531e-03,\n",
            "            6.1261e-02,  3.8110e-01]],\n",
            "\n",
            "         [[ 3.7198e-02, -5.7485e-03,  1.0096e-01,  ..., -1.3033e-01,\n",
            "            5.6751e-02,  7.1439e-02],\n",
            "          [-5.0355e-01, -4.8272e-01, -9.6257e-03,  ..., -1.4315e-01,\n",
            "           -2.6372e-02, -7.9194e-02],\n",
            "          [-1.8369e-01, -2.5003e-01, -1.8895e-02,  ..., -5.9360e-02,\n",
            "           -1.8821e-02,  5.4677e-02],\n",
            "          ...,\n",
            "          [ 9.9943e-02, -2.8458e-01, -4.9552e-02,  ..., -5.9479e-01,\n",
            "            3.1516e-02, -8.0461e-01],\n",
            "          [ 1.6268e-01, -8.7095e-02, -4.6793e-02,  ...,  8.9678e-02,\n",
            "           -8.8960e-02,  1.3394e-01],\n",
            "          [-5.6026e-02, -2.1191e-01,  8.6806e-02,  ..., -4.9504e-01,\n",
            "            1.2063e-01, -2.2318e-01]],\n",
            "\n",
            "         [[-7.7219e-02, -1.0580e-01, -2.9666e-02,  ..., -3.7682e-03,\n",
            "           -7.1088e-02,  1.6642e-02],\n",
            "          [-1.2005e-01,  2.5739e-01, -2.3770e-01,  ...,  4.9077e-01,\n",
            "           -3.7203e-02,  2.6023e-01],\n",
            "          [-2.3802e-01,  1.1865e-01,  9.4695e-03,  ...,  1.7891e-02,\n",
            "           -8.9237e-02,  3.3971e-02],\n",
            "          ...,\n",
            "          [-7.5927e-02,  3.5033e-01, -2.6092e-02,  ...,  2.5544e-01,\n",
            "           -3.6398e-01,  5.5161e-01],\n",
            "          [ 7.4234e-02, -3.2125e-02, -1.8554e-01,  ..., -2.7293e-02,\n",
            "            8.7824e-02,  1.3295e-01],\n",
            "          [ 9.7704e-02,  2.5274e-01,  8.0694e-02,  ...,  6.8049e-01,\n",
            "            1.3906e-02,  3.1319e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.4725e-02, -1.5396e-01, -2.8007e-02,  ...,  1.8844e-03,\n",
            "            2.3125e-02,  1.2811e-01],\n",
            "          [ 2.0573e-01, -2.8968e-01,  4.2687e-01,  ..., -1.4778e-01,\n",
            "            1.3982e-01,  1.0489e-02],\n",
            "          [ 1.3300e-01,  1.4713e-01, -4.3578e-02,  ..., -1.5094e-02,\n",
            "           -7.8651e-03,  1.1752e-01],\n",
            "          ...,\n",
            "          [ 1.9563e-01, -7.4400e-02, -3.7914e-02,  ..., -1.6784e-01,\n",
            "            3.0910e-01,  4.5214e-03],\n",
            "          [-1.3150e-01, -7.1161e-02,  1.4777e-01,  ...,  1.9328e-01,\n",
            "            1.6101e-01, -7.8250e-02],\n",
            "          [ 2.1454e-01, -1.1953e-01,  1.2440e-02,  ..., -4.0286e-01,\n",
            "            3.7646e-01, -1.2736e-01]],\n",
            "\n",
            "         [[ 7.3678e-02, -1.4079e-01,  5.3217e-01,  ...,  1.7956e-01,\n",
            "            1.2938e-01,  2.8350e-02],\n",
            "          [ 3.1100e-02,  7.3071e-01, -5.7849e-02,  ...,  8.4457e-02,\n",
            "            7.4472e-02,  1.7894e-01],\n",
            "          [ 3.1225e-01, -1.7810e-01,  1.0296e-01,  ...,  1.5793e-01,\n",
            "            1.3539e-01,  1.0644e-01],\n",
            "          ...,\n",
            "          [-1.5370e-01,  2.3192e-01, -4.9035e-02,  ...,  1.1251e+00,\n",
            "            1.8992e-01,  4.9641e-01],\n",
            "          [ 2.9934e-02,  3.8379e-02,  1.7372e-01,  ..., -1.0198e-01,\n",
            "            1.1460e-01, -7.0790e-02],\n",
            "          [-9.4384e-02, -1.1528e-02,  7.2154e-02,  ...,  5.7662e-02,\n",
            "           -2.9084e-01, -1.6277e-02]],\n",
            "\n",
            "         [[-1.5583e-02,  6.3468e-02, -1.6097e-01,  ...,  1.8442e-01,\n",
            "            2.9387e-02,  6.7161e-02],\n",
            "          [-2.8426e-01,  3.4150e-01, -3.4807e-01,  ..., -3.6841e-01,\n",
            "           -7.4352e-02, -7.5613e-02],\n",
            "          [-3.3179e-01,  2.6509e-01, -2.1822e-01,  ...,  1.7207e-01,\n",
            "            1.3285e-01, -4.0759e-02],\n",
            "          ...,\n",
            "          [-2.9275e-01, -2.2731e-01, -1.1545e-01,  ..., -3.3502e-01,\n",
            "           -4.6015e-01,  6.0503e-02],\n",
            "          [-8.9998e-02,  2.9982e-01, -2.7974e-01,  ...,  9.2479e-02,\n",
            "           -2.6370e-01,  4.1617e-02],\n",
            "          [ 6.6894e-02, -1.2984e-01, -4.7264e-02,  ..., -7.7451e-02,\n",
            "            1.1520e-01, -3.5427e-01]]]], device='cuda:0',\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[-2.3143, -2.1457, -2.1967,  ..., -2.3089, -2.2562, -2.1471],\n",
            "          [-2.4196, -2.4358, -2.4000,  ..., -2.3386, -2.3158, -2.3118],\n",
            "          [-2.3552, -2.3057, -2.2548,  ..., -2.2622, -2.2502, -2.2379],\n",
            "          ...,\n",
            "          [-2.4190, -2.2205, -2.0791,  ..., -2.3801, -2.2721, -2.3331],\n",
            "          [-2.4844, -2.3095, -2.1492,  ..., -2.4177, -2.3241, -2.3671],\n",
            "          [-2.7449, -2.6983, -2.6542,  ..., -2.5356, -2.5236, -2.5520]],\n",
            "\n",
            "         [[-2.4779, -2.4992, -2.4914,  ..., -2.4951, -2.6088, -2.6757],\n",
            "          [-2.3133, -2.2451, -2.3248,  ..., -2.4435, -2.5582, -2.6344],\n",
            "          [-2.3348, -2.2120, -2.3276,  ..., -2.5512, -2.6600, -2.6822],\n",
            "          ...,\n",
            "          [-1.9896, -1.8861, -2.0673,  ..., -2.2839, -2.4613, -2.5452],\n",
            "          [-1.9341, -1.9965, -2.1455,  ..., -2.4289, -2.5548, -2.6504],\n",
            "          [-2.3591, -2.1699, -2.2129,  ..., -2.4322, -2.5035, -2.4413]],\n",
            "\n",
            "         [[-2.9607, -2.8872, -2.9240,  ..., -2.9010, -2.8593, -2.5698],\n",
            "          [-3.1839, -3.0506, -3.1031,  ..., -3.1815, -3.1169, -2.6420],\n",
            "          [-3.1804, -3.1027, -3.1816,  ..., -3.1707, -3.1163, -2.6216],\n",
            "          ...,\n",
            "          [-2.6734, -2.9144, -2.8318,  ..., -2.6300, -2.6245, -2.2837],\n",
            "          [-2.7216, -2.9340, -2.8424,  ..., -2.7472, -2.6952, -2.2875],\n",
            "          [-2.4351, -2.7855, -2.7095,  ..., -2.7116, -2.7300, -2.3746]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9258, -3.2076, -3.2452,  ..., -3.2698, -3.2010, -3.2584],\n",
            "          [-3.1749, -3.3605, -3.3204,  ..., -3.4062, -3.3346, -3.4753],\n",
            "          [-3.1393, -3.3078, -3.2255,  ..., -3.4025, -3.3948, -3.5728],\n",
            "          ...,\n",
            "          [-3.1676, -2.9127, -2.8162,  ..., -3.0665, -3.0861, -3.4535],\n",
            "          [-3.0846, -2.8058, -2.7554,  ..., -3.0623, -3.0889, -3.4589],\n",
            "          [-3.1251, -2.7580, -2.7693,  ..., -2.9748, -2.9262, -2.9729]],\n",
            "\n",
            "         [[-2.3959, -2.3892, -2.4436,  ..., -2.3054, -2.3326, -2.1905],\n",
            "          [-2.7601, -2.6801, -2.5995,  ..., -2.6329, -2.5433, -2.3599],\n",
            "          [-2.8103, -2.8201, -2.7639,  ..., -2.6182, -2.5104, -2.3819],\n",
            "          ...,\n",
            "          [-2.8035, -2.9317, -2.9212,  ..., -2.9465, -2.7862, -2.5330],\n",
            "          [-2.8212, -2.9231, -2.8945,  ..., -2.9649, -2.7926, -2.5557],\n",
            "          [-2.7555, -2.7448, -2.7202,  ..., -2.8756, -2.8218, -2.7199]],\n",
            "\n",
            "         [[-2.7602, -2.7458, -2.7750,  ..., -2.6161, -2.5007, -2.5738],\n",
            "          [-2.6485, -2.6190, -2.6446,  ..., -2.6192, -2.5604, -2.5988],\n",
            "          [-2.6822, -2.6246, -2.6531,  ..., -2.6587, -2.6273, -2.5773],\n",
            "          ...,\n",
            "          [-2.8018, -2.9395, -2.8459,  ..., -2.4349, -2.5301, -2.3789],\n",
            "          [-2.7530, -2.8479, -2.7391,  ..., -2.3692, -2.4397, -2.3349],\n",
            "          [-2.4124, -2.4886, -2.4689,  ..., -2.4148, -2.5025, -2.4003]]],\n",
            "\n",
            "\n",
            "        [[[-2.3065, -2.2901, -2.3316,  ..., -2.4578, -2.4066, -2.4271],\n",
            "          [-2.3092, -2.1994, -2.1761,  ..., -2.0741, -2.0831, -2.1888],\n",
            "          [-2.3356, -2.1850, -2.1490,  ..., -1.9869, -1.9183, -2.0281],\n",
            "          ...,\n",
            "          [-2.2979, -2.3065, -2.2313,  ..., -2.3093, -2.1076, -2.2840],\n",
            "          [-2.4144, -2.3590, -2.2355,  ..., -2.3542, -2.2070, -2.3018],\n",
            "          [-2.7001, -2.4582, -2.3653,  ..., -2.2452, -2.2101, -2.3510]],\n",
            "\n",
            "         [[-2.7975, -2.8841, -2.8406,  ..., -2.7653, -2.8614, -2.7935],\n",
            "          [-2.8098, -2.9024, -2.8928,  ..., -2.9550, -2.9490, -2.8681],\n",
            "          [-2.7983, -2.9105, -2.9054,  ..., -2.9898, -2.9778, -2.8776],\n",
            "          ...,\n",
            "          [-2.7869, -2.6576, -2.5988,  ..., -2.8817, -3.0642, -2.8647],\n",
            "          [-2.6982, -2.5721, -2.5291,  ..., -2.8618, -3.0038, -2.8856],\n",
            "          [-2.5730, -2.3821, -2.3696,  ..., -2.6960, -2.7336, -2.6669]],\n",
            "\n",
            "         [[-2.5614, -2.5129, -2.5097,  ..., -2.4575, -2.4780, -2.2589],\n",
            "          [-2.6138, -2.7350, -2.7499,  ..., -2.6384, -2.5753, -2.0618],\n",
            "          [-2.6369, -2.8392, -2.8626,  ..., -2.7695, -2.6963, -2.0789],\n",
            "          ...,\n",
            "          [-3.0913, -3.3393, -3.3043,  ..., -2.2703, -2.3354, -1.9818],\n",
            "          [-2.9997, -3.1815, -3.1637,  ..., -2.2539, -2.3227, -2.0380],\n",
            "          [-2.5810, -2.7507, -2.7180,  ..., -2.3853, -2.4424, -2.3087]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9100, -3.1132, -3.0622,  ..., -2.8395, -2.7379, -2.8784],\n",
            "          [-2.8287, -2.9892, -2.9727,  ..., -2.8738, -2.9876, -3.2210],\n",
            "          [-2.8201, -2.9707, -2.9403,  ..., -2.8404, -2.9914, -3.2608],\n",
            "          ...,\n",
            "          [-2.7496, -2.8031, -2.7317,  ..., -2.8517, -2.9678, -3.1589],\n",
            "          [-2.7727, -2.8139, -2.8017,  ..., -2.8483, -2.8689, -3.1096],\n",
            "          [-2.6477, -2.5615, -2.5919,  ..., -2.5849, -2.6368, -2.8473]],\n",
            "\n",
            "         [[-2.1773, -2.0157, -2.0895,  ..., -2.1608, -2.2327, -2.3376],\n",
            "          [-2.1731, -2.1143, -2.1966,  ..., -2.3097, -2.3116, -2.3268],\n",
            "          [-2.2085, -2.0936, -2.1703,  ..., -2.2435, -2.2490, -2.3439],\n",
            "          ...,\n",
            "          [-2.1906, -2.3783, -2.3324,  ..., -2.2998, -2.1603, -2.0836],\n",
            "          [-2.2266, -2.4135, -2.3813,  ..., -2.3672, -2.2124, -2.1386],\n",
            "          [-2.3409, -2.4832, -2.4741,  ..., -2.4061, -2.3858, -2.2729]],\n",
            "\n",
            "         [[-2.7514, -2.8241, -2.8261,  ..., -2.5235, -2.4820, -2.4117],\n",
            "          [-2.7955, -2.9094, -2.9338,  ..., -2.7038, -2.7438, -2.6112],\n",
            "          [-2.8106, -2.9448, -2.9932,  ..., -2.7770, -2.8334, -2.6353],\n",
            "          ...,\n",
            "          [-3.0479, -3.1920, -3.1302,  ..., -2.9360, -3.1047, -2.9316],\n",
            "          [-2.9695, -3.0821, -3.0205,  ..., -2.7881, -2.9283, -2.8069],\n",
            "          [-2.5445, -2.5937, -2.5641,  ..., -2.6354, -2.7154, -2.6629]]],\n",
            "\n",
            "\n",
            "        [[[-2.4206, -2.3719, -2.3125,  ..., -1.9864, -2.0442, -2.1446],\n",
            "          [-2.5937, -2.5826, -2.5748,  ..., -2.1768, -2.1991, -2.2283],\n",
            "          [-2.6642, -2.6894, -2.6918,  ..., -2.2555, -2.2735, -2.2302],\n",
            "          ...,\n",
            "          [-2.5334, -2.4603, -2.4077,  ..., -2.1341, -2.2192, -2.2505],\n",
            "          [-2.6489, -2.5554, -2.5216,  ..., -2.2433, -2.2968, -2.2846],\n",
            "          [-2.7170, -2.6941, -2.7005,  ..., -2.5131, -2.5133, -2.4154]],\n",
            "\n",
            "         [[-2.7611, -2.9962, -2.9448,  ..., -2.5755, -2.5871, -2.5371],\n",
            "          [-3.0171, -3.0636, -3.0621,  ..., -2.6079, -2.5813, -2.4193],\n",
            "          [-2.8666, -2.9172, -2.8704,  ..., -2.6716, -2.6430, -2.4155],\n",
            "          ...,\n",
            "          [-2.4823, -2.4625, -2.5488,  ..., -2.3063, -2.3251, -2.2186],\n",
            "          [-2.4481, -2.4166, -2.4742,  ..., -2.3573, -2.3670, -2.2691],\n",
            "          [-2.6300, -2.5327, -2.4595,  ..., -2.4648, -2.4397, -2.3929]],\n",
            "\n",
            "         [[-2.2899, -2.0087, -2.1829,  ..., -2.8127, -2.8336, -2.4692],\n",
            "          [-2.3649, -2.1886, -2.3770,  ..., -3.0347, -2.9574, -2.5420],\n",
            "          [-2.2146, -2.0693, -2.2971,  ..., -2.9287, -2.8741, -2.4944],\n",
            "          ...,\n",
            "          [-2.5795, -2.3340, -2.1958,  ..., -2.4819, -2.4534, -2.2091],\n",
            "          [-2.4591, -2.3220, -2.2558,  ..., -2.5477, -2.5145, -2.2426],\n",
            "          [-2.3322, -2.3744, -2.3885,  ..., -2.6761, -2.5988, -2.3699]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9047, -2.9908, -2.7966,  ..., -2.5703, -2.5437, -2.8314],\n",
            "          [-2.9249, -2.7450, -2.7160,  ..., -2.8002, -2.7344, -2.7970],\n",
            "          [-2.8782, -2.5406, -2.4592,  ..., -2.9273, -2.8597, -2.8370],\n",
            "          ...,\n",
            "          [-2.8469, -2.8030, -2.8357,  ..., -3.0468, -3.0545, -2.9043],\n",
            "          [-2.7975, -2.7433, -2.8008,  ..., -2.9405, -2.9677, -2.8678],\n",
            "          [-2.8735, -2.8209, -2.8473,  ..., -2.7962, -2.8592, -2.7537]],\n",
            "\n",
            "         [[-2.7099, -2.5042, -2.5254,  ..., -2.4320, -2.4362, -2.4608],\n",
            "          [-2.4872, -2.4394, -2.5062,  ..., -2.6965, -2.6971, -2.7179],\n",
            "          [-2.3565, -2.2368, -2.3353,  ..., -2.4204, -2.4443, -2.6878],\n",
            "          ...,\n",
            "          [-2.5082, -2.4711, -2.4990,  ..., -2.2645, -2.2774, -2.6465],\n",
            "          [-2.6222, -2.5558, -2.5746,  ..., -2.3833, -2.3601, -2.6172],\n",
            "          [-2.6215, -2.4482, -2.4707,  ..., -2.4866, -2.4671, -2.5829]],\n",
            "\n",
            "         [[-2.2851, -2.4305, -2.4726,  ..., -2.7094, -2.7362, -2.8544],\n",
            "          [-2.3414, -2.3554, -2.1432,  ..., -2.5283, -2.5731, -2.7351],\n",
            "          [-2.4621, -2.4195, -2.1472,  ..., -2.4943, -2.5361, -2.6643],\n",
            "          ...,\n",
            "          [-2.6850, -2.6164, -2.5995,  ..., -2.7229, -2.6701, -2.7324],\n",
            "          [-2.6251, -2.6044, -2.5150,  ..., -2.7024, -2.6528, -2.7301],\n",
            "          [-2.6386, -2.6031, -2.5446,  ..., -2.5701, -2.5434, -2.5623]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.0222, -1.8788, -2.0113,  ..., -2.2272, -2.1732, -2.1005],\n",
            "          [-2.0595, -2.1134, -2.3353,  ..., -2.2284, -2.2546, -2.3190],\n",
            "          [-2.1262, -2.0790, -2.2703,  ..., -2.1565, -2.1438, -2.2150],\n",
            "          ...,\n",
            "          [-2.2857, -2.4504, -2.3677,  ..., -2.1919, -2.1513, -2.2215],\n",
            "          [-2.3964, -2.4598, -2.3976,  ..., -2.1732, -2.1946, -2.2872],\n",
            "          [-2.4468, -2.5212, -2.4992,  ..., -2.3574, -2.4239, -2.5131]],\n",
            "\n",
            "         [[-2.5812, -2.6585, -2.4147,  ..., -2.3485, -2.4298, -2.4951],\n",
            "          [-2.7610, -2.7922, -2.4747,  ..., -2.4686, -2.5525, -2.4360],\n",
            "          [-2.7002, -2.7603, -2.4550,  ..., -2.4648, -2.5795, -2.4301],\n",
            "          ...,\n",
            "          [-2.7669, -2.8069, -2.6667,  ..., -2.6907, -2.8182, -2.6517],\n",
            "          [-2.7817, -2.9332, -2.8636,  ..., -2.8237, -2.9099, -2.7607],\n",
            "          [-2.9088, -2.9939, -2.9279,  ..., -2.6096, -2.5538, -2.4734]],\n",
            "\n",
            "         [[-2.5719, -2.5549, -2.5522,  ..., -2.5549, -2.5492, -2.4243],\n",
            "          [-3.0438, -2.8285, -2.7684,  ..., -2.7637, -2.7540, -2.4018],\n",
            "          [-3.1369, -2.9526, -2.8990,  ..., -2.8447, -2.8441, -2.4994],\n",
            "          ...,\n",
            "          [-2.8941, -2.8864, -2.9485,  ..., -2.7364, -2.7062, -2.4925],\n",
            "          [-2.7772, -2.8051, -2.9352,  ..., -2.6974, -2.6255, -2.3944],\n",
            "          [-2.5101, -2.9407, -3.0598,  ..., -2.8694, -2.8138, -2.5581]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.1500, -3.2720, -3.2993,  ..., -3.2682, -3.1854, -3.2312],\n",
            "          [-3.1486, -3.3528, -3.4946,  ..., -3.4282, -3.3531, -3.6326],\n",
            "          [-3.1279, -3.0298, -3.0926,  ..., -3.3560, -3.3084, -3.6435],\n",
            "          ...,\n",
            "          [-2.6818, -2.3655, -2.3144,  ..., -2.4331, -2.5221, -3.0718],\n",
            "          [-2.6637, -2.3750, -2.3350,  ..., -2.5311, -2.6191, -3.1284],\n",
            "          [-2.4261, -2.1371, -2.1072,  ..., -2.4662, -2.5439, -2.8910]],\n",
            "\n",
            "         [[-2.3891, -2.1516, -2.2466,  ..., -2.3955, -2.4202, -2.3236],\n",
            "          [-2.7269, -2.4610, -2.4547,  ..., -2.5177, -2.5043, -2.4399],\n",
            "          [-2.6254, -2.3729, -2.4078,  ..., -2.5618, -2.5168, -2.4431],\n",
            "          ...,\n",
            "          [-2.7798, -2.7987, -2.8071,  ..., -2.8462, -2.7372, -2.3624],\n",
            "          [-2.7295, -2.7886, -2.7945,  ..., -2.8002, -2.6957, -2.4016],\n",
            "          [-2.4978, -2.4271, -2.3666,  ..., -2.5845, -2.5203, -2.4403]],\n",
            "\n",
            "         [[-2.7348, -2.8291, -2.8125,  ..., -2.7688, -2.7322, -2.7040],\n",
            "          [-2.9036, -2.8674, -2.7628,  ..., -2.5988, -2.6588, -2.6387],\n",
            "          [-3.0112, -3.0536, -2.9172,  ..., -2.6046, -2.6898, -2.6469],\n",
            "          ...,\n",
            "          [-2.5293, -2.6627, -2.6882,  ..., -2.8163, -2.8817, -2.8214],\n",
            "          [-2.4561, -2.5315, -2.5418,  ..., -2.8261, -2.8451, -2.7045],\n",
            "          [-2.5864, -2.6520, -2.7163,  ..., -2.7682, -2.7780, -2.6433]]],\n",
            "\n",
            "\n",
            "        [[[-2.4804, -2.8799, -2.9936,  ..., -2.3946, -2.3696, -2.3435],\n",
            "          [-2.5611, -3.0028, -3.2152,  ..., -2.4477, -2.4017, -2.2845],\n",
            "          [-2.5614, -2.8821, -3.0296,  ..., -2.4242, -2.3923, -2.2333],\n",
            "          ...,\n",
            "          [-2.6607, -2.6479, -2.6069,  ..., -2.4029, -2.3646, -2.4258],\n",
            "          [-2.7144, -2.6931, -2.6187,  ..., -2.4710, -2.4366, -2.4915],\n",
            "          [-2.7142, -2.7383, -2.7051,  ..., -2.3865, -2.3707, -2.4565]],\n",
            "\n",
            "         [[-2.0751, -2.1695, -2.1438,  ..., -2.3029, -2.3858, -2.2659],\n",
            "          [-2.2542, -2.7113, -2.7574,  ..., -2.5515, -2.6185, -2.4475],\n",
            "          [-2.3314, -2.8555, -2.9183,  ..., -2.6232, -2.6984, -2.5583],\n",
            "          ...,\n",
            "          [-1.9594, -2.1231, -2.2832,  ..., -3.0653, -3.0404, -2.9300],\n",
            "          [-1.9833, -2.1825, -2.2956,  ..., -2.9582, -2.9427, -2.9266],\n",
            "          [-2.4067, -2.5502, -2.5888,  ..., -2.8512, -2.8509, -2.7132]],\n",
            "\n",
            "         [[-3.3294, -3.2669, -3.3203,  ..., -2.8254, -2.8480, -2.5755],\n",
            "          [-3.5505, -3.4414, -3.4181,  ..., -3.0552, -2.9496, -2.7880],\n",
            "          [-3.4499, -3.3604, -3.4068,  ..., -3.0703, -2.9645, -2.7990],\n",
            "          ...,\n",
            "          [-2.7461, -2.8292, -2.9658,  ..., -2.7069, -2.6430, -2.3470],\n",
            "          [-2.7567, -2.9145, -3.0318,  ..., -2.6813, -2.6115, -2.3622],\n",
            "          [-2.5802, -2.8850, -2.9389,  ..., -2.8965, -2.8276, -2.6156]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8712, -2.9380, -3.0928,  ..., -2.6581, -2.6408, -2.8933],\n",
            "          [-2.7400, -2.7074, -2.8476,  ..., -2.5946, -2.7072, -2.7891],\n",
            "          [-2.8774, -2.8425, -2.9709,  ..., -2.7998, -2.8850, -2.8727],\n",
            "          ...,\n",
            "          [-2.9015, -2.7083, -2.6655,  ..., -2.6743, -2.6785, -3.0246],\n",
            "          [-2.7783, -2.6067, -2.5785,  ..., -2.5609, -2.5743, -2.9296],\n",
            "          [-2.5951, -2.4976, -2.4720,  ..., -2.5018, -2.5865, -2.7373]],\n",
            "\n",
            "         [[-2.2685, -1.9746, -1.8882,  ..., -2.6749, -2.7317, -2.6616],\n",
            "          [-2.4551, -2.0274, -1.8777,  ..., -2.3572, -2.3481, -2.4697],\n",
            "          [-2.3756, -1.9837, -1.8229,  ..., -2.2552, -2.2356, -2.3638],\n",
            "          ...,\n",
            "          [-2.7056, -2.6652, -2.5637,  ..., -2.3540, -2.2973, -2.1655],\n",
            "          [-2.7295, -2.7285, -2.6459,  ..., -2.4322, -2.3646, -2.1850],\n",
            "          [-2.5905, -2.3947, -2.3601,  ..., -2.3667, -2.3327, -2.1917]],\n",
            "\n",
            "         [[-2.3278, -2.2846, -2.2161,  ..., -2.1989, -2.2598, -2.5028],\n",
            "          [-2.2043, -2.1239, -2.0605,  ..., -2.3262, -2.3517, -2.3578],\n",
            "          [-2.2064, -2.2034, -2.1775,  ..., -2.4315, -2.4195, -2.3873],\n",
            "          ...,\n",
            "          [-2.3880, -2.6508, -2.6985,  ..., -2.7332, -2.8959, -2.8535],\n",
            "          [-2.4572, -2.6108, -2.6517,  ..., -2.7485, -2.8695, -2.7968],\n",
            "          [-2.4713, -2.5034, -2.5445,  ..., -2.6907, -2.8029, -2.6597]]],\n",
            "\n",
            "\n",
            "        [[[-2.2226, -2.2658, -2.3854,  ..., -2.5949, -2.5727, -2.3386],\n",
            "          [-2.2845, -2.3687, -2.4585,  ..., -2.6910, -2.6153, -2.4778],\n",
            "          [-2.3863, -2.4837, -2.6031,  ..., -2.6531, -2.4994, -2.3558],\n",
            "          ...,\n",
            "          [-2.4314, -2.4600, -2.5004,  ..., -2.6286, -2.5321, -2.4284],\n",
            "          [-2.5284, -2.4792, -2.5273,  ..., -2.6634, -2.6006, -2.5042],\n",
            "          [-2.7945, -2.7034, -2.7349,  ..., -2.5820, -2.5450, -2.5465]],\n",
            "\n",
            "         [[-2.8372, -2.7556, -2.5723,  ..., -2.2806, -2.2425, -2.3951],\n",
            "          [-2.8468, -2.8091, -2.5789,  ..., -2.2268, -2.1918, -2.4408],\n",
            "          [-2.8833, -2.9129, -2.6884,  ..., -2.4170, -2.4131, -2.5811],\n",
            "          ...,\n",
            "          [-2.4720, -2.4711, -2.3266,  ..., -2.2217, -2.3136, -2.4073],\n",
            "          [-2.4378, -2.4706, -2.3623,  ..., -2.3578, -2.4286, -2.4766],\n",
            "          [-2.5039, -2.4778, -2.4748,  ..., -2.6572, -2.6507, -2.5737]],\n",
            "\n",
            "         [[-2.5048, -2.2945, -2.2775,  ..., -2.6352, -2.5263, -2.3579],\n",
            "          [-2.7824, -2.4772, -2.4155,  ..., -2.5796, -2.5074, -2.2923],\n",
            "          [-2.9031, -2.6344, -2.5904,  ..., -2.9358, -2.8457, -2.4777],\n",
            "          ...,\n",
            "          [-2.7425, -2.5145, -2.4536,  ..., -2.1373, -2.3417, -2.0534],\n",
            "          [-2.7926, -2.5189, -2.4332,  ..., -2.1960, -2.3618, -2.0927],\n",
            "          [-2.6776, -2.5663, -2.4851,  ..., -2.1581, -2.1713, -2.0398]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.1039, -3.2420, -3.2792,  ..., -2.6172, -2.6791, -2.9143],\n",
            "          [-3.0132, -3.5227, -3.5865,  ..., -3.0837, -3.1582, -3.1462],\n",
            "          [-2.9254, -3.3466, -3.4011,  ..., -3.0049, -3.1471, -3.1086],\n",
            "          ...,\n",
            "          [-2.9293, -3.2187, -3.2884,  ..., -3.3397, -3.2970, -3.0408],\n",
            "          [-2.8172, -3.1033, -3.1797,  ..., -3.1792, -3.1747, -2.9857],\n",
            "          [-2.6757, -2.7907, -2.8270,  ..., -3.0484, -3.0067, -2.9584]],\n",
            "\n",
            "         [[-2.2056, -2.2829, -2.3629,  ..., -2.2182, -2.1506, -2.3821],\n",
            "          [-2.3217, -2.3819, -2.4220,  ..., -2.0844, -2.1317, -2.4505],\n",
            "          [-2.3822, -2.3221, -2.3178,  ..., -2.0140, -2.0562, -2.5030],\n",
            "          ...,\n",
            "          [-2.8197, -2.7943, -2.8656,  ..., -2.6526, -2.6034, -2.6609],\n",
            "          [-2.8505, -2.8848, -2.9270,  ..., -2.5473, -2.5103, -2.5882],\n",
            "          [-2.9468, -2.9590, -2.9941,  ..., -2.5045, -2.4662, -2.3981]],\n",
            "\n",
            "         [[-2.5540, -2.4672, -2.4408,  ..., -2.5277, -2.6238, -2.4998],\n",
            "          [-2.5511, -2.4065, -2.3298,  ..., -2.5567, -2.6699, -2.3482],\n",
            "          [-2.5477, -2.3026, -2.2354,  ..., -2.6801, -2.8131, -2.4473],\n",
            "          ...,\n",
            "          [-2.4152, -2.0838, -2.0269,  ..., -2.4314, -2.5972, -2.4711],\n",
            "          [-2.3570, -2.0506, -1.9684,  ..., -2.4273, -2.5817, -2.4014],\n",
            "          [-2.3449, -2.2072, -2.1745,  ..., -2.3499, -2.4159, -2.3251]]]],\n",
            "       device='cuda:0')\n",
            "tensor([[[[-2.0674e-02, -9.7830e-02, -1.1190e-01,  ..., -2.1838e-01,\n",
            "           -9.8731e-02,  1.0445e-01],\n",
            "          [-5.3919e-02,  3.8938e-01,  1.5718e-01,  ...,  1.3323e-01,\n",
            "            8.1466e-02,  1.3387e-01],\n",
            "          [-1.3780e-01, -4.0782e-01, -9.8882e-02,  ..., -8.7931e-02,\n",
            "           -8.2130e-02,  7.4275e-02],\n",
            "          ...,\n",
            "          [ 2.8446e-02,  7.0758e-02,  6.4711e-02,  ...,  1.8624e-01,\n",
            "           -1.6321e-02, -1.3522e-01],\n",
            "          [-5.3850e-02, -1.6918e-01, -9.1555e-02,  ..., -4.0627e-01,\n",
            "           -6.6367e-02,  1.1055e-02],\n",
            "          [-8.8566e-02,  1.7424e-01,  1.0186e-01,  ...,  1.9034e-01,\n",
            "            3.5980e-02,  3.1703e-01]],\n",
            "\n",
            "         [[ 8.5973e-02,  1.4061e-01,  8.8341e-02,  ...,  6.2915e-02,\n",
            "           -1.5984e-03,  2.8695e-02],\n",
            "          [-7.2119e-02, -1.7362e-01,  3.0261e-02,  ..., -2.3560e-01,\n",
            "           -3.7140e-02, -1.5029e-01],\n",
            "          [-2.1267e-02, -4.3725e-02,  1.7108e-01,  ...,  7.2400e-02,\n",
            "           -1.1771e-01, -1.1530e-03],\n",
            "          ...,\n",
            "          [-2.7765e-03, -4.6406e-01,  3.1387e-02,  ..., -4.6405e-01,\n",
            "            6.4149e-02, -2.5902e-01],\n",
            "          [ 1.4890e-01, -6.4704e-02, -2.1268e-02,  ...,  1.8533e-01,\n",
            "            2.0415e-02,  9.3391e-02],\n",
            "          [-1.9830e-02, -3.2591e-01, -2.1959e-03,  ..., -5.0282e-01,\n",
            "            4.1449e-02, -1.2477e-01]],\n",
            "\n",
            "         [[-8.7824e-03,  4.1572e-02, -4.8127e-02,  ...,  4.0876e-02,\n",
            "           -5.5696e-02,  9.0333e-02],\n",
            "          [ 2.8662e-02,  5.3659e-01,  5.9680e-04,  ...,  5.2326e-01,\n",
            "            6.7200e-02,  2.6290e-01],\n",
            "          [-1.7892e-01, -2.2091e-02,  1.1100e-01,  ...,  4.9471e-02,\n",
            "           -9.3623e-02,  2.9920e-02],\n",
            "          ...,\n",
            "          [-1.2194e-01,  4.9644e-01,  1.0546e-02,  ...,  2.4235e-01,\n",
            "           -4.0816e-02,  1.7304e-01],\n",
            "          [ 8.4291e-02, -1.4874e-02, -5.0719e-02,  ...,  2.8363e-02,\n",
            "            6.8971e-02,  5.4295e-02],\n",
            "          [ 6.0725e-03,  4.0844e-01, -3.1050e-02,  ...,  7.5657e-01,\n",
            "            1.6301e-02,  2.2748e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4080e-02,  5.3116e-02, -1.4262e-01,  ...,  5.5970e-02,\n",
            "           -6.0010e-03,  8.3729e-02],\n",
            "          [ 1.3791e-01, -1.6147e-01,  2.1476e-01,  ..., -1.4886e-01,\n",
            "            2.3391e-01,  6.0109e-02],\n",
            "          [-3.1216e-02,  1.8018e-01, -6.8806e-02,  ...,  9.2910e-02,\n",
            "            9.4122e-02, -1.8125e-02],\n",
            "          ...,\n",
            "          [ 1.7492e-01, -2.1775e-01,  1.1594e-01,  ..., -2.5571e-01,\n",
            "            4.9353e-01, -1.7045e-01],\n",
            "          [-7.8092e-02, -1.1827e-01,  2.8399e-02,  ...,  2.5902e-01,\n",
            "            5.9811e-03, -9.4073e-02],\n",
            "          [ 2.0470e-01, -2.5321e-01,  1.2204e-01,  ..., -4.0285e-01,\n",
            "            2.9266e-01, -7.4169e-02]],\n",
            "\n",
            "         [[ 9.7011e-02, -4.6106e-02,  2.4536e-01,  ...,  1.1993e-01,\n",
            "            9.6267e-02,  9.3792e-02],\n",
            "          [ 1.8718e-02,  4.8648e-01, -1.2657e-01,  ...,  5.0685e-01,\n",
            "           -4.5187e-02, -6.9907e-03],\n",
            "          [ 2.2739e-01,  1.7652e-01,  2.0722e-01,  ...,  2.2649e-01,\n",
            "            7.6155e-02,  2.9269e-02],\n",
            "          ...,\n",
            "          [ 2.6817e-03,  2.6927e-01, -5.6528e-02,  ...,  8.1871e-01,\n",
            "            4.6429e-02,  1.0190e-01],\n",
            "          [ 3.9761e-02,  2.8185e-01,  5.4888e-02,  ...,  2.3734e-02,\n",
            "            3.8360e-02,  5.0287e-02],\n",
            "          [-5.6269e-02, -1.8440e-01, -4.8080e-02,  ..., -2.2827e-01,\n",
            "           -1.9321e-01, -1.3208e-01]],\n",
            "\n",
            "         [[-1.5560e-02,  2.7593e-01,  1.6701e-01,  ...,  2.4831e-01,\n",
            "           -4.8183e-02, -4.4521e-02],\n",
            "          [-1.1719e-01, -2.9281e-01, -1.6663e-01,  ..., -4.6578e-01,\n",
            "           -6.9412e-02, -3.0382e-01],\n",
            "          [-1.3422e-01,  4.5420e-02,  6.0688e-02,  ...,  5.5072e-02,\n",
            "           -2.5640e-02, -1.9082e-02],\n",
            "          ...,\n",
            "          [-2.3154e-01, -2.5419e-01, -8.8626e-02,  ..., -4.2823e-01,\n",
            "           -3.4219e-01, -1.6522e-01],\n",
            "          [-1.3094e-01,  1.1993e-01, -1.9737e-02,  ...,  1.6745e-01,\n",
            "           -2.2179e-01,  5.2174e-02],\n",
            "          [-5.1519e-02, -2.2672e-01, -5.9352e-02,  ..., -3.9785e-01,\n",
            "            1.2950e-01, -2.8174e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.2508e-02, -1.6949e-01, -6.5669e-02,  ..., -8.3907e-02,\n",
            "           -3.6281e-02, -3.4097e-02],\n",
            "          [ 2.2534e-02, -1.4489e-01, -3.1409e-01,  ...,  3.9348e-01,\n",
            "            2.0615e-01,  8.7064e-03],\n",
            "          [-7.1552e-02, -2.4975e-01, -1.2299e-01,  ..., -1.7751e-01,\n",
            "           -4.7818e-02, -2.0996e-01],\n",
            "          ...,\n",
            "          [ 4.1492e-02, -8.5546e-02, -3.2608e-02,  ..., -1.7132e-01,\n",
            "            7.6917e-02, -4.2753e-02],\n",
            "          [ 2.5665e-03, -1.7911e-01, -1.6135e-01,  ..., -6.4521e-01,\n",
            "           -1.2676e-01,  7.5947e-02],\n",
            "          [-1.8163e-01,  1.7924e-01,  7.4524e-02,  ...,  1.3207e-01,\n",
            "           -2.2009e-01,  2.7976e-01]],\n",
            "\n",
            "         [[ 2.1755e-01,  2.6711e-01,  1.0440e-01,  ...,  1.1375e-01,\n",
            "           -5.7264e-02,  3.8575e-03],\n",
            "          [ 9.4102e-02, -7.8914e-03, -1.3117e-01,  ..., -5.0100e-01,\n",
            "            1.4389e-01, -3.4512e-01],\n",
            "          [ 2.4045e-03,  1.3363e-01, -1.0362e-01,  ..., -5.8684e-02,\n",
            "            1.5952e-01,  1.6767e-01],\n",
            "          ...,\n",
            "          [ 3.1548e-01, -3.1569e-01,  2.4725e-02,  ..., -7.8457e-01,\n",
            "            1.3661e-01, -1.7862e-02],\n",
            "          [ 2.0593e-01,  9.6854e-02, -5.0135e-03,  ...,  1.6406e-01,\n",
            "            2.8669e-01,  9.8167e-02],\n",
            "          [ 1.1311e-01, -2.3156e-01,  1.2185e-01,  ..., -1.3498e-01,\n",
            "            7.2054e-02, -1.6786e-02]],\n",
            "\n",
            "         [[-4.1285e-02, -5.7187e-02, -2.9522e-03,  ..., -3.1329e-02,\n",
            "           -6.3074e-02, -1.0205e-02],\n",
            "          [-8.2155e-02,  6.2088e-01, -2.8160e-01,  ...,  9.2328e-02,\n",
            "            1.2108e-01,  7.5607e-02],\n",
            "          [-1.1098e-01, -2.2258e-01, -5.1774e-01,  ...,  2.5353e-01,\n",
            "            1.5143e-01,  1.1021e-01],\n",
            "          ...,\n",
            "          [-1.4719e-01,  4.1208e-01,  1.6703e-02,  ...,  5.1573e-01,\n",
            "           -6.6532e-02, -1.7027e-03],\n",
            "          [ 4.0961e-02, -1.4323e-02, -1.9273e-01,  ..., -4.5708e-02,\n",
            "            1.8830e-01,  2.4151e-01],\n",
            "          [ 8.5408e-02,  5.0207e-01,  2.8120e-02,  ...,  5.0676e-01,\n",
            "           -1.0543e-01,  5.2914e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.5556e-02,  1.7062e-01, -1.3675e-01,  ...,  1.3465e-01,\n",
            "            3.8133e-02, -6.4597e-02],\n",
            "          [ 2.6512e-01,  7.3327e-01, -2.4659e-01,  ..., -3.3422e-01,\n",
            "            7.7418e-02, -1.5899e-01],\n",
            "          [-1.9589e-01,  5.2192e-01,  4.5048e-01,  ...,  3.0044e-01,\n",
            "           -1.1882e-01,  1.4104e-01],\n",
            "          ...,\n",
            "          [ 6.9917e-02, -1.4487e-01,  3.5650e-03,  ...,  1.7460e-01,\n",
            "            8.9050e-02, -2.4025e-01],\n",
            "          [-1.6021e-01,  1.0634e-01,  7.2508e-02,  ...,  1.4882e-01,\n",
            "           -1.2368e-01,  2.3288e-01],\n",
            "          [ 2.3891e-01, -1.7641e-01, -4.1617e-02,  ..., -3.3077e-01,\n",
            "            1.1176e-01, -9.9960e-02]],\n",
            "\n",
            "         [[ 1.4254e-01, -2.9002e-02,  9.1730e-02,  ...,  4.9678e-02,\n",
            "            2.5700e-02, -2.7477e-03],\n",
            "          [ 1.9241e-01,  8.5389e-01, -8.6708e-04,  ...,  6.1970e-01,\n",
            "           -6.7567e-02,  4.4426e-02],\n",
            "          [ 9.4011e-02, -8.6558e-01,  7.1216e-01,  ..., -3.6109e-01,\n",
            "            3.5766e-02, -5.3207e-02],\n",
            "          ...,\n",
            "          [-3.5588e-02,  3.7320e-01, -6.5095e-02,  ...,  3.4602e-01,\n",
            "           -2.8549e-01,  7.1542e-02],\n",
            "          [-2.6009e-03, -1.5530e-01,  1.2464e-01,  ..., -2.6934e-02,\n",
            "            1.4360e-01, -1.0419e-01],\n",
            "          [-4.7840e-03,  4.8480e-02,  1.4204e-01,  ..., -4.7090e-02,\n",
            "           -1.5132e-01, -4.5649e-02]],\n",
            "\n",
            "         [[-1.0589e-01,  3.2247e-01,  5.5722e-02,  ...,  1.3981e-01,\n",
            "           -8.5855e-02,  3.3321e-02],\n",
            "          [-1.1969e-01, -3.5134e-01, -4.4567e-01,  ..., -5.0547e-01,\n",
            "            1.9982e-02, -6.4516e-02],\n",
            "          [-5.8433e-02,  5.5351e-01, -1.0934e+00,  ...,  3.7949e-01,\n",
            "           -3.7792e-02,  6.3473e-02],\n",
            "          ...,\n",
            "          [-2.3231e-01, -3.7472e-01, -8.4817e-02,  ..., -5.1338e-01,\n",
            "           -8.8655e-02, -1.6365e-01],\n",
            "          [-2.5714e-01,  3.7891e-01, -2.7605e-01,  ...,  1.8703e-01,\n",
            "           -2.3864e-01,  3.0715e-01],\n",
            "          [-7.0419e-02, -1.9504e-01, -6.5858e-02,  ..., -3.2766e-01,\n",
            "            2.2833e-02, -1.3117e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.5581e-01, -2.3302e-01, -7.2875e-02,  ..., -2.7037e-02,\n",
            "           -1.0864e-01,  1.2473e-01],\n",
            "          [ 3.0192e-01,  5.8981e-02, -1.6221e-01,  ...,  1.6324e-01,\n",
            "            9.9923e-02,  1.0614e-01],\n",
            "          [-2.4301e-01, -3.2368e-01,  1.3506e-01,  ..., -1.6741e-01,\n",
            "           -1.3371e-01,  1.2303e-01],\n",
            "          ...,\n",
            "          [ 1.6525e-01,  1.5487e-01,  1.7492e-03,  ..., -2.4505e-01,\n",
            "           -8.5858e-02,  2.0466e-01],\n",
            "          [-8.2123e-02,  2.3865e-02, -9.7844e-02,  ..., -4.1550e-01,\n",
            "           -7.7291e-02,  7.9493e-02],\n",
            "          [ 9.7816e-02,  1.9249e-01,  6.7610e-02,  ...,  2.0919e-01,\n",
            "            8.4104e-02,  3.9523e-01]],\n",
            "\n",
            "         [[-3.8821e-02,  1.3807e-01,  1.2542e-01,  ..., -1.2558e-01,\n",
            "           -3.3028e-03, -1.3443e-02],\n",
            "          [-2.3078e-01, -2.2609e-01,  5.0088e-02,  ..., -4.3012e-01,\n",
            "           -1.6193e-02, -1.4189e-01],\n",
            "          [-1.3812e-01,  6.7273e-02, -2.0035e-02,  ..., -1.7552e-02,\n",
            "            1.6686e-03, -1.6320e-02],\n",
            "          ...,\n",
            "          [-1.0820e-01, -3.6536e-01, -6.2077e-02,  ..., -9.5388e-01,\n",
            "           -2.1393e-02, -4.2912e-01],\n",
            "          [-3.3166e-02, -1.1020e-01, -1.0309e-02,  ...,  1.8094e-02,\n",
            "           -6.5571e-02, -7.4525e-02],\n",
            "          [-1.8185e-02, -2.7403e-01,  5.2245e-02,  ..., -4.6811e-01,\n",
            "           -2.4237e-03, -1.0949e-01]],\n",
            "\n",
            "         [[-1.8981e-01, -7.3985e-03,  4.5400e-02,  ..., -5.5593e-02,\n",
            "           -5.1092e-02,  1.2233e-02],\n",
            "          [ 5.7777e-02, -9.8309e-02, -1.1376e-01,  ...,  4.3345e-01,\n",
            "            7.3057e-03,  8.4762e-02],\n",
            "          [-2.5683e-01,  8.6712e-02, -1.9468e-01,  ..., -1.0299e-02,\n",
            "           -1.5507e-02,  2.1421e-02],\n",
            "          ...,\n",
            "          [-4.5990e-02,  4.1620e-01, -5.9615e-02,  ...,  8.5869e-01,\n",
            "            8.1934e-02,  5.0796e-01],\n",
            "          [-7.8434e-02, -4.7848e-02, -1.0766e-01,  ..., -1.0723e-02,\n",
            "           -6.2091e-02,  1.4946e-01],\n",
            "          [-2.6009e-02,  1.4138e-01,  7.4287e-02,  ...,  4.4600e-01,\n",
            "            2.6610e-02,  2.0859e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2834e-01,  1.0225e-01, -1.6832e-01,  ..., -1.6355e-01,\n",
            "            1.5378e-02, -4.6474e-04],\n",
            "          [-3.0957e-02,  1.7408e-01,  2.5375e-01,  ...,  3.9940e-02,\n",
            "            2.0651e-01, -7.4250e-02],\n",
            "          [-6.1222e-02,  4.9343e-01,  2.7899e-01,  ..., -3.9862e-02,\n",
            "           -2.0596e-02, -4.3006e-02],\n",
            "          ...,\n",
            "          [ 1.8537e-01, -2.1974e-01,  2.4128e-01,  ..., -1.7087e-02,\n",
            "            2.1602e-01, -3.6363e-02],\n",
            "          [ 2.3335e-02,  7.7133e-02,  4.2771e-02,  ..., -1.9646e-02,\n",
            "            1.6907e-01,  2.8084e-02],\n",
            "          [ 8.3537e-02, -2.0970e-01,  5.5259e-02,  ..., -4.4179e-01,\n",
            "            1.6816e-01, -2.2632e-01]],\n",
            "\n",
            "         [[ 1.6187e-01,  2.2943e-01,  1.2343e-01,  ...,  3.0367e-01,\n",
            "            1.2256e-02,  1.2062e-01],\n",
            "          [ 2.1379e-01,  7.0029e-01,  1.3015e-01,  ...,  2.7264e-02,\n",
            "           -9.6506e-02, -5.3912e-02],\n",
            "          [ 3.4664e-01, -4.4968e-01,  3.4970e-01,  ...,  2.7151e-01,\n",
            "           -3.0269e-02,  9.2990e-02],\n",
            "          ...,\n",
            "          [-9.4615e-03,  6.0321e-02, -9.7150e-03,  ...,  5.8539e-01,\n",
            "           -9.0710e-02,  2.0508e-01],\n",
            "          [ 4.9103e-02,  6.7847e-02,  5.0415e-03,  ...,  5.4883e-02,\n",
            "            1.8278e-01, -1.5789e-01],\n",
            "          [ 2.3770e-02, -7.6672e-02,  3.9516e-02,  ..., -6.1570e-03,\n",
            "           -1.3514e-01, -7.1450e-02]],\n",
            "\n",
            "         [[ 7.4836e-02,  1.1822e-01,  1.0194e-01,  ...,  1.3211e-01,\n",
            "            3.2378e-02,  2.1168e-02],\n",
            "          [-7.3385e-02, -9.0351e-02, -3.3308e-01,  ..., -2.2264e-01,\n",
            "           -1.3150e-01, -2.0381e-01],\n",
            "          [-2.3179e-01,  2.8071e-01, -3.0617e-01,  ..., -2.5690e-03,\n",
            "           -9.9583e-02,  5.4703e-02],\n",
            "          ...,\n",
            "          [-7.1339e-02, -3.5841e-01, -1.3758e-01,  ..., -2.7188e-01,\n",
            "           -1.2248e-01, -1.5775e-01],\n",
            "          [-6.6536e-03,  2.3055e-01, -1.8243e-01,  ...,  1.0576e-01,\n",
            "           -2.1109e-01,  1.0200e-01],\n",
            "          [-1.0776e-01, -1.1709e-01, -1.0247e-01,  ..., -1.1896e-01,\n",
            "           -8.9963e-03, -1.6090e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.4127e-01, -1.0157e-01,  2.5307e-01,  ...,  1.5494e-02,\n",
            "           -1.0273e-01,  1.2718e-01],\n",
            "          [ 6.5947e-01,  3.2284e-03, -4.2268e-01,  ...,  4.0933e-01,\n",
            "            3.1282e-01,  2.5971e-03],\n",
            "          [-4.1871e-01, -5.0049e-01,  5.9540e-03,  ..., -1.4286e-01,\n",
            "            2.9827e-02, -1.7919e-01],\n",
            "          ...,\n",
            "          [ 8.2439e-02, -1.8371e-01,  9.3439e-04,  ..., -3.5267e-03,\n",
            "            6.5710e-02,  1.9059e-01],\n",
            "          [-5.9399e-02, -1.4591e-01, -1.2881e-01,  ..., -1.2179e-01,\n",
            "           -7.1248e-02,  7.6014e-02],\n",
            "          [-2.4965e-02,  1.5700e-01,  1.2403e-01,  ..., -4.1104e-02,\n",
            "            1.0487e-01,  6.1207e-02]],\n",
            "\n",
            "         [[ 1.7983e-02, -1.0883e-01,  3.7666e-01,  ..., -1.1211e-01,\n",
            "           -3.8261e-02, -4.8875e-02],\n",
            "          [-1.1619e-01, -5.0337e-01, -1.5427e-01,  ..., -1.6948e-01,\n",
            "           -2.2714e-01, -1.8268e-01],\n",
            "          [ 3.6442e-01, -1.5276e-01, -2.2673e-01,  ...,  2.1131e-01,\n",
            "           -1.0071e-01,  6.4832e-02],\n",
            "          ...,\n",
            "          [ 1.5008e-01, -2.5326e-01,  4.8506e-02,  ..., -6.7826e-01,\n",
            "            2.3145e-02, -1.9273e-01],\n",
            "          [ 1.5950e-01, -9.7563e-02, -7.2252e-02,  ..., -2.4668e-02,\n",
            "           -1.7873e-02, -6.8239e-03],\n",
            "          [ 7.5811e-02, -2.8259e-01,  1.2758e-01,  ..., -3.6689e-01,\n",
            "            4.3979e-02, -1.4918e-01]],\n",
            "\n",
            "         [[-4.6387e-01, -7.2499e-02, -6.7588e-02,  ..., -1.2575e-02,\n",
            "           -1.0207e-01,  1.6111e-02],\n",
            "          [ 1.0252e-02, -1.0358e-01, -2.8540e-01,  ...,  5.6971e-01,\n",
            "           -1.6302e-01,  1.4601e-01],\n",
            "          [-9.3424e-02,  7.3393e-02,  4.0836e-02,  ...,  7.6522e-03,\n",
            "           -2.4894e-01,  3.6491e-02],\n",
            "          ...,\n",
            "          [-6.2922e-02,  3.3792e-01,  6.7098e-02,  ...,  6.3646e-01,\n",
            "            5.1550e-02,  1.9775e-01],\n",
            "          [-2.0888e-02, -8.5923e-03, -2.4587e-01,  ..., -7.5029e-02,\n",
            "           -8.0118e-02, -1.7052e-02],\n",
            "          [ 8.0700e-02,  4.6378e-01,  3.6914e-02,  ...,  2.6641e-01,\n",
            "            1.0618e-01,  1.6133e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.9017e-01, -3.7420e-02,  1.4947e-01,  ..., -5.3004e-02,\n",
            "            1.2185e-02,  1.7371e-02],\n",
            "          [ 1.3350e-01, -3.4191e-01,  4.4044e-01,  ..., -4.3158e-01,\n",
            "            2.4335e-01,  4.9987e-02],\n",
            "          [-3.5711e-01,  3.6016e-01,  2.6192e-01,  ...,  2.5823e-01,\n",
            "           -2.3367e-01,  4.0587e-02],\n",
            "          ...,\n",
            "          [ 1.4863e-01,  9.1218e-03,  5.2673e-02,  ..., -4.2649e-01,\n",
            "            2.4965e-01,  2.4486e-02],\n",
            "          [-1.7243e-01, -7.3608e-02,  1.1590e-01,  ...,  1.6617e-02,\n",
            "           -2.2156e-02, -8.5894e-02],\n",
            "          [ 2.5261e-01, -2.9289e-01,  4.0285e-02,  ..., -1.4946e-01,\n",
            "            9.0073e-02, -4.7106e-02]],\n",
            "\n",
            "         [[ 1.9602e-01, -7.8323e-01,  1.0329e+00,  ...,  2.2072e-01,\n",
            "            2.7158e-02,  7.0050e-02],\n",
            "          [-2.4204e-01,  1.6186e+00,  2.7365e-01,  ...,  5.1031e-02,\n",
            "            1.2956e-01, -2.2134e-02],\n",
            "          [ 4.5952e-01, -3.4413e-01,  4.8716e-01,  ...,  1.4342e-01,\n",
            "            5.1072e-02, -1.2744e-02],\n",
            "          ...,\n",
            "          [-1.6690e-01,  5.0402e-01,  3.0884e-02,  ...,  8.7098e-02,\n",
            "           -8.4918e-02, -1.2518e-01],\n",
            "          [ 7.2361e-02,  2.3107e-02,  2.1494e-01,  ...,  2.8918e-01,\n",
            "           -6.7333e-02,  1.2160e-01],\n",
            "          [-3.0094e-02, -4.7912e-02,  9.7618e-02,  ..., -5.4208e-02,\n",
            "           -1.6908e-02, -7.7321e-02]],\n",
            "\n",
            "         [[-2.3272e-01,  5.4887e-01, -4.8337e-01,  ...,  8.6888e-02,\n",
            "            1.3561e-02,  2.0034e-02],\n",
            "          [-5.0503e-01,  1.4985e+00, -4.6502e-01,  ..., -3.3550e-01,\n",
            "           -1.9464e-01, -1.6166e-01],\n",
            "          [-4.0168e-01,  3.6336e-01, -4.7583e-01,  ...,  1.8616e-01,\n",
            "            5.7173e-03, -1.6509e-01],\n",
            "          ...,\n",
            "          [-3.3159e-01, -2.6128e-01, -1.5332e-01,  ..., -5.1141e-01,\n",
            "           -4.6530e-02, -4.3609e-01],\n",
            "          [-1.4410e-01,  2.2250e-01, -3.4086e-01,  ...,  2.1612e-01,\n",
            "           -3.2835e-02,  4.2912e-02],\n",
            "          [-2.2254e-02, -1.4971e-01, -5.2628e-02,  ..., -1.2071e-01,\n",
            "           -6.2931e-02, -9.2512e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.3242e-01, -2.0745e-01, -8.7484e-02,  ...,  1.4042e-01,\n",
            "           -4.8793e-02, -5.2035e-02],\n",
            "          [ 1.5304e-01, -2.7040e-01, -3.0473e-02,  ...,  5.3022e-01,\n",
            "            1.4530e-01, -1.0417e-01],\n",
            "          [-7.0513e-02, -2.7332e-01, -8.9708e-02,  ...,  1.7690e-01,\n",
            "           -2.9947e-01,  3.4076e-02],\n",
            "          ...,\n",
            "          [ 5.5095e-02, -4.0022e-02,  1.1661e-02,  ..., -2.3695e-01,\n",
            "            3.1548e-02,  1.5545e-01],\n",
            "          [-6.6714e-02, -9.2377e-03, -1.4954e-01,  ..., -1.6129e-01,\n",
            "           -4.5565e-02, -7.9767e-03],\n",
            "          [ 4.8708e-02,  7.8175e-02,  3.9768e-02,  ...,  1.6779e-01,\n",
            "            5.0313e-02,  2.3773e-01]],\n",
            "\n",
            "         [[-7.0593e-03,  1.6108e-01,  1.6539e-01,  ...,  8.9975e-02,\n",
            "            3.0363e-02,  7.7275e-02],\n",
            "          [ 1.9430e-01, -4.7543e-01,  5.6485e-02,  ..., -2.9411e-01,\n",
            "           -1.3524e-02, -2.1893e-02],\n",
            "          [-7.1272e-02,  4.8896e-02,  4.0247e-02,  ..., -5.7065e-04,\n",
            "            1.7437e-01,  9.6651e-02],\n",
            "          ...,\n",
            "          [-6.0279e-02, -4.1735e-01,  9.7040e-05,  ..., -5.2065e-01,\n",
            "            2.7487e-02, -2.4419e-01],\n",
            "          [ 7.9195e-04, -5.6042e-02, -7.5530e-03,  ...,  2.4773e-03,\n",
            "           -4.1130e-02, -3.5793e-02],\n",
            "          [-1.6138e-02, -1.9092e-01,  2.4560e-02,  ..., -2.6209e-01,\n",
            "           -6.1098e-02, -7.8828e-02]],\n",
            "\n",
            "         [[-2.7096e-01, -2.5276e-01,  4.9708e-02,  ..., -7.9881e-03,\n",
            "           -1.4025e-02, -3.7815e-02],\n",
            "          [-4.1669e-02,  1.8669e-01,  1.3847e-02,  ...,  3.7046e-01,\n",
            "            2.1292e-02, -2.6466e-02],\n",
            "          [-1.8510e-01,  3.7346e-02, -9.5342e-02,  ..., -1.8598e-01,\n",
            "           -1.0742e-01, -6.2364e-02],\n",
            "          ...,\n",
            "          [-1.2379e-01,  4.0014e-01, -8.3564e-02,  ...,  6.1682e-01,\n",
            "            5.1999e-02,  2.6463e-01],\n",
            "          [-2.9650e-02, -8.5392e-02, -3.7787e-02,  ..., -7.3897e-02,\n",
            "           -2.4979e-02,  1.2791e-02],\n",
            "          [ 2.8018e-02,  6.9332e-02,  5.6890e-03,  ...,  2.5597e-01,\n",
            "           -2.7632e-02,  1.0568e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5085e-01, -6.2926e-02, -9.6004e-02,  ..., -7.5795e-02,\n",
            "           -1.6941e-02, -1.9753e-02],\n",
            "          [ 2.0643e-02,  8.2428e-02,  2.1722e-01,  ..., -7.5881e-02,\n",
            "            3.5098e-01,  1.9739e-01],\n",
            "          [ 6.6314e-02,  4.4076e-02, -5.2690e-02,  ..., -2.0545e-01,\n",
            "           -2.3538e-01,  2.3212e-02],\n",
            "          ...,\n",
            "          [ 1.7979e-01, -3.6533e-02,  1.4929e-01,  ..., -1.2605e-01,\n",
            "            1.2232e-01,  1.4650e-02],\n",
            "          [-1.1282e-03, -9.2267e-02,  2.2393e-02,  ..., -1.0241e-01,\n",
            "            8.7610e-02, -6.5161e-02],\n",
            "          [ 4.3809e-02, -3.2122e-02, -3.5754e-02,  ..., -1.5904e-01,\n",
            "            1.0075e-01, -1.5816e-01]],\n",
            "\n",
            "         [[ 1.3935e-01,  2.0441e-01,  1.1632e-01,  ...,  1.6348e-01,\n",
            "            4.8878e-02,  5.2719e-02],\n",
            "          [ 1.7278e-03,  6.4818e-01,  4.9556e-02,  ..., -1.8035e-02,\n",
            "           -2.7226e-01,  1.9119e-01],\n",
            "          [ 3.2881e-01, -3.2174e-01,  2.5376e-01,  ...,  9.4301e-02,\n",
            "            2.4159e-01,  7.6458e-02],\n",
            "          ...,\n",
            "          [-5.0641e-02,  5.7323e-02, -1.4251e-01,  ...,  2.4796e-01,\n",
            "           -6.0315e-02,  7.1761e-02],\n",
            "          [-2.3773e-02,  4.5918e-02, -2.7554e-02,  ...,  7.1531e-02,\n",
            "            6.0697e-02, -7.7959e-02],\n",
            "          [-2.6974e-02, -2.6832e-02,  4.9576e-02,  ...,  4.7170e-02,\n",
            "           -5.4152e-02, -5.1420e-02]],\n",
            "\n",
            "         [[-7.7794e-03,  1.2911e-01, -1.1468e-02,  ...,  3.1309e-01,\n",
            "            7.5105e-02, -2.0034e-03],\n",
            "          [-3.7035e-01,  2.2430e-02, -8.2083e-02,  ..., -2.0139e-01,\n",
            "           -3.1786e-01, -4.8732e-02],\n",
            "          [-2.1404e-01,  1.2898e-01, -4.0733e-01,  ...,  3.6060e-01,\n",
            "           -5.5248e-02,  8.0720e-02],\n",
            "          ...,\n",
            "          [-8.4580e-02, -6.6555e-02, -1.0808e-01,  ..., -1.6244e-01,\n",
            "           -1.1089e-01, -1.5058e-01],\n",
            "          [-4.5302e-02,  1.5693e-01, -1.9800e-01,  ...,  1.5498e-02,\n",
            "           -1.3404e-01,  9.9684e-02],\n",
            "          [-3.0406e-03, -1.0129e-01, -4.0266e-03,  ..., -1.4068e-01,\n",
            "            1.2117e-02,  2.2045e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.7092e-01,  7.6107e-02, -3.0893e-01,  ..., -3.1508e-01,\n",
            "           -9.1777e-02, -1.2624e-01],\n",
            "          [ 1.1252e-01,  4.9314e-01, -2.1680e-01,  ...,  2.2788e-01,\n",
            "            1.8897e-02, -1.5650e-01],\n",
            "          [-5.0200e-01, -4.4571e-01, -4.7276e-02,  ..., -2.6673e-01,\n",
            "           -1.4848e-01, -7.9347e-02],\n",
            "          ...,\n",
            "          [ 2.5061e-02,  2.6916e-01, -2.1728e-02,  ...,  1.5505e-01,\n",
            "            4.9128e-02,  2.5660e-01],\n",
            "          [-7.3749e-02, -8.2148e-02, -2.0713e-01,  ...,  1.2268e-01,\n",
            "           -1.2527e-01,  3.7642e-02],\n",
            "          [-3.0656e-02,  2.7298e-01,  2.0730e-01,  ...,  2.8327e-01,\n",
            "           -4.4093e-02,  2.3490e-01]],\n",
            "\n",
            "         [[ 2.1729e-01,  2.0969e-01,  5.7800e-01,  ...,  1.6496e-01,\n",
            "            1.7947e-01,  2.0521e-01],\n",
            "          [-6.3915e-02,  8.4239e-02, -1.9320e-01,  ..., -3.5617e-01,\n",
            "            2.0635e-01, -3.5991e-01],\n",
            "          [-1.4540e-01, -1.4235e-01, -1.7970e-01,  ..., -6.1724e-02,\n",
            "            1.3529e-01,  2.2188e-01],\n",
            "          ...,\n",
            "          [-3.9032e-02, -3.0471e-01, -1.7500e-01,  ..., -2.4977e-01,\n",
            "            5.5737e-02, -1.3171e-01],\n",
            "          [-2.8278e-02, -1.5859e-01, -1.6754e-01,  ..., -2.1968e-01,\n",
            "            2.8539e-02,  9.3404e-02],\n",
            "          [-1.5074e-02, -3.4611e-01,  1.6349e-02,  ..., -2.4099e-01,\n",
            "           -7.8158e-03, -1.7439e-01]],\n",
            "\n",
            "         [[-1.4442e-01, -1.6851e-01, -2.0570e-01,  ...,  4.7058e-03,\n",
            "            5.4345e-02,  1.0843e-01],\n",
            "          [ 6.9249e-02,  5.5914e-01, -1.2214e-01,  ...,  2.2842e-01,\n",
            "            2.7620e-01,  3.5882e-01],\n",
            "          [-3.5381e-01,  5.7561e-01, -1.0628e-01,  ...,  2.6104e-01,\n",
            "            5.5919e-02,  1.4630e-01],\n",
            "          ...,\n",
            "          [ 6.2395e-04,  3.5260e-01, -1.4253e-01,  ...,  4.0850e-01,\n",
            "            3.9842e-03,  2.5692e-02],\n",
            "          [ 5.3496e-03,  5.5085e-02, -1.6863e-01,  ...,  7.4975e-02,\n",
            "            2.2966e-02,  7.9941e-02],\n",
            "          [-7.7924e-03,  3.2990e-01, -8.0443e-02,  ...,  1.7861e-01,\n",
            "           -6.9557e-02,  2.2360e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.8279e-02,  2.1914e-01, -2.4323e-01,  ...,  1.7861e-01,\n",
            "           -5.8274e-02,  2.1189e-01],\n",
            "          [-4.6639e-01, -6.7945e-01,  4.5909e-01,  ..., -3.1495e-01,\n",
            "            3.6170e-01,  1.0088e-01],\n",
            "          [ 6.5437e-02,  7.3048e-01,  1.5970e-01,  ...,  3.0791e-01,\n",
            "           -1.0793e-01,  2.4683e-01],\n",
            "          ...,\n",
            "          [-1.6639e-03, -2.4816e-02,  1.1995e-01,  ...,  1.0092e-02,\n",
            "            6.4807e-02, -1.5136e-01],\n",
            "          [ 6.4643e-02, -1.5621e-01,  1.5093e-01,  ...,  1.0687e-01,\n",
            "            3.5711e-02,  1.0960e-01],\n",
            "          [ 6.1992e-02, -2.6728e-01,  8.9042e-03,  ..., -3.4519e-01,\n",
            "            5.9099e-02, -1.5527e-01]],\n",
            "\n",
            "         [[ 4.7560e-01, -1.0083e+00,  1.2665e+00,  ..., -9.6575e-02,\n",
            "            2.9038e-01,  6.6821e-02],\n",
            "          [ 2.1712e-01,  1.9454e+00,  1.9342e-01,  ...,  9.7553e-01,\n",
            "           -8.2405e-02,  2.5719e-01],\n",
            "          [ 8.9109e-01, -6.7767e-01,  2.6841e-01,  ...,  5.3209e-02,\n",
            "            2.5769e-01,  6.3175e-02],\n",
            "          ...,\n",
            "          [ 4.2590e-02,  4.3316e-01,  1.5578e-01,  ...,  1.4099e-01,\n",
            "            3.3496e-02,  1.1652e-01],\n",
            "          [ 3.8668e-03,  1.2773e-02,  6.0437e-02,  ..., -4.5647e-02,\n",
            "           -5.2916e-04, -6.5352e-02],\n",
            "          [ 8.7787e-03, -8.6923e-02,  7.7813e-02,  ..., -1.0030e-01,\n",
            "            3.0553e-02, -1.3295e-01]],\n",
            "\n",
            "         [[-2.9124e-01,  7.7338e-01, -2.9040e-01,  ...,  3.2539e-01,\n",
            "            1.0351e-01, -1.4908e-02],\n",
            "          [-1.1538e-01,  3.3431e-01, -6.6229e-01,  ...,  8.2455e-02,\n",
            "            1.9857e-02, -2.4824e-01],\n",
            "          [-3.9944e-01,  1.2932e-01, -3.9784e-01,  ...,  1.4713e-01,\n",
            "            8.4160e-02, -8.8133e-02],\n",
            "          ...,\n",
            "          [-1.0978e-01, -3.1870e-01, -2.5036e-01,  ..., -3.5618e-01,\n",
            "           -4.5384e-02, -2.6417e-01],\n",
            "          [-2.2710e-01,  1.5908e-01, -1.4380e-01,  ...,  7.2991e-02,\n",
            "           -2.3023e-01,  1.5026e-01],\n",
            "          [-1.1607e-01, -1.9087e-01, -1.2373e-01,  ..., -8.1972e-02,\n",
            "           -1.4345e-01, -9.3480e-02]]]], device='cuda:0',\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[-2.3982, -2.4993, -2.4786,  ..., -2.3288, -2.3400, -2.3099],\n",
            "          [-2.3937, -2.5696, -2.4817,  ..., -2.1655, -2.2366, -2.3761],\n",
            "          [-2.4031, -2.6317, -2.5121,  ..., -2.1709, -2.2199, -2.3772],\n",
            "          ...,\n",
            "          [-2.2053, -2.4898, -2.3973,  ..., -2.6058, -2.6090, -2.4029],\n",
            "          [-2.3184, -2.4800, -2.4053,  ..., -2.6770, -2.6416, -2.4435],\n",
            "          [-2.4824, -2.5969, -2.5981,  ..., -2.5760, -2.5927, -2.6831]],\n",
            "\n",
            "         [[-2.8041, -2.8520, -2.8239,  ..., -2.8206, -2.8649, -2.6830],\n",
            "          [-2.7034, -2.8739, -2.9643,  ..., -2.6431, -2.7267, -2.5330],\n",
            "          [-2.6975, -2.9687, -3.0406,  ..., -2.7225, -2.7615, -2.5558],\n",
            "          ...,\n",
            "          [-2.3640, -2.7636, -2.8529,  ..., -2.5111, -2.6320, -2.3165],\n",
            "          [-2.2487, -2.6503, -2.7845,  ..., -2.4094, -2.5364, -2.2994],\n",
            "          [-2.5392, -2.6518, -2.7124,  ..., -2.3819, -2.3601, -2.2252]],\n",
            "\n",
            "         [[-2.4405, -2.4708, -2.4955,  ..., -2.1568, -2.1260, -2.1713],\n",
            "          [-2.8312, -2.7020, -2.7447,  ..., -2.4709, -2.4084, -2.1832],\n",
            "          [-2.8979, -2.7646, -2.7981,  ..., -2.5650, -2.5135, -2.2878],\n",
            "          ...,\n",
            "          [-2.9011, -2.6032, -2.6248,  ..., -2.6085, -2.6102, -2.1192],\n",
            "          [-2.8532, -2.6158, -2.6425,  ..., -2.5855, -2.5772, -2.1269],\n",
            "          [-2.4576, -2.5740, -2.5492,  ..., -2.5295, -2.5595, -2.2576]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9895, -3.2734, -3.4046,  ..., -3.1114, -3.0651, -3.0438],\n",
            "          [-2.9973, -3.1038, -3.1826,  ..., -3.0903, -3.1111, -3.2298],\n",
            "          [-2.9359, -2.9901, -3.0883,  ..., -3.0657, -3.0560, -3.1460],\n",
            "          ...,\n",
            "          [-2.9544, -2.8390, -2.9202,  ..., -2.8126, -2.8065, -3.0195],\n",
            "          [-2.8620, -2.7407, -2.8028,  ..., -2.7619, -2.8013, -3.0456],\n",
            "          [-2.7148, -2.5354, -2.5148,  ..., -2.5574, -2.6580, -2.9638]],\n",
            "\n",
            "         [[-2.6014, -2.5390, -2.6399,  ..., -2.4832, -2.5175, -2.3046],\n",
            "          [-2.9550, -2.8080, -2.7769,  ..., -2.5150, -2.5013, -2.5320],\n",
            "          [-2.9547, -2.8190, -2.7931,  ..., -2.4794, -2.4816, -2.5240],\n",
            "          ...,\n",
            "          [-3.0082, -2.9905, -2.9066,  ..., -1.9536, -1.9484, -2.1729],\n",
            "          [-2.9698, -2.9293, -2.8191,  ..., -2.0766, -2.0231, -2.2011],\n",
            "          [-2.8622, -2.8042, -2.6841,  ..., -2.2333, -2.1195, -2.3233]],\n",
            "\n",
            "         [[-2.1647, -2.0520, -2.0941,  ..., -2.2399, -2.1527, -2.2837],\n",
            "          [-2.3573, -2.3880, -2.4342,  ..., -2.6693, -2.6139, -2.5236],\n",
            "          [-2.3753, -2.3877, -2.4478,  ..., -2.7008, -2.6655, -2.4958],\n",
            "          ...,\n",
            "          [-2.7780, -2.6528, -2.6054,  ..., -3.0144, -2.9533, -2.8018],\n",
            "          [-2.7819, -2.6979, -2.6364,  ..., -2.9645, -2.8926, -2.6618],\n",
            "          [-2.6228, -2.6056, -2.6196,  ..., -2.7747, -2.7268, -2.4596]]],\n",
            "\n",
            "\n",
            "        [[[-2.1614, -2.1037, -2.2083,  ..., -2.6786, -2.6231, -2.3524],\n",
            "          [-2.2232, -2.1593, -2.1723,  ..., -2.3501, -2.3644, -2.3115],\n",
            "          [-2.3164, -2.1882, -2.2214,  ..., -2.2846, -2.2831, -2.2617],\n",
            "          ...,\n",
            "          [-2.2583, -2.2911, -2.2953,  ..., -2.4613, -2.4238, -2.2169],\n",
            "          [-2.2799, -2.2060, -2.1732,  ..., -2.5383, -2.4562, -2.2748],\n",
            "          [-2.5244, -2.3974, -2.3449,  ..., -2.5748, -2.4975, -2.4263]],\n",
            "\n",
            "         [[-2.7819, -2.8968, -2.7259,  ..., -2.8455, -2.8694, -2.9828],\n",
            "          [-2.7703, -3.0533, -2.9165,  ..., -2.7161, -2.7945, -2.8343],\n",
            "          [-2.9154, -3.1030, -2.9834,  ..., -2.7588, -2.8787, -2.6688],\n",
            "          ...,\n",
            "          [-2.0291, -2.2934, -2.1942,  ..., -2.4241, -2.6578, -2.7256],\n",
            "          [-1.9795, -2.3229, -2.2988,  ..., -2.4336, -2.6550, -2.7419],\n",
            "          [-2.3687, -2.4371, -2.3488,  ..., -2.5451, -2.6120, -2.5834]],\n",
            "\n",
            "         [[-2.5978, -2.6931, -2.9452,  ..., -3.0134, -2.8999, -2.6900],\n",
            "          [-3.0324, -3.1407, -3.2526,  ..., -3.3302, -3.2345, -2.9695],\n",
            "          [-3.0236, -3.0837, -3.2208,  ..., -3.4203, -3.3705, -2.9756],\n",
            "          ...,\n",
            "          [-2.4275, -2.5717, -2.4853,  ..., -2.8365, -2.8224, -2.4777],\n",
            "          [-2.4320, -2.6293, -2.5491,  ..., -2.7978, -2.7752, -2.4398],\n",
            "          [-2.2585, -2.5438, -2.4677,  ..., -2.6575, -2.6897, -2.6130]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9927, -3.0478, -3.0291,  ..., -2.6735, -2.6045, -2.6005],\n",
            "          [-2.9587, -3.0516, -2.9922,  ..., -2.4223, -2.4032, -2.4337],\n",
            "          [-2.8756, -2.9246, -2.7824,  ..., -2.3388, -2.3892, -2.4818],\n",
            "          ...,\n",
            "          [-2.6797, -2.5234, -2.5035,  ..., -2.3476, -2.4910, -2.6717],\n",
            "          [-2.5948, -2.4312, -2.4316,  ..., -2.3771, -2.4920, -2.6274],\n",
            "          [-2.7130, -2.7232, -2.7752,  ..., -2.5585, -2.5907, -2.6626]],\n",
            "\n",
            "         [[-2.3909, -2.2817, -2.3731,  ..., -2.4040, -2.4151, -2.4723],\n",
            "          [-2.5702, -2.5902, -2.6312,  ..., -2.5576, -2.4366, -2.4341],\n",
            "          [-2.5209, -2.5338, -2.5785,  ..., -2.4019, -2.2228, -2.4088],\n",
            "          ...,\n",
            "          [-2.9064, -3.0088, -3.0272,  ..., -2.3948, -2.2861, -2.1830],\n",
            "          [-2.8045, -2.8792, -2.8947,  ..., -2.4314, -2.4001, -2.2540],\n",
            "          [-2.6044, -2.5772, -2.5786,  ..., -2.4348, -2.3968, -2.2971]],\n",
            "\n",
            "         [[-2.6350, -2.9081, -2.8526,  ..., -2.7354, -2.7356, -2.7365],\n",
            "          [-2.6450, -2.8799, -2.8193,  ..., -2.6402, -2.7368, -2.8162],\n",
            "          [-2.5192, -2.7323, -2.6737,  ..., -2.7138, -2.8556, -2.8483],\n",
            "          ...,\n",
            "          [-2.8787, -2.6363, -2.5853,  ..., -3.0164, -2.9418, -2.8491],\n",
            "          [-2.7729, -2.5096, -2.4503,  ..., -2.8950, -2.8424, -2.8069],\n",
            "          [-2.5600, -2.3910, -2.4041,  ..., -2.6421, -2.6994, -2.7024]]],\n",
            "\n",
            "\n",
            "        [[[-2.0843, -2.0961, -2.2342,  ..., -2.9781, -2.9792, -2.7414],\n",
            "          [-2.3033, -2.5368, -2.6070,  ..., -2.6069, -2.6466, -2.5602],\n",
            "          [-2.3505, -2.6080, -2.6505,  ..., -2.5772, -2.6394, -2.5833],\n",
            "          ...,\n",
            "          [-2.5334, -2.8066, -2.7256,  ..., -2.9470, -2.8076, -2.7999],\n",
            "          [-2.6035, -2.8433, -2.7511,  ..., -2.9224, -2.8274, -2.7732],\n",
            "          [-2.6166, -2.7130, -2.6930,  ..., -2.7590, -2.7048, -2.7593]],\n",
            "\n",
            "         [[-2.6788, -2.7654, -2.6882,  ..., -2.4814, -2.3951, -2.3054],\n",
            "          [-2.7108, -2.8191, -2.8358,  ..., -2.4763, -2.3591, -2.3886],\n",
            "          [-2.6552, -2.8372, -2.7927,  ..., -2.6127, -2.4667, -2.4451],\n",
            "          ...,\n",
            "          [-2.2784, -2.3585, -2.4606,  ..., -2.4376, -2.5428, -2.5827],\n",
            "          [-2.1809, -2.2715, -2.3764,  ..., -2.4138, -2.4930, -2.5589],\n",
            "          [-2.6140, -2.6358, -2.6559,  ..., -2.6898, -2.6786, -2.6233]],\n",
            "\n",
            "         [[-2.6326, -2.6990, -2.7167,  ..., -2.5549, -2.6877, -2.4915],\n",
            "          [-2.8249, -2.9227, -2.9832,  ..., -2.9373, -3.0149, -2.6698],\n",
            "          [-2.8000, -2.9909, -3.0603,  ..., -3.0518, -3.0928, -2.6738],\n",
            "          ...,\n",
            "          [-2.8502, -2.8549, -2.9685,  ..., -2.8983, -2.8330, -2.3402],\n",
            "          [-2.7725, -2.8383, -2.9668,  ..., -2.8190, -2.7519, -2.3669],\n",
            "          [-2.3637, -2.4259, -2.5164,  ..., -2.4915, -2.4789, -2.2738]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6197, -2.6414, -2.6463,  ..., -2.5465, -2.4495, -2.6693],\n",
            "          [-2.4749, -2.5646, -2.6304,  ..., -2.7042, -2.6461, -2.7574],\n",
            "          [-2.5143, -2.5792, -2.6690,  ..., -2.6332, -2.6480, -2.8016],\n",
            "          ...,\n",
            "          [-2.7589, -2.6179, -2.6981,  ..., -2.7566, -2.7662, -3.0445],\n",
            "          [-2.7880, -2.6160, -2.7040,  ..., -2.7383, -2.7255, -2.9887],\n",
            "          [-2.7586, -2.6036, -2.5498,  ..., -2.6784, -2.7043, -2.8891]],\n",
            "\n",
            "         [[-2.5904, -2.3834, -2.4369,  ..., -2.3885, -2.4426, -2.3872],\n",
            "          [-2.7963, -2.5687, -2.5313,  ..., -2.4372, -2.4127, -2.3988],\n",
            "          [-2.6750, -2.4157, -2.3883,  ..., -2.3773, -2.2698, -2.3295],\n",
            "          ...,\n",
            "          [-2.8115, -2.7686, -2.6199,  ..., -2.2581, -2.2420, -2.1212],\n",
            "          [-2.7141, -2.6822, -2.5274,  ..., -2.3145, -2.2997, -2.2171],\n",
            "          [-2.5971, -2.4329, -2.3691,  ..., -2.2455, -2.2383, -2.1002]],\n",
            "\n",
            "         [[-2.6620, -2.9423, -2.8469,  ..., -2.1764, -2.2047, -2.5094],\n",
            "          [-2.5461, -2.9185, -2.8282,  ..., -2.8002, -2.7392, -2.6847],\n",
            "          [-2.6156, -2.9654, -2.9104,  ..., -3.0003, -2.8985, -2.6740],\n",
            "          ...,\n",
            "          [-2.6138, -2.6654, -2.6472,  ..., -2.6182, -2.6947, -2.5875],\n",
            "          [-2.5772, -2.5412, -2.5538,  ..., -2.5590, -2.6374, -2.5242],\n",
            "          [-2.5494, -2.4799, -2.5250,  ..., -2.5134, -2.5039, -2.5086]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.4646, -2.2901, -2.3873,  ..., -2.3733, -2.3627, -2.4599],\n",
            "          [-2.3254, -1.8893, -2.0152,  ..., -2.0987, -2.1618, -2.2728],\n",
            "          [-2.3332, -1.7886, -1.9013,  ..., -2.2053, -2.2154, -2.2778],\n",
            "          ...,\n",
            "          [-2.4625, -2.5824, -2.6521,  ..., -2.8533, -2.7400, -2.4552],\n",
            "          [-2.5700, -2.6917, -2.7380,  ..., -2.9538, -2.8728, -2.5468],\n",
            "          [-2.7791, -2.7552, -2.7411,  ..., -2.6748, -2.6479, -2.5327]],\n",
            "\n",
            "         [[-2.6981, -2.8299, -2.8543,  ..., -2.6088, -2.5921, -2.4643],\n",
            "          [-2.7528, -3.0783, -3.1587,  ..., -2.7426, -2.6509, -2.4818],\n",
            "          [-2.8783, -3.1788, -3.3107,  ..., -2.9072, -2.8225, -2.5527],\n",
            "          ...,\n",
            "          [-2.3673, -2.4491, -2.4906,  ..., -2.6553, -2.7887, -2.6876],\n",
            "          [-2.3434, -2.4771, -2.5291,  ..., -2.6803, -2.7792, -2.6972],\n",
            "          [-2.6019, -2.6349, -2.6109,  ..., -2.6259, -2.6463, -2.5999]],\n",
            "\n",
            "         [[-2.3789, -2.2768, -2.3717,  ..., -2.2546, -2.2845, -2.3103],\n",
            "          [-2.5504, -2.3768, -2.3906,  ..., -2.5134, -2.5038, -2.4659],\n",
            "          [-2.4724, -2.3195, -2.4386,  ..., -2.3105, -2.3886, -2.5352],\n",
            "          ...,\n",
            "          [-2.7057, -2.6046, -2.6135,  ..., -2.7247, -2.6722, -2.2410],\n",
            "          [-2.6481, -2.6108, -2.6534,  ..., -2.6204, -2.5926, -2.1928],\n",
            "          [-2.5196, -2.7076, -2.7066,  ..., -2.5755, -2.5483, -2.2355]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9084, -3.0746, -3.0410,  ..., -3.1805, -2.7916, -2.6407],\n",
            "          [-3.0251, -3.2798, -3.2772,  ..., -3.4801, -3.1318, -2.8880],\n",
            "          [-2.9432, -3.1510, -3.1007,  ..., -3.3382, -3.0639, -2.8457],\n",
            "          ...,\n",
            "          [-2.8162, -2.5350, -2.4590,  ..., -2.5251, -2.6548, -3.0222],\n",
            "          [-2.7350, -2.5601, -2.5444,  ..., -2.7426, -2.8502, -3.1565],\n",
            "          [-2.4339, -2.2819, -2.3000,  ..., -2.5406, -2.6414, -2.9129]],\n",
            "\n",
            "         [[-2.3297, -1.9464, -1.9523,  ..., -2.4177, -2.4334, -2.4094],\n",
            "          [-2.6046, -2.2066, -1.9648,  ..., -2.8587, -2.8174, -2.7178],\n",
            "          [-2.5994, -2.1712, -1.9028,  ..., -2.7126, -2.6281, -2.6577],\n",
            "          ...,\n",
            "          [-2.3452, -2.1020, -1.9806,  ..., -2.0815, -2.0251, -2.0284],\n",
            "          [-2.1951, -2.0390, -1.8864,  ..., -2.0974, -2.0751, -2.0676],\n",
            "          [-2.3876, -2.2790, -2.2408,  ..., -2.1508, -2.1775, -2.2558]],\n",
            "\n",
            "         [[-2.4226, -2.5195, -2.4770,  ..., -2.4276, -2.5875, -2.6592],\n",
            "          [-2.7275, -3.1956, -3.1311,  ..., -3.2487, -3.0446, -2.7834],\n",
            "          [-2.8398, -3.3879, -3.3397,  ..., -3.4147, -3.1988, -2.8199],\n",
            "          ...,\n",
            "          [-2.9602, -2.7723, -2.7502,  ..., -2.7262, -2.8281, -2.7367],\n",
            "          [-3.0276, -2.8004, -2.7504,  ..., -2.7104, -2.7860, -2.6481],\n",
            "          [-3.0092, -2.8487, -2.8226,  ..., -2.7150, -2.7365, -2.5941]]],\n",
            "\n",
            "\n",
            "        [[[-2.5938, -2.4959, -2.7290,  ..., -2.6330, -2.5106, -2.3642],\n",
            "          [-2.6948, -2.7384, -2.7966,  ..., -2.6205, -2.5643, -2.3241],\n",
            "          [-2.6622, -2.7053, -2.7042,  ..., -2.7552, -2.6812, -2.3134],\n",
            "          ...,\n",
            "          [-2.4403, -2.3443, -2.2687,  ..., -2.6269, -2.5190, -2.3674],\n",
            "          [-2.4023, -2.3176, -2.1893,  ..., -2.6782, -2.5913, -2.4585],\n",
            "          [-2.4431, -2.4860, -2.4943,  ..., -2.7676, -2.7733, -2.6967]],\n",
            "\n",
            "         [[-2.3945, -2.8238, -2.8014,  ..., -2.3709, -2.4438, -2.2797],\n",
            "          [-2.5179, -3.0595, -3.2181,  ..., -2.4161, -2.4838, -2.1592],\n",
            "          [-2.5424, -3.0234, -3.1511,  ..., -2.4614, -2.5321, -2.2313],\n",
            "          ...,\n",
            "          [-2.6363, -2.8899, -3.0460,  ..., -2.7073, -2.8516, -2.4864],\n",
            "          [-2.6220, -2.9664, -3.0966,  ..., -2.8578, -2.9655, -2.5783],\n",
            "          [-2.7940, -2.9034, -2.8484,  ..., -2.6580, -2.7109, -2.5585]],\n",
            "\n",
            "         [[-2.5470, -2.4127, -2.5746,  ..., -2.6788, -2.6954, -2.4888],\n",
            "          [-2.9256, -2.9266, -3.0080,  ..., -2.8255, -2.8250, -2.3156],\n",
            "          [-2.8225, -2.8569, -2.9710,  ..., -2.9186, -2.9029, -2.4165],\n",
            "          ...,\n",
            "          [-2.4963, -2.4897, -2.4261,  ..., -3.0675, -3.1041, -2.5297],\n",
            "          [-2.4208, -2.3680, -2.3374,  ..., -3.0131, -3.0793, -2.5952],\n",
            "          [-2.2079, -2.2643, -2.2588,  ..., -2.7962, -2.8603, -2.4652]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.1458, -3.2102, -3.1312,  ..., -2.9984, -3.0881, -3.1916],\n",
            "          [-2.9938, -3.1042, -3.0516,  ..., -3.2315, -3.4222, -3.5160],\n",
            "          [-2.8988, -2.9336, -2.7988,  ..., -2.9533, -3.2021, -3.3627],\n",
            "          ...,\n",
            "          [-2.5811, -2.5453, -2.6181,  ..., -2.7609, -2.8899, -3.2751],\n",
            "          [-2.5737, -2.5786, -2.7053,  ..., -2.8228, -2.9105, -3.2202],\n",
            "          [-2.5844, -2.6201, -2.6919,  ..., -2.7530, -2.7591, -3.0067]],\n",
            "\n",
            "         [[-2.0422, -2.1779, -2.1855,  ..., -2.2691, -2.2246, -2.1825],\n",
            "          [-2.1942, -2.4086, -2.2471,  ..., -2.4004, -2.2697, -2.5268],\n",
            "          [-2.1386, -2.3470, -2.2693,  ..., -2.4053, -2.2327, -2.4708],\n",
            "          ...,\n",
            "          [-2.3777, -2.4609, -2.4468,  ..., -2.1865, -2.0517, -2.0420],\n",
            "          [-2.3666, -2.4420, -2.4441,  ..., -2.1553, -2.0267, -2.0570],\n",
            "          [-2.4246, -2.6296, -2.6417,  ..., -2.2958, -2.2011, -2.1354]],\n",
            "\n",
            "         [[-2.7636, -2.8170, -2.7494,  ..., -2.7150, -2.6708, -2.6691],\n",
            "          [-2.7226, -2.6837, -2.6541,  ..., -2.8215, -2.8462, -2.6649],\n",
            "          [-2.8221, -2.7231, -2.6683,  ..., -2.8648, -2.8737, -2.6779],\n",
            "          ...,\n",
            "          [-2.9652, -2.7483, -2.6113,  ..., -2.7462, -2.8652, -2.8493],\n",
            "          [-2.7583, -2.6035, -2.5140,  ..., -2.6773, -2.7899, -2.7345],\n",
            "          [-2.7026, -2.5547, -2.5041,  ..., -2.5099, -2.6218, -2.6989]]],\n",
            "\n",
            "\n",
            "        [[[-2.1445, -1.9988, -1.9120,  ..., -1.8591, -1.9946, -2.1412],\n",
            "          [-2.5454, -2.3318, -2.2789,  ..., -2.2228, -2.3089, -2.2213],\n",
            "          [-2.5582, -2.4323, -2.3645,  ..., -2.3590, -2.4515, -2.3627],\n",
            "          ...,\n",
            "          [-2.4932, -2.4856, -2.3511,  ..., -2.4991, -2.3317, -2.1526],\n",
            "          [-2.5741, -2.5410, -2.4107,  ..., -2.4403, -2.3397, -2.1666],\n",
            "          [-2.6969, -2.6013, -2.4759,  ..., -2.5504, -2.5221, -2.4712]],\n",
            "\n",
            "         [[-2.3047, -2.5344, -2.5436,  ..., -2.7266, -2.6676, -2.5226],\n",
            "          [-2.2552, -2.3889, -2.3555,  ..., -2.4651, -2.4589, -2.3013],\n",
            "          [-2.2924, -2.2884, -2.2150,  ..., -2.4626, -2.4113, -2.2780],\n",
            "          ...,\n",
            "          [-2.4515, -2.5027, -2.5797,  ..., -2.6361, -2.7428, -2.6538],\n",
            "          [-2.4758, -2.5139, -2.5665,  ..., -2.6154, -2.6981, -2.6228],\n",
            "          [-2.6115, -2.6314, -2.6522,  ..., -2.6192, -2.6946, -2.6574]],\n",
            "\n",
            "         [[-2.5784, -2.4115, -2.3969,  ..., -2.7463, -2.7385, -2.6701],\n",
            "          [-2.6933, -2.9331, -3.0126,  ..., -3.1809, -3.1920, -3.0710],\n",
            "          [-2.6036, -2.9876, -3.0967,  ..., -3.2401, -3.2561, -3.1368],\n",
            "          ...,\n",
            "          [-2.4388, -2.6959, -2.7344,  ..., -2.6886, -2.6117, -2.6242],\n",
            "          [-2.4289, -2.6593, -2.6653,  ..., -2.6245, -2.5738, -2.5707],\n",
            "          [-2.2917, -2.4918, -2.5529,  ..., -2.5837, -2.6018, -2.5577]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.2246, -3.3900, -3.2832,  ..., -2.6848, -2.5934, -2.6447],\n",
            "          [-3.3248, -3.2722, -3.2685,  ..., -2.6968, -2.6687, -2.5465],\n",
            "          [-3.3714, -3.3899, -3.3888,  ..., -2.7322, -2.6352, -2.5436],\n",
            "          ...,\n",
            "          [-2.9614, -2.9005, -3.0180,  ..., -3.0284, -3.0750, -3.0084],\n",
            "          [-2.9063, -2.8284, -2.9269,  ..., -3.0388, -3.0551, -3.0426],\n",
            "          [-2.6946, -2.4964, -2.5020,  ..., -2.7025, -2.7056, -2.8373]],\n",
            "\n",
            "         [[-2.2984, -2.1687, -2.2142,  ..., -2.3471, -2.1992, -2.0667],\n",
            "          [-2.3562, -1.9024, -1.8688,  ..., -2.3927, -2.3533, -2.4008],\n",
            "          [-2.1509, -1.6844, -1.6482,  ..., -2.2926, -2.3436, -2.4396],\n",
            "          ...,\n",
            "          [-2.2783, -2.4138, -2.5933,  ..., -2.1668, -2.0696, -2.1212],\n",
            "          [-2.3581, -2.4900, -2.6504,  ..., -2.1487, -2.1094, -2.2578],\n",
            "          [-2.4694, -2.6000, -2.7198,  ..., -2.3915, -2.3353, -2.4205]],\n",
            "\n",
            "         [[-2.3176, -2.2207, -2.3042,  ..., -2.7618, -2.7501, -2.8805],\n",
            "          [-2.1668, -2.2100, -2.1460,  ..., -2.5085, -2.5337, -2.7292],\n",
            "          [-2.2323, -2.1954, -2.1553,  ..., -2.5009, -2.5996, -2.7273],\n",
            "          ...,\n",
            "          [-2.5217, -2.2460, -2.2965,  ..., -2.5051, -2.6202, -2.5371],\n",
            "          [-2.5064, -2.2485, -2.2850,  ..., -2.6150, -2.6563, -2.4256],\n",
            "          [-2.5616, -2.4937, -2.4855,  ..., -2.6718, -2.7111, -2.4432]]]],\n",
            "       device='cuda:0')\n",
            "tensor([[[[-1.3111e-01, -3.2562e-01, -2.5967e-01,  ...,  1.0206e-01,\n",
            "           -8.9479e-02,  8.4723e-02],\n",
            "          [ 7.3517e-01,  1.1422e+00, -4.4195e-01,  ..., -9.4727e-02,\n",
            "           -1.2116e-02, -7.2632e-02],\n",
            "          [-3.3207e-01, -6.3269e-01,  1.6528e-01,  ..., -1.7598e-01,\n",
            "           -2.1754e-01,  1.8567e-01],\n",
            "          ...,\n",
            "          [ 8.1902e-02,  2.1630e-01, -5.0912e-02,  ...,  2.7972e-01,\n",
            "           -1.1281e-01,  1.5777e-01],\n",
            "          [-7.6840e-02,  1.9943e-01, -1.5638e-01,  ..., -2.2096e-02,\n",
            "           -7.2342e-02,  7.1609e-02],\n",
            "          [ 1.3015e-01,  4.7259e-01, -1.2938e-01,  ...,  2.0989e-01,\n",
            "            4.4215e-02,  1.8387e-01]],\n",
            "\n",
            "         [[-2.2290e-01, -3.6102e-01,  6.0082e-02,  ..., -1.1656e-02,\n",
            "            6.2308e-02,  7.9116e-02],\n",
            "          [ 5.8525e-03, -5.7711e-01,  5.2944e-01,  ..., -6.7821e-01,\n",
            "            5.5518e-03, -4.7660e-02],\n",
            "          [ 1.3565e-01,  1.1916e-01, -8.1616e-03,  ...,  9.6990e-02,\n",
            "            7.4032e-02,  1.2317e-02],\n",
            "          ...,\n",
            "          [-1.0095e-02, -7.1661e-02, -3.7899e-02,  ..., -3.4214e-01,\n",
            "           -3.1109e-02, -1.7424e-01],\n",
            "          [-1.3573e-02, -5.2631e-02, -1.0159e-01,  ..., -6.1366e-02,\n",
            "           -5.0894e-02,  1.9956e-02],\n",
            "          [ 4.6079e-02,  5.8628e-02,  2.2125e-01,  ..., -4.0244e-01,\n",
            "            1.6025e-02, -1.3287e-01]],\n",
            "\n",
            "         [[-4.1074e-01,  1.5881e-01,  2.5937e-02,  ..., -1.4041e-01,\n",
            "            1.2500e-02, -4.7412e-02],\n",
            "          [ 5.3056e-01, -3.6389e-02, -6.7606e-01,  ...,  3.2849e-01,\n",
            "            1.0476e-01,  8.8133e-02],\n",
            "          [ 9.2928e-02,  6.2899e-01,  1.2913e-01,  ...,  1.9457e-01,\n",
            "           -1.7289e-02,  1.8929e-01],\n",
            "          ...,\n",
            "          [ 9.4760e-03,  3.3836e-01, -2.3365e-01,  ...,  4.5043e-01,\n",
            "           -7.1391e-02,  1.7582e-01],\n",
            "          [-6.2360e-02, -1.1680e-02, -8.5603e-02,  ...,  1.0687e-01,\n",
            "           -1.6534e-02,  9.4020e-02],\n",
            "          [ 4.0661e-02,  3.9854e-01, -3.0084e-01,  ...,  2.9399e-01,\n",
            "            1.7898e-02,  1.4868e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4467e-02, -1.3279e-01,  1.9741e-02,  ..., -2.8229e-01,\n",
            "           -8.7540e-03, -6.4311e-02],\n",
            "          [ 2.6869e-02, -1.3734e+00,  2.7935e-01,  ..., -2.0919e-02,\n",
            "            1.6466e-01,  3.2995e-02],\n",
            "          [-2.1626e-01,  5.9406e-01,  4.3220e-01,  ...,  8.2342e-02,\n",
            "           -1.7630e-01,  1.5417e-01],\n",
            "          ...,\n",
            "          [ 4.8337e-02, -1.0707e-02, -1.3997e-01,  ..., -2.5221e-01,\n",
            "            8.7527e-02, -1.3693e-01],\n",
            "          [-1.2498e-02,  1.7601e-01,  1.4216e-01,  ..., -3.2378e-03,\n",
            "            4.1018e-04,  6.8346e-02],\n",
            "          [ 1.5698e-01, -4.1352e-01,  7.6439e-03,  ..., -2.8170e-01,\n",
            "            8.8653e-02, -1.6894e-01]],\n",
            "\n",
            "         [[ 5.4058e-02, -9.1201e-01,  1.0157e+00,  ...,  4.3434e-01,\n",
            "           -5.7205e-03,  7.5533e-02],\n",
            "          [ 1.1125e-01,  1.2148e+00, -3.8852e-02,  ..., -4.4987e-02,\n",
            "           -1.9554e-01,  1.4173e-01],\n",
            "          [ 1.8352e-01, -6.5488e-01,  7.1185e-01,  ...,  7.8634e-02,\n",
            "            6.9852e-02,  3.2776e-02],\n",
            "          ...,\n",
            "          [-9.4577e-03,  2.2433e-01,  1.4752e-01,  ...,  1.4397e-01,\n",
            "            2.0422e-02,  2.0821e-01],\n",
            "          [ 1.8988e-02, -1.9757e-01,  2.6806e-01,  ...,  1.3799e-01,\n",
            "           -7.3969e-02, -8.4651e-04],\n",
            "          [-5.2835e-02, -8.8734e-02, -2.1049e-02,  ..., -2.4235e-01,\n",
            "            1.2926e-02, -1.6431e-01]],\n",
            "\n",
            "         [[-3.4430e-01,  1.8142e-01, -9.0669e-02,  ...,  3.9149e-01,\n",
            "            7.7710e-02, -1.4229e-02],\n",
            "          [-9.6499e-02,  8.4653e-01, -1.9350e-01,  ...,  1.6461e-01,\n",
            "           -4.9809e-02, -2.6949e-01],\n",
            "          [-8.2609e-01,  6.6896e-01,  3.1852e-01,  ...,  5.0693e-02,\n",
            "           -1.1842e-01, -1.5907e-02],\n",
            "          ...,\n",
            "          [-1.2020e-01, -2.9770e-01, -3.0735e-01,  ..., -1.6040e-01,\n",
            "            1.9022e-02, -1.6984e-01],\n",
            "          [ 5.2775e-02,  1.2520e-01, -3.4216e-01,  ...,  6.6931e-02,\n",
            "           -7.4446e-02,  4.3806e-03],\n",
            "          [-7.2179e-02,  4.1401e-02, -2.4045e-01,  ..., -1.2936e-01,\n",
            "           -1.6639e-01, -8.2250e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.2116e-01, -1.7342e-01, -2.0056e-01,  ..., -5.4740e-03,\n",
            "           -1.3502e-01, -4.1921e-02],\n",
            "          [ 1.1550e+00,  2.7782e-01, -1.9286e-01,  ...,  6.8912e-04,\n",
            "            3.3348e-02, -1.1886e-02],\n",
            "          [-5.7502e-01, -5.8544e-01, -7.2084e-01,  ..., -3.5446e-01,\n",
            "           -1.6383e-01,  8.2716e-02],\n",
            "          ...,\n",
            "          [ 1.2031e-01, -1.2622e-01, -1.8256e-02,  ...,  4.4217e-01,\n",
            "           -4.3691e-02,  1.9106e-01],\n",
            "          [-7.3089e-02, -1.7768e-01,  3.2854e-02,  ..., -4.6911e-02,\n",
            "            1.3669e-02,  1.4597e-02],\n",
            "          [ 7.5017e-02,  2.1935e-01, -6.7847e-02,  ...,  6.6831e-02,\n",
            "           -3.9247e-02,  4.8167e-02]],\n",
            "\n",
            "         [[-1.9678e-01,  1.2271e-01,  1.8652e-01,  ..., -8.6489e-02,\n",
            "            1.8551e-01,  1.1988e-01],\n",
            "          [ 4.1838e-01, -1.0669e+00, -4.4775e-01,  ..., -2.3841e-01,\n",
            "           -1.0953e-02, -2.6861e-01],\n",
            "          [ 9.3033e-01,  2.2986e-01,  2.8700e-01,  ...,  8.1699e-02,\n",
            "            7.3841e-02,  9.8187e-02],\n",
            "          ...,\n",
            "          [-1.8207e-01, -3.6130e-01,  1.0429e-01,  ..., -3.8578e-01,\n",
            "            1.3900e-01, -1.9830e-01],\n",
            "          [-8.5829e-02, -4.2516e-02,  7.5583e-02,  ..., -4.2792e-02,\n",
            "            1.0658e-01,  1.7403e-01],\n",
            "          [-6.6244e-02, -1.5630e-01,  8.8020e-02,  ..., -2.7861e-01,\n",
            "           -7.3825e-03, -2.2752e-01]],\n",
            "\n",
            "         [[-4.5818e-01,  5.2675e-01, -1.0459e-01,  ..., -2.7539e-02,\n",
            "            7.4911e-02,  5.9112e-02],\n",
            "          [ 4.0427e-01,  2.1259e-01, -5.3448e-02,  ...,  3.4435e-01,\n",
            "            2.2351e-02,  1.1209e-01],\n",
            "          [ 3.2608e-01,  6.6789e-01,  1.7928e-01,  ...,  2.6683e-01,\n",
            "            5.5548e-02,  1.2214e-01],\n",
            "          ...,\n",
            "          [-2.4722e-02,  2.0340e-01, -7.6210e-02,  ...,  3.8198e-01,\n",
            "           -1.5248e-01,  1.5048e-01],\n",
            "          [-1.4191e-02, -4.2099e-02, -8.1408e-02,  ..., -4.2579e-02,\n",
            "            5.9397e-02, -6.7917e-03],\n",
            "          [ 5.4913e-02,  3.4595e-01,  9.0034e-02,  ...,  1.9517e-01,\n",
            "            4.6836e-02,  2.6056e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.7340e-02,  6.6679e-02, -1.9629e-01,  ..., -1.6667e-01,\n",
            "           -2.5468e-02,  1.3264e-01],\n",
            "          [-1.1169e-01, -6.1917e-01, -4.7322e-01,  ...,  8.2546e-02,\n",
            "            4.2593e-01, -1.3374e-01],\n",
            "          [-6.6598e-01,  1.7819e+00, -2.8159e-01,  ...,  4.7798e-01,\n",
            "           -1.4205e-01,  5.7018e-02],\n",
            "          ...,\n",
            "          [ 2.0913e-01,  4.2315e-02,  7.5371e-02,  ..., -1.9656e-01,\n",
            "            9.1166e-02, -1.5951e-02],\n",
            "          [ 4.7585e-02,  1.5177e-02, -2.1834e-03,  ...,  2.3121e-02,\n",
            "            1.1281e-01,  7.2081e-02],\n",
            "          [ 1.5001e-01, -3.5046e-01,  5.1121e-02,  ..., -3.0693e-01,\n",
            "            1.2831e-01,  2.0428e-02]],\n",
            "\n",
            "         [[-7.1357e-02, -1.0358e+00,  7.3219e-01,  ...,  1.9119e-01,\n",
            "            2.7039e-01, -3.3628e-02],\n",
            "          [-5.1932e-01,  1.2641e+00, -6.5200e-01,  ...,  8.0236e-01,\n",
            "           -8.5050e-02,  2.5429e-01],\n",
            "          [ 7.1294e-01, -1.5201e+00,  3.7025e-01,  ...,  6.9564e-02,\n",
            "            6.6522e-02,  6.1240e-02],\n",
            "          ...,\n",
            "          [ 2.1897e-02,  1.1551e-01, -6.6915e-02,  ...,  1.0647e-01,\n",
            "           -5.2360e-02,  1.4316e-01],\n",
            "          [ 1.3400e-01, -1.2085e-01,  1.2590e-01,  ...,  1.9339e-01,\n",
            "            1.3930e-01,  9.6539e-02],\n",
            "          [-1.2744e-01, -1.1572e-01, -7.1080e-02,  ..., -5.0155e-03,\n",
            "           -1.3146e-01,  4.2809e-02]],\n",
            "\n",
            "         [[-6.8466e-01,  8.0803e-01,  4.7920e-01,  ...,  1.7496e-01,\n",
            "            1.0487e-01,  5.1661e-02],\n",
            "          [-1.8928e-01,  7.4166e-01,  3.3406e-01,  ..., -1.1245e-02,\n",
            "           -2.0965e-01, -2.3532e-01],\n",
            "          [-1.1574e+00,  1.5508e+00, -9.9406e-01,  ..., -1.4473e-01,\n",
            "           -2.2373e-01, -1.9362e-02],\n",
            "          ...,\n",
            "          [-1.3143e-01,  3.2555e-02, -1.6131e-01,  ..., -2.6048e-01,\n",
            "           -6.7094e-02, -7.1613e-03],\n",
            "          [-1.1768e-01,  7.5919e-02, -2.1644e-01,  ...,  1.4620e-01,\n",
            "            8.3760e-02,  6.4646e-02],\n",
            "          [ 2.2825e-02, -1.6288e-02,  7.1665e-02,  ..., -3.4732e-02,\n",
            "           -3.9439e-02, -1.4164e-01]]],\n",
            "\n",
            "\n",
            "        [[[-3.6569e-01, -8.3007e-02, -1.3222e-01,  ..., -2.5986e-01,\n",
            "           -1.1895e-01,  1.0611e-01],\n",
            "          [ 3.7060e-01, -1.6275e-02,  2.3117e-01,  ..., -4.6346e-02,\n",
            "            1.9939e-01,  8.0882e-02],\n",
            "          [-6.7482e-01, -3.8118e-01, -2.0626e-01,  ..., -5.4372e-01,\n",
            "           -2.2852e-01,  2.0417e-01],\n",
            "          ...,\n",
            "          [-6.0843e-02,  1.5191e-01,  1.2275e-01,  ...,  9.7242e-02,\n",
            "            1.1664e-01, -2.7088e-02],\n",
            "          [-4.1594e-02, -1.3183e-01, -2.1691e-01,  ..., -2.0621e-01,\n",
            "           -5.3026e-02,  3.8871e-02],\n",
            "          [-4.1647e-02,  2.6328e-01,  1.5703e-01,  ...,  2.5117e-01,\n",
            "            4.7552e-02,  8.5219e-02]],\n",
            "\n",
            "         [[ 1.5993e-01,  2.3037e-01,  1.4869e-01,  ..., -3.2231e-02,\n",
            "            5.9653e-02,  1.5951e-03],\n",
            "          [ 1.3656e-01, -2.4345e-01, -1.7796e-01,  ..., -4.3623e-01,\n",
            "            1.5737e-01, -7.4200e-02],\n",
            "          [-6.9812e-02,  2.1289e-01,  1.5807e-01,  ...,  9.2452e-02,\n",
            "            1.1046e-01,  4.9233e-02],\n",
            "          ...,\n",
            "          [ 8.2097e-02, -1.3305e-01, -1.9635e-01,  ..., -3.8758e-01,\n",
            "           -1.4782e-01, -1.6171e-01],\n",
            "          [ 7.2485e-02,  3.8996e-02, -9.0833e-02,  ...,  3.3891e-02,\n",
            "            5.5570e-02,  1.2112e-02],\n",
            "          [ 7.8674e-02, -1.9969e-01,  1.3059e-01,  ..., -1.8358e-01,\n",
            "            2.9946e-02, -4.6716e-02]],\n",
            "\n",
            "         [[ 2.7275e-02,  1.2032e-01, -2.7066e-02,  ...,  3.4502e-02,\n",
            "           -1.8983e-02,  7.4509e-02],\n",
            "          [-8.8196e-02,  4.8190e-01,  1.9694e-01,  ...,  3.3421e-01,\n",
            "            1.1670e-01,  6.8990e-02],\n",
            "          [-1.6387e-01,  2.8192e-01, -5.7335e-02,  ...,  1.4696e-01,\n",
            "            1.0831e-01,  2.0320e-01],\n",
            "          ...,\n",
            "          [-1.2819e-01,  3.4058e-01, -6.6657e-02,  ...,  3.7885e-01,\n",
            "           -7.7991e-02,  6.1350e-02],\n",
            "          [ 2.2710e-02,  1.0935e-01, -1.5716e-01,  ...,  4.4084e-02,\n",
            "           -3.8406e-02,  6.0598e-02],\n",
            "          [ 3.2827e-02,  3.6065e-01,  2.3945e-02,  ...,  5.2495e-01,\n",
            "            4.1019e-02,  1.0246e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3729e-01, -1.2281e-02, -1.6039e-01,  ...,  7.4614e-02,\n",
            "           -5.7723e-02,  4.9568e-02],\n",
            "          [ 4.0132e-01, -2.2998e-01,  2.5115e-01,  ..., -2.1368e-01,\n",
            "            2.3175e-01, -1.1373e-01],\n",
            "          [-4.0567e-01,  2.7348e-01, -2.3435e-01,  ...,  1.4600e-01,\n",
            "           -1.9127e-01,  1.2452e-01],\n",
            "          ...,\n",
            "          [ 9.2481e-02, -2.5886e-01,  1.0750e-01,  ..., -1.3943e-01,\n",
            "            2.2193e-01, -2.6283e-01],\n",
            "          [-5.2914e-04,  1.0225e-02,  1.5010e-03,  ...,  8.0952e-02,\n",
            "           -5.1843e-02,  7.1123e-02],\n",
            "          [ 1.5205e-01, -2.4162e-01, -6.5049e-02,  ..., -2.3662e-01,\n",
            "            1.0944e-01, -9.3200e-02]],\n",
            "\n",
            "         [[ 1.2960e-01,  2.1757e-02,  3.2934e-01,  ...,  1.4766e-01,\n",
            "            2.0607e-02,  1.4398e-01],\n",
            "          [-5.5284e-03,  7.5589e-01, -1.7116e-01,  ...,  2.5439e-01,\n",
            "           -1.6128e-01, -1.6518e-01],\n",
            "          [ 3.3242e-01,  1.8378e-01,  1.8149e-01,  ...,  3.2213e-01,\n",
            "           -2.0494e-02,  1.0921e-01],\n",
            "          ...,\n",
            "          [ 7.5215e-02,  5.4888e-01,  1.9351e-01,  ...,  3.9052e-01,\n",
            "            1.4674e-01,  1.6849e-01],\n",
            "          [ 1.9849e-02, -5.9353e-02,  8.0498e-02,  ..., -2.2537e-02,\n",
            "            5.0261e-02,  6.6455e-02],\n",
            "          [-5.3261e-02, -2.0503e-01,  7.5305e-02,  ..., -1.5350e-01,\n",
            "           -1.0886e-02, -1.0437e-01]],\n",
            "\n",
            "         [[-1.3057e-01,  3.5172e-01,  2.1028e-01,  ...,  9.3497e-02,\n",
            "           -5.2579e-02,  5.2177e-02],\n",
            "          [-3.2426e-01, -4.5457e-01, -1.6094e-01,  ..., -4.7517e-01,\n",
            "            6.2454e-02, -3.4123e-01],\n",
            "          [-2.9730e-01,  7.5246e-02, -2.0869e-01,  ..., -9.1763e-02,\n",
            "           -1.3126e-01,  4.6827e-02],\n",
            "          ...,\n",
            "          [-2.3283e-01, -3.6284e-01, -1.3216e-01,  ..., -5.0094e-01,\n",
            "           -1.9684e-01, -1.9733e-01],\n",
            "          [-2.4339e-01,  2.3659e-01, -1.4080e-01,  ...,  2.2703e-01,\n",
            "           -6.7009e-03,  6.1266e-02],\n",
            "          [ 6.8994e-04, -2.4027e-01, -1.0262e-01,  ..., -2.8767e-01,\n",
            "           -4.0059e-02, -5.5302e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.4906e-01,  1.3532e-01, -2.9246e-01,  ..., -3.2638e-01,\n",
            "           -1.0284e-01, -1.6129e-01],\n",
            "          [ 3.6444e-01,  6.0844e-01,  2.4202e-01,  ...,  5.1231e-02,\n",
            "            2.0819e-02, -2.3110e-01],\n",
            "          [-1.8504e-01, -2.4535e-01,  7.0017e-02,  ..., -4.3889e-01,\n",
            "            6.0818e-02, -7.9802e-02],\n",
            "          ...,\n",
            "          [ 8.3348e-02,  1.0537e-01,  1.1747e-01,  ...,  6.1300e-02,\n",
            "            4.4442e-03,  2.1699e-01],\n",
            "          [-5.0304e-02, -1.3730e-01, -9.9973e-02,  ..., -1.8435e-01,\n",
            "           -1.8817e-01,  1.6955e-01],\n",
            "          [-1.0873e-02,  2.5022e-01,  5.7572e-02,  ...,  2.2007e-01,\n",
            "            5.2467e-02,  1.7435e-01]],\n",
            "\n",
            "         [[-1.4837e-01, -3.6207e-01,  2.9037e-01,  ...,  2.2762e-01,\n",
            "            2.4359e-01,  1.7502e-01],\n",
            "          [ 2.3893e-01, -3.4686e-01, -1.2478e-01,  ..., -3.7975e-01,\n",
            "            2.6137e-01, -6.3152e-01],\n",
            "          [ 1.6453e-01,  1.3178e-01, -8.7954e-02,  ...,  7.0707e-02,\n",
            "            2.7739e-02,  1.6227e-01],\n",
            "          ...,\n",
            "          [-6.0548e-02, -4.2013e-01, -5.8658e-02,  ..., -5.2944e-01,\n",
            "            1.1112e-01, -8.8617e-02],\n",
            "          [ 2.9556e-02, -5.2018e-02,  2.2625e-02,  ...,  1.3564e-01,\n",
            "            1.7658e-01, -3.6326e-02],\n",
            "          [ 6.7085e-03, -2.7214e-01, -3.7109e-02,  ..., -5.0326e-01,\n",
            "            4.1151e-02, -1.3099e-01]],\n",
            "\n",
            "         [[-2.9223e-01, -3.5386e-02, -2.7366e-01,  ...,  1.8930e-01,\n",
            "           -3.7072e-02,  1.6150e-01],\n",
            "          [ 2.5396e-01,  3.8236e-01, -1.9217e-01,  ..., -4.8700e-02,\n",
            "            2.1812e-01,  3.4305e-01],\n",
            "          [-1.0879e-01, -9.9108e-02, -1.2273e-01,  ...,  8.2369e-02,\n",
            "            1.6737e-02,  1.4780e-01],\n",
            "          ...,\n",
            "          [-7.6678e-02,  4.0248e-01, -1.3338e-01,  ...,  3.0338e-01,\n",
            "            1.1930e-01,  3.9401e-02],\n",
            "          [ 4.9194e-02,  6.9191e-03, -1.3064e-02,  ...,  1.5309e-01,\n",
            "           -1.0250e-01,  7.4333e-02],\n",
            "          [ 8.3836e-02,  2.6082e-01, -2.5176e-02,  ...,  4.2497e-01,\n",
            "            3.2382e-02,  1.6521e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.9785e-02, -1.7851e-01, -2.5376e-01,  ...,  3.0027e-01,\n",
            "           -1.7427e-01,  3.3663e-01],\n",
            "          [ 2.0294e-01, -3.5790e-01,  2.5665e-01,  ..., -1.1216e-01,\n",
            "            5.0868e-01,  1.5073e-01],\n",
            "          [-3.2532e-01, -4.0266e-02,  1.5611e-01,  ...,  2.0612e-01,\n",
            "            1.4523e-01,  1.9801e-02],\n",
            "          ...,\n",
            "          [ 2.7208e-01, -2.0533e-01,  8.9959e-02,  ..., -3.0350e-01,\n",
            "            2.8332e-01, -4.6094e-02],\n",
            "          [-5.6814e-02, -2.1110e-01,  2.7932e-03,  ...,  3.6448e-01,\n",
            "           -1.3041e-01,  4.6906e-02],\n",
            "          [ 1.6580e-01, -1.8064e-01,  3.3832e-02,  ..., -4.9773e-01,\n",
            "            4.3409e-02,  3.0917e-02]],\n",
            "\n",
            "         [[ 2.9718e-02, -3.8134e-01,  4.6836e-01,  ..., -3.3747e-01,\n",
            "            3.7595e-01, -5.3571e-02],\n",
            "          [-7.3921e-02,  4.8737e-01,  2.8046e-01,  ...,  1.0614e+00,\n",
            "            1.0950e-01,  3.4590e-01],\n",
            "          [ 1.2657e-01,  6.3686e-02,  4.0426e-01,  ..., -1.9680e-01,\n",
            "            3.4410e-01, -1.6221e-01],\n",
            "          ...,\n",
            "          [-4.4990e-02,  1.3999e-01, -2.3052e-02,  ...,  6.8156e-01,\n",
            "           -1.9617e-01,  1.3370e-01],\n",
            "          [-1.3316e-01,  1.9008e-01,  4.9577e-02,  ..., -1.2700e-01,\n",
            "            1.3078e-01,  4.8891e-02],\n",
            "          [-8.4712e-02, -2.0802e-01, -3.9859e-03,  ..., -4.3916e-02,\n",
            "            3.6399e-02, -1.2797e-01]],\n",
            "\n",
            "         [[-3.8941e-01,  2.7599e-01, -2.2758e-01,  ...,  2.6766e-01,\n",
            "            1.0756e-01, -1.3865e-02],\n",
            "          [-3.9567e-01, -3.0478e-01, -9.2977e-02,  ...,  4.9622e-02,\n",
            "           -2.5629e-01, -1.7454e-02],\n",
            "          [-9.3373e-02,  3.6425e-01,  9.4498e-02,  ...,  7.7742e-02,\n",
            "           -3.4398e-01, -3.7322e-02],\n",
            "          ...,\n",
            "          [-1.0175e-01, -3.1070e-01, -6.6855e-02,  ..., -1.6974e-01,\n",
            "           -9.0969e-02, -5.9239e-01],\n",
            "          [-2.1945e-01,  1.5060e-01, -6.6367e-02,  ...,  3.4877e-01,\n",
            "           -3.2630e-01,  2.0629e-01],\n",
            "          [-4.2674e-02, -1.7350e-01, -5.1956e-02,  ..., -2.7541e-01,\n",
            "            4.9212e-02, -1.9049e-01]]],\n",
            "\n",
            "\n",
            "        [[[-7.6733e-02,  3.6614e-02, -2.7993e-02,  ...,  4.6602e-02,\n",
            "           -6.8260e-02,  1.1079e-01],\n",
            "          [ 5.7936e-02,  6.4470e-02, -6.9943e-02,  ...,  4.8691e-01,\n",
            "            6.3512e-02,  1.5070e-01],\n",
            "          [-9.5934e-02,  2.3991e-02,  5.2914e-03,  ...,  4.7173e-02,\n",
            "           -2.8340e-01,  1.1323e-01],\n",
            "          ...,\n",
            "          [-6.9498e-02,  1.7227e-01,  6.7363e-02,  ..., -9.7089e-02,\n",
            "            1.8144e-03,  7.8920e-02],\n",
            "          [-3.0302e-02, -2.1282e-02,  4.0299e-02,  ..., -2.0928e-01,\n",
            "           -6.3318e-02,  1.0161e-01],\n",
            "          [ 7.4181e-02,  6.1114e-02,  8.8400e-02,  ...,  1.0827e-01,\n",
            "            1.0407e-01,  1.3912e-01]],\n",
            "\n",
            "         [[ 9.0204e-02,  1.8890e-01,  4.4413e-03,  ..., -4.3844e-02,\n",
            "           -1.0788e-01, -4.8790e-02],\n",
            "          [-1.0505e-01, -4.8232e-01, -2.6910e-02,  ..., -3.6962e-01,\n",
            "           -8.4733e-02,  9.1380e-02],\n",
            "          [ 6.6561e-02, -2.4303e-01, -4.9862e-02,  ..., -1.1516e-02,\n",
            "           -8.3634e-02,  9.4555e-02],\n",
            "          ...,\n",
            "          [-6.9487e-02, -2.1559e-01, -8.4516e-02,  ..., -5.2014e-01,\n",
            "           -1.3560e-02, -9.9486e-02],\n",
            "          [-4.6632e-03, -2.4544e-02, -1.2144e-01,  ...,  1.0042e-01,\n",
            "           -8.8613e-02, -4.7522e-02],\n",
            "          [ 1.7980e-02, -2.5113e-01,  4.2377e-02,  ..., -3.0623e-01,\n",
            "            4.1770e-02, -6.8272e-02]],\n",
            "\n",
            "         [[-5.6549e-02, -1.6409e-01, -9.3809e-02,  ..., -5.4555e-02,\n",
            "           -1.2717e-01,  2.7303e-02],\n",
            "          [ 1.2857e-01,  5.3459e-02,  1.2668e-02,  ...,  4.5899e-01,\n",
            "           -5.9617e-02,  1.2885e-01],\n",
            "          [-1.2501e-01,  3.1305e-01, -1.1164e-01,  ...,  5.7136e-02,\n",
            "           -1.4379e-01,  1.2990e-02],\n",
            "          ...,\n",
            "          [-1.3882e-01,  1.9501e-01, -8.0499e-02,  ...,  2.7210e-01,\n",
            "           -3.1539e-02,  6.0120e-02],\n",
            "          [-7.6911e-02,  6.6593e-02, -8.9325e-02,  ...,  6.7219e-02,\n",
            "           -9.6949e-02,  6.6605e-02],\n",
            "          [ 1.6909e-02,  1.5890e-01,  6.4104e-02,  ...,  3.9105e-01,\n",
            "           -1.2430e-02,  6.1963e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.4123e-02, -8.8688e-02, -1.9906e-02,  ..., -1.7407e-01,\n",
            "            8.6763e-02,  6.2965e-02],\n",
            "          [ 5.7143e-02, -1.0902e-01,  1.1771e-01,  ..., -1.3640e-01,\n",
            "            7.8664e-02, -3.2911e-02],\n",
            "          [-2.1240e-02,  1.9300e-01,  1.5093e-01,  ..., -1.7229e-01,\n",
            "           -5.7393e-02,  1.6903e-01],\n",
            "          ...,\n",
            "          [ 7.7973e-02, -7.4389e-02,  5.7615e-02,  ..., -1.9272e-01,\n",
            "           -3.9021e-02,  2.2901e-02],\n",
            "          [-3.1399e-02, -1.5681e-02,  1.7058e-01,  ...,  5.6968e-02,\n",
            "            7.8693e-02,  3.9571e-02],\n",
            "          [ 1.1556e-01, -2.4626e-01,  8.2425e-02,  ..., -3.9159e-01,\n",
            "            2.8086e-02, -9.6846e-02]],\n",
            "\n",
            "         [[ 1.1003e-02,  1.8613e-01,  1.9453e-02,  ...,  1.3006e-01,\n",
            "            8.0816e-02,  1.1906e-02],\n",
            "          [-1.4929e-01,  3.8349e-01,  8.3276e-02,  ...,  1.9019e-01,\n",
            "            1.7110e-02,  1.6979e-01],\n",
            "          [ 2.7306e-01, -2.2581e-01,  1.8308e-01,  ...,  7.7843e-02,\n",
            "            1.4354e-01, -2.7849e-02],\n",
            "          ...,\n",
            "          [ 1.7369e-02,  3.7052e-01,  2.5473e-01,  ...,  3.0436e-01,\n",
            "            4.9342e-02,  1.1069e-01],\n",
            "          [ 2.1815e-02,  9.8768e-02,  1.0575e-01,  ..., -1.2224e-01,\n",
            "            8.6691e-02, -5.7739e-02],\n",
            "          [-1.8875e-03,  3.6048e-02, -2.1964e-02,  ...,  5.4222e-02,\n",
            "           -2.4802e-03, -1.6651e-02]],\n",
            "\n",
            "         [[ 6.2348e-03,  2.9267e-01,  1.0014e-01,  ...,  8.5895e-02,\n",
            "            8.6559e-02, -5.9474e-02],\n",
            "          [ 2.2482e-02, -1.8561e-01, -7.5437e-02,  ..., -1.8478e-01,\n",
            "           -1.6936e-01, -7.6877e-02],\n",
            "          [-2.4625e-01,  2.5283e-01,  4.3523e-02,  ...,  2.4049e-01,\n",
            "            5.9650e-02, -8.3432e-02],\n",
            "          ...,\n",
            "          [-1.3553e-01, -1.7963e-01, -5.6232e-02,  ..., -7.9376e-02,\n",
            "           -1.0098e-01, -1.2430e-01],\n",
            "          [ 3.2796e-02,  7.1020e-02,  2.7434e-02,  ...,  9.3500e-02,\n",
            "           -4.9377e-02, -3.2697e-02],\n",
            "          [-1.1298e-01,  8.0444e-02, -1.2870e-01,  ..., -8.5895e-04,\n",
            "           -6.4781e-02, -1.1819e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.7130e-01, -1.3264e-01, -4.5081e-02,  ..., -6.8453e-02,\n",
            "            1.0774e-01, -9.1743e-02],\n",
            "          [ 2.0507e-01,  2.6287e-01,  3.3917e-02,  ..., -3.1096e-01,\n",
            "           -1.2767e-01,  1.0981e-01],\n",
            "          [-5.2522e-02, -1.1332e-01, -2.6339e-02,  ..., -3.7420e-01,\n",
            "           -3.8744e-01,  2.8095e-01],\n",
            "          ...,\n",
            "          [ 1.6791e-01,  3.8247e-02,  4.6992e-02,  ...,  6.5408e-02,\n",
            "           -1.8715e-01, -1.6358e-01],\n",
            "          [ 1.4212e-02, -2.1265e-01, -9.1937e-02,  ..., -2.2022e-01,\n",
            "           -1.6130e-01,  1.5377e-01],\n",
            "          [-6.2021e-02,  1.9993e-01,  1.3437e-01,  ...,  8.4524e-02,\n",
            "            2.3879e-02,  1.4015e-01]],\n",
            "\n",
            "         [[ 2.8984e-02,  1.6412e-01,  8.5529e-02,  ...,  2.1707e-01,\n",
            "            7.9490e-02,  1.2093e-01],\n",
            "          [-2.0100e-01, -5.5005e-01,  3.4655e-02,  ..., -5.8638e-01,\n",
            "            1.1009e-02, -8.9666e-02],\n",
            "          [ 6.5327e-02, -1.0394e-01,  1.4743e-01,  ...,  5.5985e-02,\n",
            "            6.7004e-02, -4.6874e-02],\n",
            "          ...,\n",
            "          [-7.0660e-02, -4.9281e-01,  6.3078e-02,  ..., -5.2061e-01,\n",
            "           -1.1566e-01, -4.9742e-02],\n",
            "          [ 7.6801e-02, -9.7633e-02, -7.9036e-02,  ..., -3.8410e-02,\n",
            "            3.3410e-02,  4.3228e-02],\n",
            "          [-8.3003e-02, -3.5515e-01,  2.0852e-02,  ..., -1.1101e-01,\n",
            "            1.0198e-01, -4.5547e-02]],\n",
            "\n",
            "         [[-2.4559e-01, -1.5742e-01, -8.4623e-02,  ..., -1.3506e-01,\n",
            "           -1.6001e-02,  1.2721e-01],\n",
            "          [ 9.1351e-02,  2.0124e-01,  1.0418e-01,  ...,  5.0883e-01,\n",
            "            9.3031e-02,  2.6002e-01],\n",
            "          [-8.9798e-02,  1.3982e-01,  4.8033e-02,  ...,  2.3057e-01,\n",
            "           -9.5765e-02,  2.0383e-01],\n",
            "          ...,\n",
            "          [-1.3016e-01,  3.2085e-01,  3.7656e-02,  ...,  3.9161e-01,\n",
            "            5.6952e-05,  1.7906e-01],\n",
            "          [ 6.6569e-02,  5.7126e-02, -7.3658e-02,  ..., -9.6599e-02,\n",
            "           -7.8828e-03,  6.3351e-02],\n",
            "          [ 5.8538e-02,  3.3510e-01,  1.1078e-02,  ...,  4.6469e-01,\n",
            "           -8.9058e-02,  4.7027e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.9774e-01, -4.6243e-02, -1.2914e-01,  ..., -6.1694e-03,\n",
            "            9.0291e-02,  1.5223e-01],\n",
            "          [-2.0254e-02, -2.3743e-01,  1.6111e-01,  ..., -2.3788e-01,\n",
            "            3.8673e-01, -6.3393e-02],\n",
            "          [-5.1368e-02,  1.9831e-01, -3.2620e-04,  ...,  2.3366e-01,\n",
            "           -1.9231e-01,  9.8179e-02],\n",
            "          ...,\n",
            "          [ 2.0660e-01, -7.3622e-02,  5.3166e-02,  ..., -3.4816e-01,\n",
            "            3.1702e-01, -1.7620e-01],\n",
            "          [-8.3693e-02, -1.0441e-01,  6.6334e-02,  ...,  6.4770e-02,\n",
            "           -3.7178e-02,  3.3899e-02],\n",
            "          [ 1.9725e-01, -2.8750e-01,  9.6899e-02,  ..., -2.4405e-01,\n",
            "            4.2781e-02, -8.2253e-02]],\n",
            "\n",
            "         [[ 1.7421e-01,  1.6740e-01,  1.8295e-01,  ..., -7.4753e-03,\n",
            "            3.2698e-01, -3.0487e-01],\n",
            "          [-5.6772e-02,  5.7523e-01, -9.3350e-02,  ...,  7.2300e-01,\n",
            "           -3.2945e-01,  2.8519e-01],\n",
            "          [ 1.5762e-01, -9.2120e-02,  1.1953e-01,  ...,  3.2212e-03,\n",
            "            5.4170e-02,  8.8342e-02],\n",
            "          ...,\n",
            "          [ 4.0767e-02,  2.1526e-01,  5.1429e-02,  ...,  3.1817e-01,\n",
            "           -1.8437e-02,  3.2829e-01],\n",
            "          [ 2.1177e-02,  9.0694e-02,  2.4994e-02,  ..., -1.2217e-01,\n",
            "           -1.4852e-02,  5.3738e-02],\n",
            "          [-1.1732e-01, -1.2112e-01, -2.4507e-02,  ..., -1.6643e-02,\n",
            "           -5.3171e-02, -4.7102e-02]],\n",
            "\n",
            "         [[ 1.5539e-01,  2.4140e-01,  2.2545e-01,  ...,  4.3663e-01,\n",
            "           -2.3081e-01, -2.3161e-02],\n",
            "          [-4.6797e-02, -1.0306e-02, -1.0133e-01,  ...,  3.7578e-01,\n",
            "           -1.8248e-02, -6.8520e-01],\n",
            "          [-2.1699e-01,  2.1888e-01,  1.5800e-01,  ...,  2.2987e-02,\n",
            "           -2.6903e-01,  1.0458e-01],\n",
            "          ...,\n",
            "          [-1.3321e-01, -1.2022e-01, -1.3383e-01,  ..., -4.3678e-01,\n",
            "           -1.7826e-01, -2.0732e-01],\n",
            "          [-1.0380e-01,  5.3384e-02, -1.1311e-01,  ...,  3.0151e-01,\n",
            "           -6.5607e-02,  1.1274e-01],\n",
            "          [-6.3489e-02, -8.5056e-02, -3.0569e-03,  ..., -1.1923e-01,\n",
            "           -6.5685e-02, -9.5835e-02]]]], device='cuda:0',\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[-2.2078, -2.0057, -2.0900,  ..., -2.0642, -2.1052, -2.0549],\n",
            "          [-2.3478, -2.2886, -2.2945,  ..., -2.3132, -2.3962, -2.2593],\n",
            "          [-2.4545, -2.3926, -2.3806,  ..., -2.2516, -2.2589, -2.1954],\n",
            "          ...,\n",
            "          [-2.6035, -2.2765, -2.2586,  ..., -2.2074, -2.2667, -2.4376],\n",
            "          [-2.6099, -2.2831, -2.2197,  ..., -2.3414, -2.4186, -2.5153],\n",
            "          [-2.5950, -2.4409, -2.3767,  ..., -2.5969, -2.6930, -2.6033]],\n",
            "\n",
            "         [[-2.4836, -2.6341, -2.5350,  ..., -2.6468, -2.6585, -2.8253],\n",
            "          [-2.4283, -2.7350, -2.7798,  ..., -2.7780, -2.6629, -2.5911],\n",
            "          [-2.4809, -2.7681, -2.8425,  ..., -2.8796, -2.6671, -2.5740],\n",
            "          ...,\n",
            "          [-2.6404, -2.9156, -2.9203,  ..., -3.0344, -3.0013, -2.8785],\n",
            "          [-2.5660, -2.8150, -2.7508,  ..., -2.9121, -2.8927, -2.7719],\n",
            "          [-2.5874, -2.6866, -2.6362,  ..., -2.7328, -2.6693, -2.5777]],\n",
            "\n",
            "         [[-2.6589, -2.8439, -3.0778,  ..., -2.7906, -2.7481, -2.5278],\n",
            "          [-3.2105, -3.3707, -3.5481,  ..., -3.3848, -3.2407, -2.8588],\n",
            "          [-3.2303, -3.4650, -3.6427,  ..., -3.2776, -3.1686, -2.9027],\n",
            "          ...,\n",
            "          [-2.5954, -2.6563, -2.6591,  ..., -2.3350, -2.5410, -2.4742],\n",
            "          [-2.5424, -2.7099, -2.6871,  ..., -2.2772, -2.4727, -2.4916],\n",
            "          [-2.4609, -2.9172, -2.9205,  ..., -2.4205, -2.5605, -2.6154]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.2025, -3.3007, -3.2773,  ..., -3.4333, -3.3590, -3.2967],\n",
            "          [-3.2860, -3.3403, -3.3767,  ..., -3.5542, -3.5212, -3.4142],\n",
            "          [-3.2382, -3.3140, -3.3385,  ..., -3.3618, -3.3603, -3.2980],\n",
            "          ...,\n",
            "          [-3.2082, -2.9488, -2.9109,  ..., -2.5476, -2.5467, -2.5860],\n",
            "          [-3.0570, -2.7706, -2.7495,  ..., -2.5072, -2.5119, -2.5609],\n",
            "          [-2.9420, -2.7624, -2.8209,  ..., -2.5979, -2.6063, -2.6434]],\n",
            "\n",
            "         [[-2.2425, -2.0728, -2.0782,  ..., -2.0608, -2.1019, -2.0165],\n",
            "          [-2.5723, -2.3119, -2.2463,  ..., -2.2443, -2.2219, -2.2639],\n",
            "          [-2.2890, -2.0742, -2.0311,  ..., -2.1362, -2.1507, -2.2802],\n",
            "          ...,\n",
            "          [-2.5067, -2.6826, -2.6439,  ..., -2.3858, -2.2517, -1.9597],\n",
            "          [-2.3590, -2.5682, -2.5377,  ..., -2.3824, -2.2370, -2.0237],\n",
            "          [-2.4453, -2.5984, -2.5855,  ..., -2.3898, -2.2858, -2.2480]],\n",
            "\n",
            "         [[-2.4809, -2.6420, -2.6799,  ..., -2.9410, -2.8105, -2.5171],\n",
            "          [-2.6163, -2.7529, -2.7698,  ..., -2.8362, -2.7891, -2.5981],\n",
            "          [-2.7489, -2.9229, -2.9396,  ..., -2.9051, -2.8804, -2.7107],\n",
            "          ...,\n",
            "          [-2.5551, -2.7727, -2.7904,  ..., -3.1271, -3.0468, -2.8946],\n",
            "          [-2.5454, -2.8099, -2.8823,  ..., -3.0351, -2.9784, -2.8096],\n",
            "          [-2.4598, -2.6991, -2.6735,  ..., -2.7736, -2.7370, -2.5467]]],\n",
            "\n",
            "\n",
            "        [[[-2.7576, -2.7927, -2.8690,  ..., -2.5647, -2.6196, -2.4161],\n",
            "          [-2.8224, -2.6739, -2.7249,  ..., -2.6638, -2.6112, -2.5385],\n",
            "          [-2.9436, -2.6944, -2.7703,  ..., -2.8633, -2.7399, -2.5919],\n",
            "          ...,\n",
            "          [-2.6600, -2.8596, -2.7245,  ..., -2.6316, -2.6198, -2.6229],\n",
            "          [-2.7494, -2.9137, -2.7659,  ..., -2.6763, -2.6608, -2.6932],\n",
            "          [-2.7082, -2.7855, -2.7600,  ..., -2.5619, -2.6200, -2.6677]],\n",
            "\n",
            "         [[-2.3451, -2.1518, -2.0151,  ..., -2.3677, -2.3678, -2.3407],\n",
            "          [-2.5196, -2.2274, -2.0861,  ..., -2.5986, -2.5624, -2.2318],\n",
            "          [-2.6066, -2.1570, -1.9687,  ..., -2.7487, -2.6998, -2.3425],\n",
            "          ...,\n",
            "          [-2.3586, -2.4206, -2.5367,  ..., -2.8145, -2.8084, -2.7315],\n",
            "          [-2.2495, -2.3725, -2.4525,  ..., -2.8995, -2.8955, -2.8044],\n",
            "          [-2.4936, -2.5593, -2.5354,  ..., -2.8073, -2.7810, -2.7251]],\n",
            "\n",
            "         [[-2.6338, -2.5627, -2.7030,  ..., -2.4736, -2.4371, -2.4023],\n",
            "          [-2.5454, -2.5601, -2.7644,  ..., -3.1557, -3.0390, -2.8417],\n",
            "          [-2.4739, -2.6419, -2.8042,  ..., -3.2774, -3.1453, -2.9113],\n",
            "          ...,\n",
            "          [-2.3714, -2.6480, -2.7282,  ..., -2.5744, -2.5159, -2.1853],\n",
            "          [-2.3716, -2.6358, -2.7486,  ..., -2.6058, -2.5664, -2.1888],\n",
            "          [-2.1914, -2.4937, -2.4857,  ..., -2.5185, -2.5378, -2.2726]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7596, -2.8280, -2.8322,  ..., -2.9186, -2.8649, -2.8747],\n",
            "          [-2.8050, -2.8371, -2.8374,  ..., -3.2105, -3.2286, -3.0331],\n",
            "          [-2.8093, -2.7889, -2.7665,  ..., -3.1236, -3.1500, -2.9563],\n",
            "          ...,\n",
            "          [-2.5421, -2.4568, -2.4995,  ..., -2.6407, -2.6995, -2.9522],\n",
            "          [-2.5691, -2.5978, -2.6806,  ..., -2.7718, -2.7841, -3.0397],\n",
            "          [-2.3921, -2.4052, -2.4653,  ..., -2.6624, -2.6559, -2.7442]],\n",
            "\n",
            "         [[-2.5174, -2.7140, -2.8375,  ..., -2.2733, -2.2810, -2.1783],\n",
            "          [-2.2534, -2.6170, -2.7500,  ..., -2.3392, -2.2984, -2.3822],\n",
            "          [-2.0780, -2.4832, -2.6103,  ..., -2.1815, -2.2063, -2.2998],\n",
            "          ...,\n",
            "          [-2.3101, -2.2353, -2.2485,  ..., -2.2423, -2.2284, -2.3438],\n",
            "          [-2.2895, -2.2440, -2.2374,  ..., -2.2991, -2.2693, -2.3796],\n",
            "          [-2.3162, -2.2408, -2.2693,  ..., -2.2595, -2.2543, -2.2881]],\n",
            "\n",
            "         [[-2.4154, -2.3296, -2.2560,  ..., -2.6979, -2.6005, -2.6713],\n",
            "          [-2.5095, -2.4567, -2.3537,  ..., -2.7590, -2.7282, -2.7600],\n",
            "          [-2.5629, -2.3305, -2.2443,  ..., -2.8543, -2.8380, -2.7424],\n",
            "          ...,\n",
            "          [-2.8935, -2.6508, -2.6953,  ..., -2.8716, -2.8737, -2.6563],\n",
            "          [-2.7846, -2.5671, -2.5906,  ..., -2.7813, -2.8122, -2.6150],\n",
            "          [-2.6751, -2.4770, -2.5085,  ..., -2.6146, -2.6950, -2.7608]]],\n",
            "\n",
            "\n",
            "        [[[-2.4344, -2.1988, -2.2643,  ..., -1.9856, -2.0029, -2.1813],\n",
            "          [-2.7463, -2.5927, -2.5948,  ..., -2.1215, -2.0883, -2.3238],\n",
            "          [-2.7970, -2.6305, -2.5781,  ..., -2.1850, -2.1436, -2.3138],\n",
            "          ...,\n",
            "          [-2.2700, -2.1211, -2.0033,  ..., -2.3726, -2.3426, -2.3950],\n",
            "          [-2.4350, -2.2683, -2.1265,  ..., -2.3496, -2.3475, -2.4099],\n",
            "          [-2.6757, -2.6090, -2.5822,  ..., -2.6032, -2.6432, -2.6768]],\n",
            "\n",
            "         [[-2.4213, -2.5627, -2.5001,  ..., -2.6688, -2.7140, -2.9117],\n",
            "          [-2.5705, -2.4626, -2.4516,  ..., -2.7401, -2.7406, -2.4057],\n",
            "          [-2.5271, -2.4064, -2.3773,  ..., -2.8322, -2.8285, -2.4246],\n",
            "          ...,\n",
            "          [-2.1569, -2.0639, -2.2360,  ..., -2.5195, -2.5360, -2.4883],\n",
            "          [-2.1185, -2.0460, -2.2126,  ..., -2.4459, -2.4476, -2.4165],\n",
            "          [-2.4876, -2.2625, -2.2185,  ..., -2.4254, -2.4064, -2.3352]],\n",
            "\n",
            "         [[-2.6596, -2.7905, -2.9612,  ..., -2.7457, -2.6846, -2.2683],\n",
            "          [-2.7025, -2.9242, -3.0560,  ..., -2.9415, -2.8166, -2.2649],\n",
            "          [-2.5916, -3.0598, -3.2141,  ..., -2.8897, -2.7706, -2.2550],\n",
            "          ...,\n",
            "          [-3.1092, -3.5198, -3.4941,  ..., -2.6463, -2.5930, -2.2703],\n",
            "          [-2.9122, -3.2830, -3.2743,  ..., -2.5583, -2.5393, -2.2848],\n",
            "          [-2.5269, -2.8962, -2.8128,  ..., -2.6339, -2.6505, -2.4424]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5635, -2.9247, -2.8405,  ..., -2.9141, -2.8777, -2.9678],\n",
            "          [-2.8155, -3.0956, -3.0395,  ..., -3.1613, -3.1755, -3.2743],\n",
            "          [-2.7831, -2.9703, -2.9282,  ..., -3.1307, -3.1746, -3.2545],\n",
            "          ...,\n",
            "          [-2.7221, -2.6379, -2.6389,  ..., -2.8562, -2.8340, -3.0169],\n",
            "          [-2.6233, -2.5775, -2.6218,  ..., -2.8905, -2.8587, -3.0251],\n",
            "          [-2.4734, -2.4356, -2.4795,  ..., -2.7036, -2.6676, -2.7411]],\n",
            "\n",
            "         [[-2.1474, -1.8643, -1.9363,  ..., -1.9448, -1.9139, -1.7978],\n",
            "          [-2.3410, -2.1006, -2.0504,  ..., -2.1337, -2.0844, -2.1004],\n",
            "          [-2.2953, -2.0873, -2.0586,  ..., -2.1136, -2.0673, -2.1172],\n",
            "          ...,\n",
            "          [-2.5288, -2.5520, -2.5179,  ..., -2.4118, -2.3598, -2.2112],\n",
            "          [-2.3939, -2.4036, -2.4057,  ..., -2.5242, -2.4452, -2.3078],\n",
            "          [-2.4400, -2.4716, -2.4877,  ..., -2.6011, -2.5244, -2.5270]],\n",
            "\n",
            "         [[-2.5263, -2.5823, -2.5822,  ..., -2.4645, -2.4409, -2.5048],\n",
            "          [-2.5548, -2.6410, -2.5786,  ..., -2.6171, -2.6545, -2.6565],\n",
            "          [-2.6383, -2.6573, -2.5996,  ..., -2.6370, -2.6848, -2.7251],\n",
            "          ...,\n",
            "          [-2.8757, -2.9721, -2.9024,  ..., -2.9242, -2.9407, -2.8499],\n",
            "          [-2.7921, -2.8042, -2.7447,  ..., -2.8502, -2.8405, -2.7267],\n",
            "          [-2.6444, -2.6484, -2.7096,  ..., -2.8336, -2.8833, -2.7573]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.6021, -2.4696, -2.6691,  ..., -2.5598, -2.5588, -2.3684],\n",
            "          [-2.6520, -2.7632, -3.0238,  ..., -2.2423, -2.3022, -2.3632],\n",
            "          [-2.7488, -2.8142, -3.0965,  ..., -2.2525, -2.3092, -2.3441],\n",
            "          ...,\n",
            "          [-2.4920, -2.4041, -2.4300,  ..., -2.3585, -2.2898, -2.4009],\n",
            "          [-2.5167, -2.4402, -2.4425,  ..., -2.4449, -2.3837, -2.4291],\n",
            "          [-2.6197, -2.5939, -2.5442,  ..., -2.6525, -2.6563, -2.6036]],\n",
            "\n",
            "         [[-2.5196, -2.5577, -2.2916,  ..., -2.2029, -2.2551, -2.3503],\n",
            "          [-3.0811, -3.1374, -3.0357,  ..., -2.4314, -2.3413, -2.5246],\n",
            "          [-3.1359, -3.2533, -3.1707,  ..., -2.4183, -2.3163, -2.4993],\n",
            "          ...,\n",
            "          [-2.5524, -2.6675, -2.7643,  ..., -2.5372, -2.5840, -2.5287],\n",
            "          [-2.6330, -2.6773, -2.7623,  ..., -2.4592, -2.5061, -2.4570],\n",
            "          [-2.6757, -2.6317, -2.6049,  ..., -2.3561, -2.4565, -2.5246]],\n",
            "\n",
            "         [[-2.9488, -3.0635, -3.1447,  ..., -3.0464, -3.0626, -2.9382],\n",
            "          [-2.5900, -3.0528, -3.2858,  ..., -3.8724, -3.7859, -3.2966],\n",
            "          [-2.4768, -2.8998, -3.1473,  ..., -3.9572, -3.8759, -3.4810],\n",
            "          ...,\n",
            "          [-2.1675, -2.3214, -2.3015,  ..., -2.2713, -2.3890, -2.5205],\n",
            "          [-2.0706, -2.2364, -2.2450,  ..., -2.1955, -2.3330, -2.5510],\n",
            "          [-1.9623, -2.2122, -2.2449,  ..., -2.3526, -2.4110, -2.5398]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.1213, -3.5144, -3.5141,  ..., -3.0941, -2.8572, -2.9914],\n",
            "          [-3.2474, -3.3591, -3.2750,  ..., -3.3449, -3.2336, -3.1472],\n",
            "          [-3.2937, -3.3457, -3.2368,  ..., -3.2022, -3.2031, -3.0512],\n",
            "          ...,\n",
            "          [-2.5508, -2.3593, -2.3412,  ..., -2.7887, -2.9352, -2.9139],\n",
            "          [-2.5819, -2.4333, -2.4239,  ..., -2.9953, -3.0549, -2.9310],\n",
            "          [-2.5501, -2.4801, -2.5602,  ..., -2.7057, -2.7970, -2.6984]],\n",
            "\n",
            "         [[-2.3160, -2.2949, -2.3635,  ..., -2.2922, -2.3081, -2.5092],\n",
            "          [-2.5157, -2.4539, -2.2894,  ..., -2.2856, -2.2801, -2.5504],\n",
            "          [-2.3088, -2.2680, -2.1321,  ..., -2.4063, -2.3043, -2.5117],\n",
            "          ...,\n",
            "          [-2.4160, -2.5730, -2.6635,  ..., -2.3131, -2.1204, -2.1484],\n",
            "          [-2.4365, -2.5513, -2.6444,  ..., -2.3861, -2.1754, -2.1909],\n",
            "          [-2.5147, -2.5193, -2.6653,  ..., -2.3819, -2.1975, -2.1259]],\n",
            "\n",
            "         [[-2.1555, -2.2850, -2.2580,  ..., -2.4704, -2.4815, -2.6241],\n",
            "          [-2.4390, -2.4400, -2.3950,  ..., -2.9473, -2.8074, -2.7351],\n",
            "          [-2.5737, -2.5392, -2.4894,  ..., -3.1761, -3.0550, -2.7965],\n",
            "          ...,\n",
            "          [-2.4525, -2.5469, -2.6810,  ..., -3.2677, -3.2518, -2.9846],\n",
            "          [-2.4454, -2.4244, -2.5403,  ..., -3.1459, -3.1707, -2.8846],\n",
            "          [-2.4815, -2.4848, -2.5767,  ..., -2.8217, -2.9076, -2.7731]]],\n",
            "\n",
            "\n",
            "        [[[-2.3172, -2.3804, -2.4489,  ..., -2.5833, -2.6880, -2.4729],\n",
            "          [-2.3187, -2.4388, -2.4597,  ..., -2.4485, -2.5547, -2.6021],\n",
            "          [-2.3055, -2.5464, -2.5266,  ..., -2.4048, -2.4808, -2.5697],\n",
            "          ...,\n",
            "          [-2.4322, -2.8979, -2.8210,  ..., -2.9134, -2.8993, -2.7230],\n",
            "          [-2.5489, -2.8810, -2.8392,  ..., -2.8217, -2.8020, -2.6579],\n",
            "          [-2.5642, -2.7931, -2.7757,  ..., -2.6909, -2.7095, -2.6708]],\n",
            "\n",
            "         [[-2.2086, -2.4812, -2.5042,  ..., -2.2510, -2.3891, -2.4010],\n",
            "          [-1.9909, -2.3694, -2.4137,  ..., -2.1039, -2.2023, -2.0210],\n",
            "          [-2.1081, -2.3876, -2.4366,  ..., -2.3264, -2.3938, -2.1631],\n",
            "          ...,\n",
            "          [-2.0784, -2.3685, -2.4031,  ..., -2.4921, -2.7086, -2.7829],\n",
            "          [-2.1988, -2.4758, -2.4863,  ..., -2.5362, -2.7174, -2.7654],\n",
            "          [-2.4682, -2.6102, -2.4328,  ..., -2.4617, -2.5069, -2.4809]],\n",
            "\n",
            "         [[-3.0209, -2.7208, -2.7171,  ..., -2.7695, -2.5681, -2.5422],\n",
            "          [-3.2842, -3.2454, -3.2658,  ..., -3.3571, -3.1798, -2.8412],\n",
            "          [-3.2582, -3.4282, -3.4024,  ..., -3.4183, -3.2478, -2.9998],\n",
            "          ...,\n",
            "          [-3.1991, -3.4774, -3.2766,  ..., -2.8258, -2.8197, -2.4545],\n",
            "          [-3.0810, -3.4465, -3.2051,  ..., -2.8088, -2.7712, -2.4392],\n",
            "          [-2.7627, -2.9609, -2.8250,  ..., -2.8086, -2.8327, -2.5719]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8590, -2.8958, -2.8388,  ..., -2.7262, -2.6307, -2.7801],\n",
            "          [-2.7678, -2.6639, -2.6720,  ..., -2.8387, -2.7424, -2.7802],\n",
            "          [-2.6900, -2.4934, -2.5388,  ..., -2.7834, -2.7071, -2.6677],\n",
            "          ...,\n",
            "          [-2.6201, -2.4977, -2.7071,  ..., -2.8497, -2.8696, -3.0138],\n",
            "          [-2.5280, -2.4668, -2.6797,  ..., -2.7627, -2.8032, -2.9448],\n",
            "          [-2.4762, -2.4919, -2.6443,  ..., -2.6353, -2.6540, -2.8032]],\n",
            "\n",
            "         [[-2.2732, -2.3272, -2.3942,  ..., -2.1140, -2.1736, -2.1931],\n",
            "          [-2.4334, -2.4058, -2.4214,  ..., -2.0792, -2.1629, -2.4238],\n",
            "          [-2.4595, -2.4384, -2.4830,  ..., -1.9316, -2.0317, -2.3324],\n",
            "          ...,\n",
            "          [-2.5580, -2.6121, -2.5975,  ..., -2.4904, -2.3430, -2.1086],\n",
            "          [-2.5932, -2.6263, -2.6099,  ..., -2.4997, -2.3354, -2.1956],\n",
            "          [-2.4896, -2.4175, -2.5157,  ..., -2.3864, -2.3221, -2.2835]],\n",
            "\n",
            "         [[-2.5352, -2.4980, -2.4749,  ..., -2.6271, -2.5580, -2.7001],\n",
            "          [-2.4039, -2.3533, -2.3227,  ..., -2.6531, -2.5714, -2.6519],\n",
            "          [-2.3880, -2.3136, -2.2891,  ..., -2.6661, -2.6215, -2.6625],\n",
            "          ...,\n",
            "          [-2.4068, -2.2510, -2.0823,  ..., -2.3246, -2.5115, -2.7125],\n",
            "          [-2.2458, -2.1035, -1.9660,  ..., -2.3838, -2.5267, -2.6433],\n",
            "          [-2.3610, -2.2279, -2.1700,  ..., -2.5923, -2.6748, -2.6743]]],\n",
            "\n",
            "\n",
            "        [[[-2.1681, -2.3246, -2.5411,  ..., -3.0019, -3.0984, -2.7815],\n",
            "          [-2.3192, -2.4983, -2.5021,  ..., -2.7161, -2.8449, -2.5345],\n",
            "          [-2.3859, -2.5763, -2.5362,  ..., -2.6132, -2.7264, -2.4629],\n",
            "          ...,\n",
            "          [-2.2863, -2.5295, -2.4313,  ..., -2.5348, -2.5404, -2.4276],\n",
            "          [-2.5586, -2.7677, -2.6567,  ..., -2.5878, -2.6104, -2.5037],\n",
            "          [-2.6633, -2.8027, -2.7861,  ..., -2.5243, -2.6401, -2.6110]],\n",
            "\n",
            "         [[-2.4683, -2.4953, -2.4334,  ..., -2.1862, -2.2217, -2.3771],\n",
            "          [-2.2748, -2.3111, -2.4160,  ..., -2.0543, -2.1369, -2.0651],\n",
            "          [-2.3031, -2.3367, -2.4566,  ..., -2.0714, -2.1209, -2.0038],\n",
            "          ...,\n",
            "          [-2.1561, -2.6754, -2.6704,  ..., -2.7802, -2.8892, -2.7996],\n",
            "          [-2.1485, -2.6030, -2.6348,  ..., -2.8636, -2.9124, -2.8471],\n",
            "          [-2.5514, -2.8410, -2.7879,  ..., -2.7936, -2.7331, -2.5824]],\n",
            "\n",
            "         [[-2.7555, -2.7898, -2.9005,  ..., -3.1759, -3.0587, -2.6378],\n",
            "          [-3.0626, -3.2529, -3.3113,  ..., -3.8291, -3.5215, -3.0341],\n",
            "          [-3.0187, -3.2772, -3.3464,  ..., -3.8614, -3.5398, -3.1622],\n",
            "          ...,\n",
            "          [-3.1206, -3.1546, -3.0995,  ..., -2.5309, -2.4733, -2.2594],\n",
            "          [-2.9560, -3.0040, -2.9516,  ..., -2.4813, -2.4241, -2.2310],\n",
            "          [-2.5482, -2.7080, -2.5998,  ..., -2.5329, -2.5298, -2.5027]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5831, -2.5877, -2.6362,  ..., -2.7759, -2.7482, -2.7188],\n",
            "          [-2.7290, -2.8264, -2.8502,  ..., -3.0151, -3.0623, -2.8273],\n",
            "          [-2.6744, -2.7331, -2.7379,  ..., -2.8342, -2.8953, -2.6821],\n",
            "          ...,\n",
            "          [-2.7030, -2.6546, -2.7111,  ..., -2.5762, -2.7202, -2.9624],\n",
            "          [-2.6609, -2.6045, -2.6932,  ..., -2.7092, -2.7770, -2.9933],\n",
            "          [-2.4064, -2.3334, -2.3950,  ..., -2.7362, -2.8134, -2.8161]],\n",
            "\n",
            "         [[-2.4162, -2.3817, -2.4931,  ..., -2.2534, -2.2407, -2.3170],\n",
            "          [-2.5381, -2.5091, -2.4584,  ..., -2.4414, -2.4128, -2.6895],\n",
            "          [-2.4588, -2.4163, -2.3554,  ..., -2.4011, -2.3853, -2.6516],\n",
            "          ...,\n",
            "          [-2.6733, -2.4670, -2.4793,  ..., -2.7866, -2.5837, -2.4480],\n",
            "          [-2.6520, -2.5036, -2.5078,  ..., -2.8541, -2.6285, -2.4912],\n",
            "          [-2.5432, -2.4251, -2.4356,  ..., -2.6002, -2.5354, -2.4910]],\n",
            "\n",
            "         [[-2.5914, -2.6221, -2.4693,  ..., -2.8530, -2.7456, -2.6179],\n",
            "          [-2.5182, -2.5911, -2.4832,  ..., -2.8814, -2.7700, -2.6541],\n",
            "          [-2.5263, -2.6182, -2.4999,  ..., -2.9890, -2.9074, -2.6631],\n",
            "          ...,\n",
            "          [-2.6300, -2.7674, -2.8057,  ..., -3.0072, -3.0095, -2.8191],\n",
            "          [-2.5728, -2.6145, -2.6087,  ..., -2.7991, -2.8152, -2.6407],\n",
            "          [-2.4695, -2.4521, -2.4625,  ..., -2.5741, -2.6069, -2.6189]]]],\n",
            "       device='cuda:0')\n",
            "tensor([[[[-1.4279e-02, -3.7981e-01, -7.2942e-02,  ...,  1.6964e-01,\n",
            "           -6.4592e-02,  1.2243e-01],\n",
            "          [ 6.3746e-01,  3.7402e-01,  3.2227e-01,  ...,  3.3529e-01,\n",
            "            2.8629e-02,  1.5862e-01],\n",
            "          [-4.0152e-01, -3.3094e-01, -1.4859e-01,  ...,  1.6265e-01,\n",
            "           -7.9374e-02,  1.3105e-01],\n",
            "          ...,\n",
            "          [ 2.8791e-01,  3.6937e-02,  1.3850e-01,  ...,  2.3296e-01,\n",
            "            1.3070e-01,  2.2280e-01],\n",
            "          [ 7.8318e-03, -3.1422e-01, -1.4551e-01,  ...,  4.3347e-02,\n",
            "           -7.3344e-02,  1.0173e-01],\n",
            "          [ 1.9542e-02,  1.7512e-01, -1.0345e-01,  ...,  1.4517e-01,\n",
            "            8.1175e-02,  1.4465e-01]],\n",
            "\n",
            "         [[-8.9119e-02,  1.5725e-01,  3.5577e-01,  ..., -1.8175e-01,\n",
            "            3.4427e-02,  6.3798e-02],\n",
            "          [-9.9608e-02, -5.5296e-01, -2.6583e-01,  ..., -9.7804e-02,\n",
            "           -3.5910e-02, -7.9291e-03],\n",
            "          [ 1.4884e-01, -4.2078e-01,  6.7669e-02,  ..., -7.1259e-02,\n",
            "           -3.1260e-02, -7.1830e-02],\n",
            "          ...,\n",
            "          [-8.8057e-03, -5.4063e-01,  3.0394e-02,  ..., -3.9505e-01,\n",
            "           -1.6443e-02, -4.3842e-02],\n",
            "          [ 7.9248e-02, -4.9316e-02,  1.8632e-01,  ..., -1.2783e-01,\n",
            "            8.3095e-03,  1.9996e-03],\n",
            "          [ 1.9334e-03, -1.8743e-01,  1.1682e-01,  ..., -2.7660e-01,\n",
            "            1.6911e-02, -8.8358e-02]],\n",
            "\n",
            "         [[-2.3954e-01, -2.3883e-01, -3.8402e-02,  ..., -1.0816e-01,\n",
            "           -1.5647e-01, -1.1760e-02],\n",
            "          [ 2.6287e-01, -5.2276e-02, -2.2887e-01,  ...,  6.8922e-01,\n",
            "           -1.3046e-01,  1.5664e-01],\n",
            "          [-1.3845e-01,  3.7339e-01,  2.0549e-01,  ..., -5.8459e-02,\n",
            "           -1.3174e-01,  2.6951e-02],\n",
            "          ...,\n",
            "          [ 2.6392e-02,  4.5419e-01, -1.6475e-01,  ...,  5.6622e-01,\n",
            "           -8.0511e-02,  7.4923e-02],\n",
            "          [ 4.4806e-02, -1.1121e-01,  8.8615e-02,  ..., -1.3269e-01,\n",
            "           -1.0179e-01, -1.3872e-02],\n",
            "          [ 6.2532e-02,  2.5991e-01, -1.4785e-01,  ...,  3.5624e-01,\n",
            "           -6.2305e-02,  1.1155e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0749e-01, -3.9386e-01, -1.4075e-01,  ..., -7.9956e-02,\n",
            "            4.2870e-03,  1.3225e-01],\n",
            "          [ 8.9341e-02, -1.6364e-01,  5.2917e-01,  ..., -9.1609e-02,\n",
            "            7.2290e-02, -9.4231e-02],\n",
            "          [-1.7931e-01,  3.6362e-01, -1.2023e-01,  ..., -1.3131e-01,\n",
            "           -1.8336e-02,  2.6732e-02],\n",
            "          ...,\n",
            "          [ 2.6027e-01,  1.0043e-01, -2.4299e-02,  ...,  1.0050e-01,\n",
            "            1.0199e-01, -6.6793e-02],\n",
            "          [-7.1472e-02, -1.9572e-01, -1.2440e-01,  ..., -2.1768e-01,\n",
            "            6.3489e-03,  7.3845e-03],\n",
            "          [ 2.5609e-01, -2.5642e-01,  4.6641e-02,  ..., -1.5321e-01,\n",
            "            4.7720e-02, -1.0491e-01]],\n",
            "\n",
            "         [[-1.3221e-01,  7.3387e-02,  6.0630e-01,  ...,  2.5917e-01,\n",
            "            1.3804e-01,  1.0289e-02],\n",
            "          [-3.2009e-01,  1.4364e+00,  1.2574e-02,  ...,  2.8127e-03,\n",
            "           -6.9224e-03,  2.6354e-02],\n",
            "          [ 4.2378e-01, -1.2390e-01,  1.0925e-01,  ...,  3.2025e-01,\n",
            "            5.1258e-02,  4.2294e-02],\n",
            "          ...,\n",
            "          [-2.3407e-01,  1.2793e-01, -2.6135e-01,  ...,  2.5595e-02,\n",
            "           -6.5996e-02, -5.5340e-02],\n",
            "          [-3.2236e-03,  2.6898e-01,  1.1589e-01,  ...,  2.8400e-01,\n",
            "            6.4539e-02,  5.0675e-02],\n",
            "          [-1.8384e-01, -2.9717e-01, -8.2426e-02,  ..., -1.3229e-01,\n",
            "           -3.3988e-03, -8.7090e-02]],\n",
            "\n",
            "         [[-6.9313e-02,  2.6220e-01,  2.9152e-01,  ...,  8.4358e-02,\n",
            "           -3.5553e-02,  8.4291e-02],\n",
            "          [-2.5828e-01,  1.8240e-01, -2.9502e-01,  ..., -3.5494e-01,\n",
            "           -1.1987e-01, -1.7459e-01],\n",
            "          [-4.8071e-01,  3.4470e-01, -2.4657e-01,  ...,  6.4876e-02,\n",
            "            1.0983e-02, -1.9506e-03],\n",
            "          ...,\n",
            "          [-2.4790e-01, -2.7865e-01, -2.7279e-02,  ..., -4.4121e-01,\n",
            "           -1.4480e-01, -2.4835e-01],\n",
            "          [-1.9778e-01,  9.8101e-02, -1.8812e-01,  ...,  9.8324e-02,\n",
            "           -4.5683e-02,  7.0137e-02],\n",
            "          [ 1.3146e-01, -2.3257e-01, -5.0280e-02,  ..., -1.3194e-01,\n",
            "           -5.0840e-02, -4.5437e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.1274e-02, -4.0396e-01, -3.0843e-01,  ..., -1.6734e-01,\n",
            "           -6.3528e-02, -2.4741e-02],\n",
            "          [ 7.2365e-01,  4.2846e-01,  1.8604e-01,  ...,  3.4272e-01,\n",
            "            9.5887e-02,  6.4822e-02],\n",
            "          [-4.0683e-01, -2.1266e-01,  1.4863e-01,  ..., -8.4039e-02,\n",
            "           -4.1073e-01,  4.5686e-01],\n",
            "          ...,\n",
            "          [-1.0548e-01,  5.5725e-02,  2.7546e-01,  ...,  4.4314e-01,\n",
            "            1.6615e-02,  2.4463e-01],\n",
            "          [-1.2797e-01,  1.2252e-01,  2.0823e-01,  ..., -7.6173e-04,\n",
            "           -1.7754e-01,  1.4199e-01],\n",
            "          [ 8.8626e-02,  6.4914e-02, -3.2250e-01,  ...,  3.7510e-01,\n",
            "           -2.3785e-01,  2.5741e-01]],\n",
            "\n",
            "         [[ 6.9411e-02,  4.0067e-02,  4.0618e-02,  ...,  5.3987e-02,\n",
            "            2.5368e-02,  7.5787e-02],\n",
            "          [-6.1874e-02, -5.7767e-01,  2.2443e-01,  ..., -5.2975e-01,\n",
            "           -1.6195e-01,  1.0607e-01],\n",
            "          [ 3.8504e-01,  1.0623e-01,  2.5755e-01,  ...,  3.1960e-02,\n",
            "            3.3403e-01, -1.6044e-02],\n",
            "          ...,\n",
            "          [ 8.2591e-02, -3.1474e-01, -1.6292e-01,  ..., -1.3940e-01,\n",
            "            1.3373e-01,  1.9328e-01],\n",
            "          [-2.4121e-02,  5.6576e-02,  1.2409e-01,  ...,  1.0106e-01,\n",
            "            2.8669e-01,  1.6273e-01],\n",
            "          [ 7.4026e-02, -2.5711e-02,  1.5113e-01,  ..., -6.1200e-02,\n",
            "            7.8856e-02, -1.3209e-01]],\n",
            "\n",
            "         [[-2.4582e-01,  4.5427e-01, -5.1721e-02,  ...,  3.2667e-01,\n",
            "           -3.6146e-02,  4.6920e-02],\n",
            "          [ 4.0732e-01,  2.1593e-01,  2.4440e-01,  ...,  6.4198e-01,\n",
            "           -3.7270e-02, -2.6289e-01],\n",
            "          [ 1.7011e-01,  1.0417e+00, -1.8315e-01,  ...,  5.4238e-02,\n",
            "            6.8461e-02,  3.2656e-01],\n",
            "          ...,\n",
            "          [-1.3015e-01,  2.2601e-01,  3.2863e-02,  ...,  5.0115e-01,\n",
            "           -1.6447e-01, -2.5736e-01],\n",
            "          [-8.7339e-04,  5.7566e-02, -1.3552e-01,  ..., -1.3585e-02,\n",
            "           -7.6824e-02,  6.3911e-02],\n",
            "          [ 8.4732e-02,  3.5438e-01,  1.8454e-01,  ...,  3.2859e-01,\n",
            "           -4.0654e-01,  1.5200e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1814e-02,  7.3453e-02, -7.8793e-02,  ...,  7.1818e-02,\n",
            "           -4.3134e-02,  1.4866e-01],\n",
            "          [-8.5563e-02, -1.6508e+00,  2.8725e-01,  ..., -2.3437e-01,\n",
            "            1.8130e-01, -1.4146e-01],\n",
            "          [-5.3988e-01,  1.2567e+00, -1.2689e-01,  ...,  3.0661e-02,\n",
            "           -2.1007e-01,  2.8081e-01],\n",
            "          ...,\n",
            "          [ 1.0032e-01, -5.7668e-02,  1.0786e-01,  ..., -1.4810e-01,\n",
            "           -7.1151e-02, -2.0041e-01],\n",
            "          [ 3.9341e-02,  1.1847e-01, -1.3166e-01,  ...,  2.3409e-01,\n",
            "           -7.0755e-02,  3.0155e-01],\n",
            "          [ 1.7807e-01, -4.4270e-01,  1.9124e-02,  ..., -4.8270e-01,\n",
            "           -1.1525e-01, -1.9937e-01]],\n",
            "\n",
            "         [[ 2.0869e-01, -6.7881e-01,  6.1427e-01,  ...,  3.9886e-02,\n",
            "            1.2600e-01,  2.6757e-02],\n",
            "          [-2.8840e-01,  8.7153e-01, -4.0120e-01,  ..., -2.6129e-01,\n",
            "           -5.7258e-01,  1.8877e-01],\n",
            "          [ 4.8249e-01, -7.1446e-01,  3.3716e-01,  ...,  2.9935e-01,\n",
            "            2.2236e-01, -2.3514e-01],\n",
            "          ...,\n",
            "          [-1.9195e-01,  1.9207e-01, -1.3969e-02,  ...,  3.2111e-01,\n",
            "           -3.4759e-01,  4.4067e-01],\n",
            "          [-3.9746e-02, -2.2839e-01,  1.5653e-01,  ..., -1.0667e-01,\n",
            "            3.5297e-01, -2.5859e-01],\n",
            "          [-8.0554e-02, -3.4372e-01, -3.3824e-02,  ..., -6.6535e-02,\n",
            "            4.5081e-02,  2.0291e-01]],\n",
            "\n",
            "         [[-5.4364e-01,  5.3790e-01,  6.1859e-01,  ...,  2.1466e-01,\n",
            "            2.5526e-01, -9.4216e-02],\n",
            "          [ 2.6826e-01,  1.3904e-01, -6.5928e-02,  ..., -5.8619e-01,\n",
            "           -1.8050e-01, -1.0673e-01],\n",
            "          [-6.1862e-01,  9.8793e-01,  5.6357e-02,  ...,  4.7672e-01,\n",
            "           -3.0404e-01,  3.3744e-01],\n",
            "          ...,\n",
            "          [-1.7230e-01, -1.0725e-01, -2.5579e-02,  ..., -4.3576e-01,\n",
            "           -3.0078e-01, -1.4450e-01],\n",
            "          [-1.4391e-01,  4.0633e-01, -4.8266e-01,  ...,  4.3289e-01,\n",
            "           -3.0535e-01,  3.7632e-01],\n",
            "          [-6.2443e-03,  3.3763e-01, -1.5743e-01,  ..., -5.6589e-02,\n",
            "           -1.5691e-01, -2.7880e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.7136e-01,  5.5698e-02, -1.1104e-01,  ..., -1.5195e-01,\n",
            "           -2.3341e-02,  7.1879e-02],\n",
            "          [ 5.9736e-01,  6.9933e-01, -2.2528e-01,  ...,  5.7241e-01,\n",
            "            2.1607e-01,  2.0090e-01],\n",
            "          [-2.5248e-01, -5.5939e-01,  1.9564e-02,  ..., -1.6996e-01,\n",
            "           -1.9201e-01, -4.2103e-02],\n",
            "          ...,\n",
            "          [ 1.4032e-01,  4.3387e-03,  4.8234e-02,  ...,  3.1329e-01,\n",
            "            1.3689e-01,  5.2763e-02],\n",
            "          [ 6.3516e-02, -2.2777e-01, -6.4561e-02,  ..., -2.5063e-01,\n",
            "           -7.4064e-02, -3.8003e-03],\n",
            "          [-1.0760e-01,  9.2026e-02,  9.8962e-02,  ...,  9.2488e-02,\n",
            "           -6.1421e-02,  1.5747e-01]],\n",
            "\n",
            "         [[-9.9080e-02,  2.8872e-03,  2.5219e-01,  ...,  2.8760e-02,\n",
            "            4.5737e-02,  1.4538e-02],\n",
            "          [-4.2686e-01, -4.5766e-01,  7.7535e-02,  ..., -1.7045e-01,\n",
            "            8.7204e-02,  1.2936e-02],\n",
            "          [-1.5638e-02,  1.3668e-01, -1.3429e-01,  ...,  1.1237e-01,\n",
            "            2.6271e-01,  1.2831e-01],\n",
            "          ...,\n",
            "          [ 1.6036e-01, -3.5525e-01,  5.9714e-02,  ..., -6.0283e-02,\n",
            "            4.8475e-02, -1.7549e-01],\n",
            "          [ 5.9015e-02, -1.6663e-01,  2.4209e-02,  ..., -2.9821e-02,\n",
            "            2.2535e-01,  3.0146e-02],\n",
            "          [ 4.9072e-02, -3.4167e-01,  7.1620e-02,  ..., -6.6285e-02,\n",
            "           -7.8577e-02, -1.2092e-01]],\n",
            "\n",
            "         [[-3.4741e-01,  3.5884e-03, -1.2234e-01,  ..., -1.2945e-01,\n",
            "            2.3486e-03,  9.6289e-02],\n",
            "          [ 3.2713e-02,  2.5192e-02, -2.3164e-01,  ...,  7.2419e-01,\n",
            "            5.3569e-02, -4.1134e-02],\n",
            "          [-6.3503e-02,  4.0843e-01,  9.6073e-02,  ...,  1.0525e-01,\n",
            "           -1.5169e-02,  1.1692e-01],\n",
            "          ...,\n",
            "          [ 1.6682e-01,  3.6880e-01, -4.5275e-02,  ...,  4.0415e-01,\n",
            "           -2.6269e-02, -1.1163e-02],\n",
            "          [ 1.9845e-02,  7.9724e-02, -2.6063e-02,  ..., -4.0878e-02,\n",
            "            4.4289e-02,  1.4008e-01],\n",
            "          [ 9.6349e-02,  4.8535e-01,  1.5077e-02,  ...,  2.3456e-01,\n",
            "           -5.7168e-02,  7.7997e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.9264e-02,  7.9119e-02, -1.6746e-01,  ...,  4.4941e-02,\n",
            "           -3.6881e-02,  3.1542e-02],\n",
            "          [-1.9558e-01, -6.8291e-01,  1.3189e-02,  ..., -3.2121e-01,\n",
            "            5.7339e-02,  2.0975e-02],\n",
            "          [ 7.1769e-02,  5.9676e-01,  2.2899e-01,  ...,  2.0420e-01,\n",
            "           -1.6313e-01,  3.3606e-01],\n",
            "          ...,\n",
            "          [ 1.1403e-01,  2.4667e-02,  1.4952e-01,  ..., -3.3522e-01,\n",
            "            1.1799e-01, -3.3785e-01],\n",
            "          [-1.0973e-01, -2.6438e-02, -1.5785e-02,  ..., -2.5727e-03,\n",
            "           -1.2314e-01,  1.9675e-01],\n",
            "          [ 1.6217e-01, -3.1773e-01,  1.6477e-01,  ..., -1.9523e-01,\n",
            "            1.5312e-01, -1.8140e-01]],\n",
            "\n",
            "         [[ 1.3936e-01, -7.1725e-01,  6.5693e-01,  ...,  2.1237e-02,\n",
            "            6.2198e-02, -1.2276e-02],\n",
            "          [ 1.2846e-01,  1.1624e+00,  8.0234e-02,  ...,  4.0462e-01,\n",
            "           -3.3567e-01,  2.1468e-01],\n",
            "          [ 4.9337e-01, -8.9820e-01,  5.2440e-01,  ..., -3.1350e-02,\n",
            "            3.7950e-01, -1.7636e-01],\n",
            "          ...,\n",
            "          [ 3.4039e-02,  5.1363e-01,  3.8253e-02,  ...,  3.7382e-01,\n",
            "            1.2860e-02,  2.5923e-01],\n",
            "          [-6.6735e-03,  8.4117e-02,  3.1767e-02,  ...,  1.6839e-02,\n",
            "            1.9033e-01, -5.8763e-02],\n",
            "          [-1.9565e-02, -1.5450e-01, -8.7951e-02,  ...,  4.4861e-02,\n",
            "            5.0128e-02, -5.1118e-02]],\n",
            "\n",
            "         [[-1.0659e-01,  3.5103e-01, -2.6594e-01,  ...,  1.5161e-01,\n",
            "           -1.4467e-01,  4.6509e-03],\n",
            "          [ 1.9123e-02,  1.2545e+00, -1.6128e-01,  ..., -2.1212e-01,\n",
            "           -7.1164e-03, -2.3767e-01],\n",
            "          [-5.2148e-01,  3.3121e-01,  1.3312e-01,  ...,  8.6360e-02,\n",
            "           -5.4454e-04,  2.1100e-01],\n",
            "          ...,\n",
            "          [-1.2150e-01,  5.9118e-02, -1.9920e-01,  ..., -2.5526e-01,\n",
            "           -1.9508e-01, -1.0405e-01],\n",
            "          [-2.0993e-01, -9.9289e-02, -5.8323e-02,  ...,  6.5759e-02,\n",
            "           -8.2284e-02,  1.9826e-01],\n",
            "          [-1.1832e-01, -3.0166e-01,  2.8654e-02,  ..., -1.7210e-01,\n",
            "           -7.1760e-02,  8.0382e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.4337e-01,  1.1169e-01, -9.1366e-02,  ...,  1.7141e-03,\n",
            "           -9.6943e-02,  6.6921e-02],\n",
            "          [ 7.2954e-02,  3.1579e-01,  1.4858e-01,  ...,  3.5232e-01,\n",
            "            3.7298e-02,  1.4998e-01],\n",
            "          [-1.9410e-01, -9.8794e-02, -6.7005e-02,  ..., -1.8380e-01,\n",
            "           -7.9259e-02,  1.0584e-01],\n",
            "          ...,\n",
            "          [-1.2626e-02,  4.0098e-02,  4.3014e-02,  ...,  6.7045e-02,\n",
            "            2.7593e-02,  1.8703e-01],\n",
            "          [-8.7245e-02,  2.9370e-02, -6.6582e-02,  ..., -2.1599e-01,\n",
            "           -5.8300e-02,  5.5002e-02],\n",
            "          [ 1.6322e-01,  1.9999e-01,  4.4663e-02,  ...,  2.5521e-01,\n",
            "            5.5252e-02,  2.8308e-01]],\n",
            "\n",
            "         [[ 9.9704e-02, -2.9924e-02,  1.4766e-01,  ..., -3.0348e-02,\n",
            "            5.8358e-02,  1.7947e-02],\n",
            "          [-3.2696e-01, -3.5775e-01, -5.8791e-02,  ..., -3.9427e-01,\n",
            "            3.4157e-02, -2.5789e-01],\n",
            "          [-1.1352e-01, -1.1718e-01,  1.4094e-01,  ...,  2.4155e-02,\n",
            "            5.4981e-02,  6.6716e-02],\n",
            "          ...,\n",
            "          [-2.7802e-01, -3.5439e-01,  3.8995e-02,  ..., -6.2514e-01,\n",
            "           -4.2113e-03, -2.5397e-01],\n",
            "          [-7.3398e-02, -1.3614e-01, -1.0941e-02,  ..., -1.7956e-02,\n",
            "            1.8215e-02,  2.3172e-03],\n",
            "          [-1.8410e-02, -2.6587e-01,  1.3712e-02,  ..., -4.2604e-01,\n",
            "           -3.4075e-02, -9.6402e-02]],\n",
            "\n",
            "         [[-1.5857e-01, -3.0364e-01, -9.4216e-02,  ..., -1.5812e-01,\n",
            "           -1.5932e-02, -2.5430e-03],\n",
            "          [-5.4993e-02,  3.9417e-01,  5.4630e-03,  ...,  2.3271e-01,\n",
            "           -7.9480e-02,  2.0346e-01],\n",
            "          [-2.7426e-01,  1.5645e-01, -2.8159e-02,  ...,  7.4420e-02,\n",
            "            2.9339e-02,  6.4483e-03],\n",
            "          ...,\n",
            "          [-2.2058e-01,  4.0979e-01,  8.8267e-02,  ...,  3.8982e-01,\n",
            "           -1.4517e-02,  1.8560e-01],\n",
            "          [-1.4534e-01,  5.9313e-03, -3.0363e-02,  ...,  3.3509e-02,\n",
            "            2.3930e-02,  4.9310e-02],\n",
            "          [-1.3076e-02,  1.5099e-01,  3.1855e-02,  ...,  2.5976e-01,\n",
            "            3.2387e-02,  1.4717e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5647e-01, -1.9067e-01, -5.3307e-02,  ...,  4.9648e-04,\n",
            "           -5.1204e-03, -4.4591e-02],\n",
            "          [ 1.0950e-01, -4.4394e-01,  6.5262e-02,  ..., -1.5204e-01,\n",
            "            2.3410e-01, -1.1985e-02],\n",
            "          [ 6.9175e-02,  7.7523e-02, -1.2943e-01,  ...,  1.6166e-01,\n",
            "            6.7418e-03, -1.8076e-02],\n",
            "          ...,\n",
            "          [ 1.8488e-01, -1.1988e-01,  2.4460e-01,  ..., -2.2913e-01,\n",
            "            1.7178e-01, -1.3340e-03],\n",
            "          [ 1.1506e-02, -1.1948e-02,  3.8123e-02,  ...,  3.2086e-02,\n",
            "            5.6924e-02, -3.9072e-02],\n",
            "          [ 5.0386e-02, -2.9228e-01,  6.0244e-02,  ..., -3.1187e-01,\n",
            "            1.4773e-01, -9.9854e-02]],\n",
            "\n",
            "         [[ 9.1635e-02,  1.7788e-01,  1.6764e-01,  ...,  1.2574e-01,\n",
            "            2.8653e-02,  8.2214e-02],\n",
            "          [-1.1328e-02,  3.4280e-01, -8.4031e-02,  ...,  4.1603e-01,\n",
            "           -9.3752e-02, -2.8072e-02],\n",
            "          [ 2.1973e-01, -7.0785e-02,  2.3156e-01,  ...,  1.5195e-01,\n",
            "            8.3033e-03,  1.3811e-01],\n",
            "          ...,\n",
            "          [ 6.9445e-02,  2.9583e-01, -1.2423e-01,  ...,  3.3536e-01,\n",
            "           -1.1458e-01,  4.5430e-03],\n",
            "          [ 1.0485e-01,  8.0137e-02,  1.0695e-02,  ...,  1.3288e-01,\n",
            "            3.9666e-02,  2.0352e-02],\n",
            "          [-1.3665e-02, -1.2640e-01, -1.1118e-02,  ..., -1.2901e-01,\n",
            "           -1.2295e-01, -1.6822e-01]],\n",
            "\n",
            "         [[-2.8472e-02,  3.1140e-01,  4.6111e-02,  ...,  2.1083e-01,\n",
            "           -8.7485e-02,  1.1804e-01],\n",
            "          [-1.2795e-01, -2.8266e-01,  5.9306e-02,  ..., -2.7818e-01,\n",
            "           -1.9306e-02, -7.9757e-02],\n",
            "          [-1.1435e-01,  2.7092e-01,  1.8456e-01,  ...,  1.0966e-01,\n",
            "            4.8924e-03,  3.4806e-02],\n",
            "          ...,\n",
            "          [-9.9917e-02, -3.5871e-03,  6.3885e-02,  ..., -5.9681e-02,\n",
            "           -8.6116e-02, -3.0154e-01],\n",
            "          [ 5.1477e-02,  1.2454e-02, -1.1565e-01,  ...,  6.8462e-02,\n",
            "           -1.2852e-01,  9.9014e-02],\n",
            "          [-9.9516e-02, -6.9802e-02, -5.0087e-02,  ..., -2.2136e-01,\n",
            "            5.1566e-02, -1.0987e-01]]],\n",
            "\n",
            "\n",
            "        [[[-7.0533e-02,  2.0636e-02, -7.5746e-02,  ...,  9.1770e-03,\n",
            "           -8.7670e-02,  1.1207e-01],\n",
            "          [ 1.1014e-01,  6.4595e-01,  2.0393e-02,  ...,  2.0712e-01,\n",
            "            6.9757e-02, -2.6804e-02],\n",
            "          [-2.1730e-01,  8.5602e-02,  5.8215e-02,  ..., -1.2789e-01,\n",
            "           -2.4402e-01,  2.6163e-01],\n",
            "          ...,\n",
            "          [ 4.0443e-03,  1.7375e-01,  1.6735e-01,  ...,  4.2360e-01,\n",
            "            8.1920e-02,  1.3311e-01],\n",
            "          [-1.5654e-02, -1.1908e-01, -7.9819e-02,  ..., -2.0250e-01,\n",
            "           -1.4414e-01,  1.3612e-01],\n",
            "          [ 3.2715e-02,  5.6031e-02,  1.2730e-01,  ...,  2.1102e-01,\n",
            "           -1.5492e-02,  1.0997e-01]],\n",
            "\n",
            "         [[-3.0706e-02,  2.0658e-01,  2.4955e-02,  ..., -7.9687e-02,\n",
            "            3.9162e-02,  6.6644e-02],\n",
            "          [-1.3888e-01, -3.8695e-01,  7.2009e-02,  ..., -4.1980e-01,\n",
            "           -1.6075e-01,  1.1780e-01],\n",
            "          [ 1.1492e-01, -1.0261e-01, -3.8697e-03,  ...,  4.1028e-02,\n",
            "            6.7749e-02,  2.0246e-02],\n",
            "          ...,\n",
            "          [-3.1498e-02, -3.1154e-01,  4.2700e-02,  ..., -3.6536e-01,\n",
            "            1.1869e-02, -8.1702e-02],\n",
            "          [ 4.8455e-02, -1.4700e-01,  3.9838e-02,  ...,  8.1220e-02,\n",
            "            2.0948e-01,  7.8830e-02],\n",
            "          [ 6.1299e-02, -3.0696e-01,  6.0880e-04,  ..., -2.1553e-01,\n",
            "           -5.5836e-02, -2.3290e-01]],\n",
            "\n",
            "         [[-1.9469e-01, -1.4639e-01, -1.6733e-01,  ..., -9.4949e-02,\n",
            "           -1.2692e-01, -3.6889e-02],\n",
            "          [ 6.8197e-02,  8.9577e-02, -5.5147e-02,  ...,  6.5447e-01,\n",
            "           -2.1489e-01,  1.1136e-01],\n",
            "          [-1.1540e-01,  1.5249e-01, -1.8951e-02,  ..., -2.3967e-01,\n",
            "            2.3198e-02,  2.4648e-01],\n",
            "          ...,\n",
            "          [-1.5516e-01,  5.0333e-01, -1.2086e-01,  ...,  6.0701e-01,\n",
            "           -3.1462e-01,  9.1486e-02],\n",
            "          [-6.9784e-02, -9.0977e-02, -5.0195e-02,  ..., -2.1064e-01,\n",
            "            5.3009e-02,  1.4005e-01],\n",
            "          [ 2.7833e-02,  3.6882e-01,  4.2223e-05,  ...,  2.3785e-01,\n",
            "           -1.3180e-01,  7.3092e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.6005e-01,  2.3878e-02, -1.9284e-01,  ..., -7.5177e-02,\n",
            "           -5.4836e-03,  8.8425e-02],\n",
            "          [ 9.0661e-02, -1.7085e-01,  1.2403e-01,  ..., -4.5839e-02,\n",
            "            3.1336e-02, -6.9660e-02],\n",
            "          [-1.1501e-01,  1.8862e-01,  1.7086e-01,  ..., -2.6383e-01,\n",
            "           -1.7629e-01,  1.8210e-01],\n",
            "          ...,\n",
            "          [ 7.3393e-02, -3.6682e-02,  2.9548e-01,  ..., -3.2116e-01,\n",
            "           -5.0839e-02, -1.2509e-01],\n",
            "          [-6.8528e-02, -1.9360e-01, -2.3828e-02,  ..., -1.1769e-01,\n",
            "           -7.3836e-02,  1.7029e-01],\n",
            "          [ 1.5008e-01, -2.8756e-01,  1.5839e-01,  ..., -1.3276e-01,\n",
            "            1.3026e-01, -1.2221e-01]],\n",
            "\n",
            "         [[ 4.9402e-02, -8.5175e-02,  1.4473e-01,  ...,  2.4857e-01,\n",
            "            1.3473e-01,  2.8845e-02],\n",
            "          [-1.9020e-01,  5.5923e-01,  4.6871e-02,  ..., -4.4363e-03,\n",
            "           -1.8680e-01,  5.1355e-02],\n",
            "          [ 1.5201e-01, -1.9492e-02,  1.6253e-01,  ...,  4.3358e-01,\n",
            "            6.0939e-02,  4.0047e-02],\n",
            "          ...,\n",
            "          [-1.1247e-01,  3.2034e-01, -9.2984e-02,  ...,  7.2522e-02,\n",
            "           -8.3880e-02,  3.4255e-01],\n",
            "          [ 2.0543e-02,  3.5002e-01,  7.1343e-02,  ...,  2.4479e-01,\n",
            "            1.8755e-01,  5.3506e-02],\n",
            "          [-4.3225e-02, -1.5522e-01, -4.6602e-02,  ..., -5.1618e-02,\n",
            "           -1.1230e-01,  1.0136e-01]],\n",
            "\n",
            "         [[ 6.3826e-02,  1.8049e-01,  1.4241e-02,  ...,  7.4197e-02,\n",
            "            5.1733e-02,  4.7611e-02],\n",
            "          [-1.2634e-01, -2.6474e-01, -5.1161e-02,  ...,  7.1953e-02,\n",
            "           -1.0309e-01, -1.3469e-01],\n",
            "          [-3.7096e-01,  3.3437e-01,  2.0290e-01,  ...,  1.4224e-01,\n",
            "           -5.2862e-03,  3.1558e-02],\n",
            "          ...,\n",
            "          [-2.3116e-01, -1.2941e-01, -1.2395e-01,  ..., -2.4368e-01,\n",
            "           -1.2292e-01,  8.8855e-02],\n",
            "          [-2.7322e-02,  4.4680e-03,  4.1511e-03,  ...,  2.2990e-01,\n",
            "            8.0950e-02,  2.1711e-01],\n",
            "          [-5.2639e-02, -1.8445e-01, -1.9089e-02,  ..., -1.7298e-01,\n",
            "           -1.3626e-01, -2.7400e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.8230e-02, -1.3407e-01, -2.3151e-01,  ..., -7.4795e-02,\n",
            "           -8.5450e-02, -1.0824e-01],\n",
            "          [ 1.6944e-01,  2.7943e-01,  1.2240e-02,  ...,  2.9491e-01,\n",
            "            1.5126e-01, -7.9578e-02],\n",
            "          [-2.5044e-01, -1.9592e-01, -7.6433e-02,  ..., -5.8914e-02,\n",
            "           -1.9058e-01, -2.6782e-02],\n",
            "          ...,\n",
            "          [ 3.9758e-02, -1.6885e-01, -1.8845e-01,  ...,  2.5061e-02,\n",
            "           -7.2137e-02,  5.7384e-02],\n",
            "          [-3.2802e-02, -4.5698e-02, -1.9404e-01,  ..., -2.1400e-01,\n",
            "           -4.5259e-03,  3.4087e-02],\n",
            "          [-6.6913e-02,  2.2573e-01,  1.9102e-01,  ..., -1.4330e-01,\n",
            "            3.1342e-02,  1.8289e-01]],\n",
            "\n",
            "         [[-1.1036e-01,  2.2884e-01,  1.1763e-01,  ...,  2.0517e-01,\n",
            "           -1.3693e-01,  2.0167e-01],\n",
            "          [ 1.3043e-01, -4.6171e-01,  9.0769e-02,  ..., -3.5754e-01,\n",
            "            9.0146e-02, -3.5971e-01],\n",
            "          [ 3.4445e-02,  7.2664e-02,  1.7369e-01,  ...,  1.2546e-01,\n",
            "            2.9887e-01,  7.5491e-02],\n",
            "          ...,\n",
            "          [ 1.4012e-01, -3.2664e-01, -9.0355e-02,  ..., -2.7753e-01,\n",
            "           -5.8099e-02, -3.0140e-01],\n",
            "          [ 3.9210e-02,  7.4733e-02, -1.7816e-01,  ...,  2.9080e-01,\n",
            "           -7.3726e-02, -1.3498e-01],\n",
            "          [-1.0943e-02, -3.0573e-01,  2.8315e-02,  ..., -3.2556e-01,\n",
            "            1.5901e-01, -3.2442e-02]],\n",
            "\n",
            "         [[-2.1987e-01, -4.2748e-02, -1.7062e-01,  ..., -1.6786e-01,\n",
            "           -1.8496e-01, -1.1621e-01],\n",
            "          [ 7.2709e-02,  3.7173e-01, -2.9003e-02,  ...,  4.0562e-01,\n",
            "            2.0904e-01,  1.3219e-01],\n",
            "          [-2.1840e-01, -6.3036e-03, -7.0436e-02,  ...,  2.1269e-01,\n",
            "           -1.0422e-01,  4.0349e-02],\n",
            "          ...,\n",
            "          [-2.0588e-01,  5.3757e-01, -2.2762e-02,  ..., -2.3718e-01,\n",
            "            1.5292e-01,  1.0303e-01],\n",
            "          [-5.3673e-03, -2.8518e-02, -1.9069e-01,  ...,  6.0970e-02,\n",
            "           -3.1738e-01,  1.9588e-01],\n",
            "          [-7.3317e-02,  2.3462e-01, -5.8554e-02,  ...,  4.0299e-01,\n",
            "            1.0690e-01,  2.7674e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.3198e-01, -7.7429e-02, -2.7146e-01,  ..., -4.9580e-02,\n",
            "           -1.4283e-02, -2.9505e-02],\n",
            "          [ 1.6437e-01, -4.0755e-01,  1.2497e-01,  ..., -3.7711e-01,\n",
            "            1.2126e-01,  1.1771e-01],\n",
            "          [-6.0653e-02,  9.4785e-02, -1.2327e-01,  ...,  5.3205e-02,\n",
            "           -1.9377e-01,  2.2367e-01],\n",
            "          ...,\n",
            "          [ 1.2966e-01, -1.8607e-01, -1.2504e-01,  ..., -1.2360e-01,\n",
            "            1.1461e-01, -4.9316e-02],\n",
            "          [-4.5148e-02, -1.1719e-01,  1.5506e-01,  ...,  2.8996e-01,\n",
            "            1.6774e-01,  2.4383e-01],\n",
            "          [ 1.0389e-01, -1.3592e-01, -8.2054e-02,  ..., -4.3277e-01,\n",
            "           -7.3482e-02, -2.0063e-01]],\n",
            "\n",
            "         [[-3.1707e-02, -1.5048e-01,  2.9203e-01,  ...,  9.5481e-02,\n",
            "            1.9811e-01,  6.8202e-02],\n",
            "          [-2.8333e-01,  4.4613e-01,  5.9620e-02,  ...,  5.3876e-01,\n",
            "           -5.0710e-01,  2.7315e-01],\n",
            "          [ 1.7385e-01, -1.5229e-01,  2.4118e-01,  ..., -1.1038e-01,\n",
            "            3.9276e-01, -4.8007e-03],\n",
            "          ...,\n",
            "          [ 1.4864e-01,  5.2598e-01,  1.0021e-01,  ...,  8.0637e-01,\n",
            "            1.2346e-01,  2.2705e-01],\n",
            "          [ 2.4675e-02, -6.8250e-02,  2.0524e-02,  ..., -5.4630e-01,\n",
            "            3.8258e-01, -4.7269e-01],\n",
            "          [-4.7441e-02,  1.4672e-01,  1.4171e-01,  ...,  4.7736e-01,\n",
            "            1.1901e-01,  1.7899e-01]],\n",
            "\n",
            "         [[-8.4212e-02,  9.0782e-02,  1.0671e-01,  ...,  2.5018e-01,\n",
            "            1.6975e-01, -1.9252e-01],\n",
            "          [-2.7531e-01, -1.0214e-01,  2.3100e-02,  ...,  2.5539e-01,\n",
            "           -2.0883e-02, -6.5130e-02],\n",
            "          [-3.5571e-01,  5.6495e-01,  2.0780e-01,  ...,  3.1485e-01,\n",
            "            3.0028e-01, -1.8561e-02],\n",
            "          ...,\n",
            "          [-3.1199e-01,  7.0348e-02, -1.1339e-01,  ..., -2.1531e-01,\n",
            "           -8.1919e-02, -2.7555e-01],\n",
            "          [-1.0291e-01,  1.8501e-01, -1.2555e-01,  ...,  5.2598e-01,\n",
            "           -3.5948e-01,  6.1554e-02],\n",
            "          [-8.4825e-02, -1.0572e-01, -1.3425e-01,  ...,  3.4279e-01,\n",
            "           -1.1182e-01, -1.4797e-01]]]], device='cuda:0',\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[-2.3302, -2.1231, -2.1560,  ..., -2.5363, -2.4806, -2.5016],\n",
            "          [-2.5173, -2.3964, -2.6057,  ..., -2.5566, -2.5065, -2.4961],\n",
            "          [-2.5175, -2.3169, -2.5526,  ..., -2.4816, -2.4293, -2.3658],\n",
            "          ...,\n",
            "          [-3.0387, -2.5967, -2.4598,  ..., -2.1213, -1.9845, -2.1137],\n",
            "          [-3.2025, -2.7265, -2.5731,  ..., -2.1898, -2.0136, -2.1708],\n",
            "          [-3.2299, -2.9783, -2.8946,  ..., -2.5169, -2.4135, -2.4933]],\n",
            "\n",
            "         [[-2.2702, -2.6927, -2.6369,  ..., -2.6010, -2.6429, -2.5738],\n",
            "          [-2.0252, -2.5772, -2.6166,  ..., -2.6285, -2.7005, -2.4347],\n",
            "          [-2.2033, -2.7117, -2.6738,  ..., -2.6640, -2.7300, -2.4440],\n",
            "          ...,\n",
            "          [-1.8673, -2.0814, -2.2019,  ..., -2.6857, -2.7442, -2.5838],\n",
            "          [-1.8995, -2.0754, -2.1164,  ..., -2.6490, -2.6968, -2.5201],\n",
            "          [-2.1821, -2.2604, -2.1949,  ..., -2.5457, -2.5922, -2.4229]],\n",
            "\n",
            "         [[-2.2785, -2.3115, -2.3742,  ..., -2.4174, -2.4605, -2.2893],\n",
            "          [-2.8397, -3.0526, -3.1460,  ..., -2.6681, -2.6972, -2.3770],\n",
            "          [-2.9053, -3.2170, -3.3388,  ..., -2.7012, -2.7690, -2.4032],\n",
            "          ...,\n",
            "          [-2.3581, -2.7589, -2.6972,  ..., -2.7588, -2.7252, -2.5354],\n",
            "          [-2.2905, -2.7810, -2.7550,  ..., -2.7343, -2.6995, -2.4931],\n",
            "          [-2.2607, -2.7134, -2.6916,  ..., -2.6637, -2.6325, -2.5373]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.0142, -3.0758, -2.9679,  ..., -2.8008, -2.8220, -2.9698],\n",
            "          [-2.9102, -3.0143, -2.9112,  ..., -3.0054, -3.0272, -3.2594],\n",
            "          [-3.0263, -3.0930, -2.9153,  ..., -3.1070, -3.1533, -3.3059],\n",
            "          ...,\n",
            "          [-3.0685, -3.1170, -2.9702,  ..., -2.6135, -2.7866, -2.9810],\n",
            "          [-3.0111, -2.8836, -2.8236,  ..., -2.5594, -2.7480, -2.8846],\n",
            "          [-2.7034, -2.5149, -2.5892,  ..., -2.5111, -2.5946, -2.7357]],\n",
            "\n",
            "         [[-2.4177, -2.3328, -2.4454,  ..., -2.3012, -2.2618, -2.0193],\n",
            "          [-2.5731, -2.4720, -2.5527,  ..., -2.5024, -2.4054, -2.2314],\n",
            "          [-2.3868, -2.3107, -2.4465,  ..., -2.4271, -2.3637, -2.2454],\n",
            "          ...,\n",
            "          [-2.8198, -2.7823, -2.7341,  ..., -2.4892, -2.4198, -2.3543],\n",
            "          [-2.6873, -2.8283, -2.8423,  ..., -2.6340, -2.5758, -2.5327],\n",
            "          [-2.6797, -2.7926, -2.8440,  ..., -2.6480, -2.5891, -2.5630]],\n",
            "\n",
            "         [[-2.5550, -2.5529, -2.6066,  ..., -2.6008, -2.6350, -2.5151],\n",
            "          [-2.5430, -2.4004, -2.3420,  ..., -2.5555, -2.7035, -2.5573],\n",
            "          [-2.5574, -2.4428, -2.3492,  ..., -2.5712, -2.7404, -2.6091],\n",
            "          ...,\n",
            "          [-2.4680, -2.3690, -2.2679,  ..., -2.6483, -2.7774, -2.5903],\n",
            "          [-2.4047, -2.2888, -2.2392,  ..., -2.5456, -2.6562, -2.4840],\n",
            "          [-2.3010, -2.2520, -2.1961,  ..., -2.4618, -2.5187, -2.3835]]],\n",
            "\n",
            "\n",
            "        [[[-2.2464, -2.2871, -2.3839,  ..., -2.3647, -2.3209, -2.1448],\n",
            "          [-2.9071, -2.7174, -2.8575,  ..., -2.4799, -2.4994, -2.3115],\n",
            "          [-2.9774, -2.6794, -2.8862,  ..., -2.6259, -2.5461, -2.4006],\n",
            "          ...,\n",
            "          [-2.6276, -2.3255, -2.3196,  ..., -2.5778, -2.5442, -2.4015],\n",
            "          [-2.7280, -2.4377, -2.4791,  ..., -2.6271, -2.5976, -2.4451],\n",
            "          [-2.8136, -2.7074, -2.8634,  ..., -2.7164, -2.7316, -2.6366]],\n",
            "\n",
            "         [[-2.1359, -2.1304, -2.1434,  ..., -2.9685, -2.9342, -2.6320],\n",
            "          [-1.7835, -1.6215, -1.5924,  ..., -2.6352, -2.5764, -2.5501],\n",
            "          [-1.9204, -1.6360, -1.6116,  ..., -2.7714, -2.6187, -2.5909],\n",
            "          ...,\n",
            "          [-2.3345, -2.6882, -2.7188,  ..., -3.0326, -2.8919, -2.6969],\n",
            "          [-2.1969, -2.6186, -2.6568,  ..., -2.8480, -2.7291, -2.6368],\n",
            "          [-2.3068, -2.3869, -2.3600,  ..., -2.7266, -2.6412, -2.6811]],\n",
            "\n",
            "         [[-2.7486, -2.5974, -2.7210,  ..., -2.8785, -2.8014, -2.6540],\n",
            "          [-3.0766, -3.0904, -3.1917,  ..., -2.9951, -3.0314, -2.8792],\n",
            "          [-3.0243, -3.0051, -3.1156,  ..., -2.8985, -2.9599, -2.8679],\n",
            "          ...,\n",
            "          [-2.7541, -2.4692, -2.5553,  ..., -2.2905, -2.2637, -2.1908],\n",
            "          [-2.7397, -2.5029, -2.6246,  ..., -2.2816, -2.2814, -2.1572],\n",
            "          [-2.4042, -2.5729, -2.6553,  ..., -2.4750, -2.4536, -2.2825]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.3357, -2.3229, -2.2052,  ..., -2.3187, -2.2936, -2.1624],\n",
            "          [-2.9025, -2.9232, -2.7921,  ..., -2.7591, -2.6762, -2.3340],\n",
            "          [-2.8602, -2.9180, -2.8096,  ..., -2.6540, -2.6288, -2.3653],\n",
            "          ...,\n",
            "          [-2.7735, -2.6748, -2.5385,  ..., -2.8760, -2.8845, -2.7223],\n",
            "          [-2.6768, -2.4547, -2.3572,  ..., -2.7888, -2.8002, -2.7009],\n",
            "          [-2.5408, -2.0938, -2.1116,  ..., -2.5169, -2.5269, -2.5234]],\n",
            "\n",
            "         [[-2.4821, -2.6542, -2.7487,  ..., -2.4727, -2.4288, -2.3217],\n",
            "          [-2.5458, -2.6071, -2.5063,  ..., -2.4642, -2.4674, -2.5070],\n",
            "          [-2.4376, -2.5621, -2.4623,  ..., -2.3241, -2.3716, -2.4270],\n",
            "          ...,\n",
            "          [-2.5215, -2.7936, -2.6665,  ..., -2.1303, -2.0232, -2.3309],\n",
            "          [-2.5387, -2.7376, -2.6202,  ..., -2.2162, -2.1200, -2.4023],\n",
            "          [-2.5198, -2.5246, -2.4239,  ..., -2.2152, -2.2487, -2.5177]],\n",
            "\n",
            "         [[-2.2173, -2.3018, -2.3139,  ..., -2.5812, -2.4945, -2.7718],\n",
            "          [-2.0438, -2.4279, -2.5030,  ..., -2.6594, -2.6604, -3.0383],\n",
            "          [-2.0950, -2.4354, -2.5385,  ..., -2.7489, -2.8139, -3.0208],\n",
            "          ...,\n",
            "          [-2.6393, -2.9244, -2.7756,  ..., -3.0136, -2.9548, -2.7224],\n",
            "          [-2.5676, -2.8298, -2.7271,  ..., -2.8692, -2.8377, -2.6706],\n",
            "          [-2.7569, -2.9743, -2.8579,  ..., -2.8357, -2.7852, -2.6835]]],\n",
            "\n",
            "\n",
            "        [[[-2.2564, -2.0154, -2.1071,  ..., -2.3342, -2.2641, -2.0734],\n",
            "          [-2.4571, -2.2439, -2.2915,  ..., -2.8030, -2.6410, -2.4058],\n",
            "          [-2.4983, -2.1239, -2.1422,  ..., -2.8957, -2.7092, -2.4130],\n",
            "          ...,\n",
            "          [-2.5315, -2.4174, -2.3286,  ..., -2.2687, -2.1771, -2.1647],\n",
            "          [-2.5530, -2.5079, -2.3893,  ..., -2.2980, -2.2203, -2.1879],\n",
            "          [-2.8089, -2.8904, -2.9002,  ..., -2.6529, -2.6235, -2.5242]],\n",
            "\n",
            "         [[-2.4739, -2.6936, -2.6522,  ..., -2.4645, -2.4522, -2.3646],\n",
            "          [-2.5897, -2.4219, -2.4851,  ..., -2.7392, -2.7113, -2.4314],\n",
            "          [-2.6698, -2.4314, -2.4995,  ..., -2.7454, -2.7481, -2.4306],\n",
            "          ...,\n",
            "          [-2.0841, -1.9341, -2.1729,  ..., -1.8970, -2.1113, -2.5148],\n",
            "          [-2.1039, -2.0254, -2.2764,  ..., -2.0944, -2.2222, -2.5717],\n",
            "          [-2.3520, -2.3539, -2.3900,  ..., -2.1683, -2.2604, -2.4456]],\n",
            "\n",
            "         [[-2.4478, -2.4107, -2.4707,  ..., -2.4712, -2.6023, -2.5235],\n",
            "          [-2.5721, -2.6886, -2.7692,  ..., -2.9533, -2.9137, -2.7118],\n",
            "          [-2.4830, -2.7414, -2.9028,  ..., -2.8837, -2.8574, -2.7034],\n",
            "          ...,\n",
            "          [-2.8580, -2.8419, -2.8030,  ..., -2.9313, -2.7908, -2.4641],\n",
            "          [-2.8370, -2.9250, -2.8513,  ..., -2.8942, -2.7808, -2.5232],\n",
            "          [-2.5773, -2.7159, -2.7148,  ..., -2.7840, -2.7146, -2.4790]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8809, -3.3124, -3.1750,  ..., -2.9473, -2.8326, -2.8119],\n",
            "          [-3.0693, -3.3099, -3.1832,  ..., -3.4320, -3.3271, -3.1662],\n",
            "          [-3.0308, -3.2920, -3.1102,  ..., -3.5399, -3.4480, -3.1771],\n",
            "          ...,\n",
            "          [-2.9476, -3.0919, -2.9003,  ..., -2.6841, -2.6280, -2.9501],\n",
            "          [-2.8802, -2.9910, -2.8887,  ..., -2.6816, -2.6666, -2.9882],\n",
            "          [-2.6561, -2.6310, -2.6256,  ..., -2.5227, -2.4832, -2.7263]],\n",
            "\n",
            "         [[-2.5991, -2.2830, -2.2669,  ..., -2.5720, -2.4809, -2.2846],\n",
            "          [-2.8004, -2.4192, -2.3117,  ..., -2.3735, -2.3402, -2.3825],\n",
            "          [-2.6674, -2.3627, -2.2545,  ..., -2.1592, -2.0874, -2.2272],\n",
            "          ...,\n",
            "          [-2.7112, -2.7907, -2.8656,  ..., -2.5486, -2.5073, -2.5659],\n",
            "          [-2.7050, -2.7630, -2.7722,  ..., -2.5411, -2.5006, -2.5899],\n",
            "          [-2.7579, -2.6605, -2.7032,  ..., -2.5915, -2.5516, -2.6623]],\n",
            "\n",
            "         [[-2.3582, -2.2423, -2.1983,  ..., -2.4781, -2.5614, -2.7532],\n",
            "          [-2.2916, -2.3158, -2.2294,  ..., -2.2215, -2.3729, -2.5966],\n",
            "          [-2.3145, -2.4022, -2.3177,  ..., -2.2025, -2.3855, -2.5225],\n",
            "          ...,\n",
            "          [-2.8491, -3.1208, -3.0520,  ..., -2.7622, -2.7909, -2.5292],\n",
            "          [-2.6664, -2.7975, -2.7396,  ..., -2.6144, -2.6590, -2.3938],\n",
            "          [-2.4054, -2.4027, -2.3799,  ..., -2.4980, -2.5993, -2.4334]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.7496, -2.7274, -2.7338,  ..., -2.6765, -2.6656, -2.4801],\n",
            "          [-2.7972, -2.8409, -2.7622,  ..., -2.8238, -2.8511, -2.6119],\n",
            "          [-2.8673, -2.8853, -2.7880,  ..., -2.8157, -2.8440, -2.6176],\n",
            "          ...,\n",
            "          [-2.6780, -2.7821, -2.7245,  ..., -2.4613, -2.4209, -2.3015],\n",
            "          [-2.7386, -2.7754, -2.6976,  ..., -2.4997, -2.4429, -2.3629],\n",
            "          [-2.7268, -2.7415, -2.6961,  ..., -2.6603, -2.6559, -2.6422]],\n",
            "\n",
            "         [[-2.5283, -2.8741, -2.9144,  ..., -2.7040, -2.6065, -2.4098],\n",
            "          [-2.6326, -3.0230, -3.0546,  ..., -2.6635, -2.6223, -2.4542],\n",
            "          [-2.6584, -3.0396, -3.0644,  ..., -2.7023, -2.6461, -2.4825],\n",
            "          ...,\n",
            "          [-2.4128, -2.6976, -2.8043,  ..., -2.7299, -2.7441, -2.5310],\n",
            "          [-2.3615, -2.6862, -2.7661,  ..., -2.6587, -2.6955, -2.6205],\n",
            "          [-2.3367, -2.4657, -2.5009,  ..., -2.4831, -2.5131, -2.4055]],\n",
            "\n",
            "         [[-2.5378, -2.4755, -2.5160,  ..., -2.8872, -3.0314, -2.7896],\n",
            "          [-2.5036, -2.4776, -2.5429,  ..., -3.0350, -3.1421, -2.6907],\n",
            "          [-2.5119, -2.4971, -2.5742,  ..., -2.9901, -3.0582, -2.6619],\n",
            "          ...,\n",
            "          [-2.4803, -2.6096, -2.6325,  ..., -2.3745, -2.5012, -2.2294],\n",
            "          [-2.6058, -2.7511, -2.7887,  ..., -2.4665, -2.5707, -2.2670],\n",
            "          [-2.4948, -2.6691, -2.6058,  ..., -2.4143, -2.5298, -2.3288]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9076, -3.3096, -3.3421,  ..., -3.1418, -2.8553, -2.8472],\n",
            "          [-3.0390, -3.5539, -3.6743,  ..., -3.3735, -3.0759, -3.0250],\n",
            "          [-2.9693, -3.4753, -3.6271,  ..., -3.3814, -3.1369, -3.0882],\n",
            "          ...,\n",
            "          [-2.6513, -2.6928, -2.7854,  ..., -2.8506, -2.7568, -2.8644],\n",
            "          [-2.5906, -2.5520, -2.6443,  ..., -2.7576, -2.6793, -2.8048],\n",
            "          [-2.4604, -2.3240, -2.3482,  ..., -2.5430, -2.5326, -2.6513]],\n",
            "\n",
            "         [[-2.0393, -1.9822, -2.0567,  ..., -1.9520, -2.0177, -2.0252],\n",
            "          [-2.0249, -1.9112, -1.9688,  ..., -1.8828, -1.9763, -1.9607],\n",
            "          [-2.0325, -1.8892, -1.9232,  ..., -1.8639, -1.9280, -1.9000],\n",
            "          ...,\n",
            "          [-2.2515, -2.1640, -2.2503,  ..., -2.1303, -2.0425, -2.0019],\n",
            "          [-2.3080, -2.2392, -2.3489,  ..., -2.2179, -2.1167, -2.0380],\n",
            "          [-2.4445, -2.3237, -2.3616,  ..., -2.1531, -2.0873, -2.1070]],\n",
            "\n",
            "         [[-2.5098, -2.5052, -2.5224,  ..., -2.7147, -2.6189, -2.5092],\n",
            "          [-2.5982, -2.7390, -2.8189,  ..., -2.9530, -2.8946, -2.7599],\n",
            "          [-2.5779, -2.6943, -2.7765,  ..., -2.8484, -2.8466, -2.7215],\n",
            "          ...,\n",
            "          [-2.9111, -2.8184, -2.8173,  ..., -2.9306, -2.9406, -2.9671],\n",
            "          [-2.9006, -2.7612, -2.7144,  ..., -2.8986, -2.8918, -2.8557],\n",
            "          [-2.7130, -2.5396, -2.5159,  ..., -2.6825, -2.6660, -2.5949]]],\n",
            "\n",
            "\n",
            "        [[[-2.7375, -2.6635, -2.6283,  ..., -2.7145, -2.6531, -2.2710],\n",
            "          [-2.7666, -2.8659, -2.8867,  ..., -2.8840, -2.8035, -2.6172],\n",
            "          [-2.7545, -2.9003, -2.9388,  ..., -3.0901, -2.8404, -2.6036],\n",
            "          ...,\n",
            "          [-2.5484, -2.8072, -2.7473,  ..., -2.7818, -2.6602, -2.5053],\n",
            "          [-2.6864, -2.8807, -2.8007,  ..., -2.8668, -2.7225, -2.6115],\n",
            "          [-2.9016, -3.0566, -3.1047,  ..., -2.9754, -2.8931, -2.8315]],\n",
            "\n",
            "         [[-2.0999, -2.1692, -2.2389,  ..., -2.5298, -2.5905, -2.3433],\n",
            "          [-2.1790, -2.1939, -2.2919,  ..., -2.5157, -2.5810, -2.1754],\n",
            "          [-2.2937, -2.3273, -2.4166,  ..., -2.7694, -2.7732, -2.3506],\n",
            "          ...,\n",
            "          [-2.0521, -2.1087, -2.1411,  ..., -2.4570, -2.5085, -2.4000],\n",
            "          [-2.1339, -2.1937, -2.2341,  ..., -2.5115, -2.5443, -2.4366],\n",
            "          [-2.4392, -2.4949, -2.4554,  ..., -2.4600, -2.4315, -2.2936]],\n",
            "\n",
            "         [[-2.7087, -2.6333, -2.5621,  ..., -3.0625, -3.0423, -2.7117],\n",
            "          [-2.9763, -3.0424, -3.0305,  ..., -3.4914, -3.4187, -2.8109],\n",
            "          [-2.9339, -3.1723, -3.1289,  ..., -3.4970, -3.4502, -2.9102],\n",
            "          ...,\n",
            "          [-3.3103, -3.5287, -3.4582,  ..., -2.8358, -2.9135, -2.5125],\n",
            "          [-3.1786, -3.4574, -3.3946,  ..., -2.8796, -2.9556, -2.5821],\n",
            "          [-2.7581, -3.1372, -3.0735,  ..., -2.9178, -2.9507, -2.6141]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9611, -3.0152, -2.9965,  ..., -2.6980, -2.7064, -2.9015],\n",
            "          [-2.7622, -2.7251, -2.7741,  ..., -2.8600, -2.9880, -3.3185],\n",
            "          [-2.6568, -2.6026, -2.6886,  ..., -2.8220, -2.8669, -3.1528],\n",
            "          ...,\n",
            "          [-2.7532, -2.8142, -2.7557,  ..., -2.3227, -2.3405, -2.8291],\n",
            "          [-2.7072, -2.7557, -2.6826,  ..., -2.3293, -2.3035, -2.8518],\n",
            "          [-2.8842, -2.7416, -2.6597,  ..., -2.1853, -2.2126, -2.6770]],\n",
            "\n",
            "         [[-2.3026, -2.3941, -2.4833,  ..., -2.3079, -2.2812, -2.2909],\n",
            "          [-2.7445, -2.7409, -2.7467,  ..., -2.7078, -2.6902, -2.7292],\n",
            "          [-2.6737, -2.6493, -2.7081,  ..., -2.4529, -2.5193, -2.7060],\n",
            "          ...,\n",
            "          [-2.7303, -2.8596, -2.9501,  ..., -2.4602, -2.3355, -2.3206],\n",
            "          [-2.6976, -2.7970, -2.8871,  ..., -2.3901, -2.2517, -2.3848],\n",
            "          [-2.8915, -2.9744, -3.0040,  ..., -2.3130, -2.2534, -2.5689]],\n",
            "\n",
            "         [[-2.5137, -2.4130, -2.4430,  ..., -2.8248, -2.8168, -2.8864],\n",
            "          [-2.4741, -2.5517, -2.5708,  ..., -2.6392, -2.7071, -2.7355],\n",
            "          [-2.4920, -2.5854, -2.5681,  ..., -2.5281, -2.6993, -2.6201],\n",
            "          ...,\n",
            "          [-2.4253, -2.5943, -2.6274,  ..., -2.7843, -2.8437, -2.8151],\n",
            "          [-2.3401, -2.4574, -2.5189,  ..., -2.8050, -2.8992, -2.7731],\n",
            "          [-2.2541, -2.3204, -2.4010,  ..., -2.7624, -2.7871, -2.6809]]],\n",
            "\n",
            "\n",
            "        [[[-2.3467, -2.3341, -2.4028,  ..., -2.7232, -2.6899, -2.5232],\n",
            "          [-2.4834, -2.6207, -2.6698,  ..., -2.8650, -2.8130, -2.5327],\n",
            "          [-2.4464, -2.6626, -2.6444,  ..., -2.8753, -2.8000, -2.5775],\n",
            "          ...,\n",
            "          [-2.3004, -2.8267, -2.7272,  ..., -2.5947, -2.4643, -2.2857],\n",
            "          [-2.4508, -2.8720, -2.7858,  ..., -2.5979, -2.4891, -2.3140],\n",
            "          [-2.5986, -2.6330, -2.6474,  ..., -2.5113, -2.4897, -2.4845]],\n",
            "\n",
            "         [[-2.2498, -2.5642, -2.5224,  ..., -2.3171, -2.3668, -2.5657],\n",
            "          [-2.1435, -2.3774, -2.4350,  ..., -2.3785, -2.5074, -2.4685],\n",
            "          [-2.1602, -2.3514, -2.4576,  ..., -2.5036, -2.6782, -2.6495],\n",
            "          ...,\n",
            "          [-1.9595, -2.4707, -2.5987,  ..., -2.8639, -3.0043, -2.8319],\n",
            "          [-1.9663, -2.5689, -2.7151,  ..., -2.9806, -3.0739, -2.9484],\n",
            "          [-2.3962, -2.6876, -2.6214,  ..., -2.7322, -2.7434, -2.6430]],\n",
            "\n",
            "         [[-2.7193, -2.7116, -2.7304,  ..., -2.6083, -2.5923, -2.3824],\n",
            "          [-2.7407, -2.8164, -2.9269,  ..., -2.7063, -2.6817, -2.4286],\n",
            "          [-2.7685, -2.8411, -2.9336,  ..., -2.7871, -2.7151, -2.5450],\n",
            "          ...,\n",
            "          [-2.5552, -2.8254, -2.7831,  ..., -2.6234, -2.6379, -2.4313],\n",
            "          [-2.4830, -2.7527, -2.7421,  ..., -2.6809, -2.6767, -2.4905],\n",
            "          [-2.4448, -2.6320, -2.6280,  ..., -2.6511, -2.7140, -2.6338]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8265, -2.8120, -2.7505,  ..., -2.8995, -2.8924, -2.9678],\n",
            "          [-2.8773, -2.9212, -2.9215,  ..., -3.0336, -3.0709, -2.8755],\n",
            "          [-2.8990, -2.9723, -2.9967,  ..., -2.9983, -3.0906, -2.9336],\n",
            "          ...,\n",
            "          [-2.9482, -2.9625, -3.0717,  ..., -3.4536, -3.5490, -3.2881],\n",
            "          [-2.8721, -2.9323, -3.0444,  ..., -3.3187, -3.3969, -3.2292],\n",
            "          [-2.8043, -2.6236, -2.6724,  ..., -2.7844, -2.8459, -2.8113]],\n",
            "\n",
            "         [[-2.6541, -2.5249, -2.5821,  ..., -2.3174, -2.4681, -2.6090],\n",
            "          [-2.5963, -2.7361, -2.8412,  ..., -2.5577, -2.6145, -2.8996],\n",
            "          [-2.4688, -2.5653, -2.7559,  ..., -2.4411, -2.4571, -2.7391],\n",
            "          ...,\n",
            "          [-2.2766, -2.4820, -2.6485,  ..., -2.3242, -2.3056, -2.3686],\n",
            "          [-2.4137, -2.6811, -2.8067,  ..., -2.4144, -2.3490, -2.3428],\n",
            "          [-2.6218, -2.6832, -2.7541,  ..., -2.3910, -2.3505, -2.3123]],\n",
            "\n",
            "         [[-2.6597, -2.8538, -2.7902,  ..., -2.7170, -2.6766, -2.8676],\n",
            "          [-2.4286, -2.5259, -2.4678,  ..., -2.4659, -2.4693, -2.6749],\n",
            "          [-2.4705, -2.5373, -2.4633,  ..., -2.5719, -2.5534, -2.6353],\n",
            "          ...,\n",
            "          [-2.9448, -2.7175, -2.5326,  ..., -2.6926, -2.7511, -2.5228],\n",
            "          [-2.8682, -2.5805, -2.4321,  ..., -2.6379, -2.6862, -2.4639],\n",
            "          [-2.5358, -2.2404, -2.2484,  ..., -2.4744, -2.5373, -2.4418]]]],\n",
            "       device='cuda:0')\n",
            "tensor([[[[ 2.0366e-02, -2.7441e-02, -1.7890e-01,  ..., -6.0856e-02,\n",
            "           -1.1473e-01,  1.2770e-01],\n",
            "          [ 2.4921e-02,  3.8826e-01,  3.0437e-01,  ...,  1.6567e-01,\n",
            "            1.0520e-01,  1.9331e-01],\n",
            "          [-8.7388e-02, -4.0660e-02, -5.3365e-02,  ...,  1.6892e-04,\n",
            "           -1.0357e-01,  1.2495e-01],\n",
            "          ...,\n",
            "          [ 2.1091e-01, -1.1488e-03, -1.6041e-01,  ...,  1.7658e-01,\n",
            "            5.2046e-02,  7.4550e-02],\n",
            "          [ 2.3135e-02, -3.5203e-02, -5.8815e-02,  ..., -1.2334e-01,\n",
            "           -8.7104e-03,  3.1312e-02],\n",
            "          [-1.8024e-02,  1.0300e-01,  2.2692e-02,  ...,  1.3191e-01,\n",
            "            9.3892e-02,  2.0792e-01]],\n",
            "\n",
            "         [[-6.9981e-02,  1.0040e-02,  1.3678e-01,  ..., -9.9847e-02,\n",
            "            8.6774e-02,  1.0345e-01],\n",
            "          [ 4.9895e-02, -6.9939e-02, -1.2326e-01,  ..., -1.7553e-01,\n",
            "            3.6340e-02, -1.5456e-03],\n",
            "          [-5.5866e-02,  4.8754e-03,  6.8268e-02,  ..., -2.1250e-02,\n",
            "            1.4312e-02, -2.9629e-02],\n",
            "          ...,\n",
            "          [-2.9046e-02, -2.9379e-01,  1.6811e-01,  ..., -4.3141e-01,\n",
            "            7.9484e-02, -1.2610e-01],\n",
            "          [ 5.9701e-02, -7.0416e-02,  2.9338e-02,  ...,  2.8127e-02,\n",
            "           -5.8714e-02,  5.9062e-02],\n",
            "          [-9.0633e-03, -2.4324e-01,  9.2965e-02,  ..., -2.8401e-01,\n",
            "            1.6081e-02, -1.3107e-01]],\n",
            "\n",
            "         [[-2.1278e-01, -1.3024e-01, -2.4242e-01,  ...,  1.6090e-02,\n",
            "           -6.6455e-02,  2.4702e-02],\n",
            "          [ 8.5915e-02,  3.9997e-01, -4.6040e-02,  ...,  7.1564e-01,\n",
            "           -5.9688e-02,  1.0645e-01],\n",
            "          [-1.6988e-01, -1.9146e-02, -4.3547e-02,  ..., -8.0393e-02,\n",
            "           -9.2577e-02,  2.7639e-02],\n",
            "          ...,\n",
            "          [-2.1777e-01,  4.4896e-01, -2.7244e-02,  ...,  5.4987e-01,\n",
            "           -2.6619e-01,  2.5515e-01],\n",
            "          [ 3.4906e-02, -4.3665e-02, -1.0979e-01,  ..., -1.7185e-01,\n",
            "           -4.8560e-02,  1.9389e-02],\n",
            "          [ 4.0230e-02,  4.1416e-01, -5.1927e-02,  ...,  4.7381e-01,\n",
            "           -6.2819e-02,  1.3941e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4904e-01, -7.0503e-02, -2.1199e-01,  ...,  9.5102e-02,\n",
            "           -6.0624e-02,  1.1219e-01],\n",
            "          [-3.3752e-02, -3.2589e-01,  1.0161e-01,  ..., -1.8121e-01,\n",
            "            1.3774e-01,  1.6872e-02],\n",
            "          [ 9.2405e-02,  8.8922e-02, -8.9378e-02,  ..., -1.7388e-01,\n",
            "           -8.8249e-02,  3.7542e-02],\n",
            "          ...,\n",
            "          [ 1.7984e-01, -1.2425e-01,  8.1561e-02,  ..., -1.2761e-01,\n",
            "            1.3436e-01, -2.7179e-02],\n",
            "          [-7.3143e-02, -1.9443e-01, -1.5885e-02,  ..., -2.3177e-01,\n",
            "            3.9428e-02, -3.5671e-02],\n",
            "          [ 1.8375e-01, -2.8830e-01, -1.4129e-02,  ..., -2.1537e-01,\n",
            "            1.6695e-01, -1.3511e-01]],\n",
            "\n",
            "         [[ 8.9542e-03,  4.2448e-02,  3.1820e-01,  ..., -6.3857e-02,\n",
            "            8.8331e-02,  5.2500e-02],\n",
            "          [ 3.0547e-02,  3.2523e-01,  3.1331e-03,  ...,  7.1916e-02,\n",
            "           -5.0462e-02,  1.0796e-03],\n",
            "          [ 1.3740e-01,  6.0688e-02,  1.0146e-01,  ...,  2.6471e-01,\n",
            "            6.5937e-02,  7.4692e-02],\n",
            "          ...,\n",
            "          [ 3.7101e-03,  2.2747e-01, -9.2286e-02,  ...,  3.0585e-01,\n",
            "            7.9754e-02,  4.4336e-02],\n",
            "          [-5.1324e-02,  1.5346e-01,  1.0439e-01,  ...,  2.3893e-01,\n",
            "            9.2524e-02,  1.0577e-02],\n",
            "          [-1.3403e-01, -2.0177e-01, -1.4176e-03,  ..., -8.6047e-02,\n",
            "           -1.6875e-01,  5.4909e-03]],\n",
            "\n",
            "         [[ 2.0496e-02,  1.6776e-01,  3.0315e-02,  ...,  1.6623e-01,\n",
            "           -1.1047e-01,  7.5352e-02],\n",
            "          [-1.4325e-01, -3.3272e-01, -6.0123e-02,  ..., -4.4245e-01,\n",
            "           -4.0612e-02, -2.3868e-01],\n",
            "          [-8.7859e-02,  1.8979e-01,  2.2680e-03,  ...,  1.6118e-02,\n",
            "            1.1089e-02,  5.7006e-03],\n",
            "          ...,\n",
            "          [-2.4366e-01,  1.9653e-01, -5.8554e-02,  ..., -1.1802e-01,\n",
            "           -2.1970e-01, -6.1663e-02],\n",
            "          [-1.3763e-01,  1.0543e-01, -8.5606e-02,  ...,  1.4810e-02,\n",
            "           -3.0630e-04, -2.4004e-02],\n",
            "          [ 1.5057e-02, -6.1435e-02, -4.2850e-02,  ..., -5.9801e-02,\n",
            "            5.1445e-04, -1.1787e-01]]],\n",
            "\n",
            "\n",
            "        [[[-4.7006e-02,  2.2797e-02, -1.1044e-01,  ..., -1.4762e-01,\n",
            "           -8.3319e-02,  1.7196e-01],\n",
            "          [ 7.9008e-02,  3.0634e-01,  1.9935e-01,  ...,  1.2811e-01,\n",
            "            1.4647e-01,  2.0445e-01],\n",
            "          [-1.2272e-01, -1.3024e-01, -6.2367e-02,  ..., -1.9801e-01,\n",
            "           -2.1720e-01,  1.7243e-01],\n",
            "          ...,\n",
            "          [ 1.1462e-01,  2.2654e-01,  5.1846e-02,  ...,  2.5313e-01,\n",
            "            7.3143e-02,  2.5636e-01],\n",
            "          [-2.7505e-02, -4.7141e-02, -1.3093e-01,  ..., -1.4607e-02,\n",
            "           -1.4265e-01,  1.9072e-01],\n",
            "          [ 6.6529e-03,  2.3261e-01,  1.2795e-01,  ...,  9.8012e-02,\n",
            "           -9.3885e-03,  2.5892e-01]],\n",
            "\n",
            "         [[ 3.8146e-02, -2.2585e-02,  7.7760e-02,  ..., -7.1162e-02,\n",
            "            2.6203e-02, -6.8880e-02],\n",
            "          [-7.9202e-02, -1.0650e-01, -8.5528e-02,  ..., -2.3504e-01,\n",
            "           -8.8259e-02,  3.8559e-02],\n",
            "          [-1.3236e-01,  1.4807e-01,  2.7770e-02,  ...,  2.0876e-02,\n",
            "           -4.3170e-02,  1.6427e-02],\n",
            "          ...,\n",
            "          [-8.2304e-02, -3.5190e-01, -5.9712e-02,  ..., -2.5749e-01,\n",
            "            1.5771e-02, -8.5007e-02],\n",
            "          [-1.4953e-02, -9.7190e-02, -2.8643e-02,  ..., -6.5536e-02,\n",
            "            1.5757e-01,  3.0123e-02],\n",
            "          [-2.2048e-02, -3.3222e-01,  1.2200e-02,  ..., -3.1809e-01,\n",
            "           -1.8290e-02, -1.6187e-01]],\n",
            "\n",
            "         [[-1.9785e-01, -1.6838e-01, -9.5449e-02,  ..., -9.2963e-02,\n",
            "           -5.8668e-02,  1.0217e-01],\n",
            "          [-1.2707e-01,  7.0908e-01, -7.7913e-02,  ...,  5.0422e-01,\n",
            "           -4.4280e-04,  1.1118e-01],\n",
            "          [-2.9097e-01, -3.4530e-02, -1.2845e-01,  ...,  2.0475e-02,\n",
            "           -4.7559e-02,  1.2065e-01],\n",
            "          ...,\n",
            "          [-4.4756e-02,  4.2957e-01, -6.0652e-02,  ...,  2.3737e-01,\n",
            "            4.7228e-02, -9.0091e-04],\n",
            "          [ 1.0006e-02,  5.3540e-03, -9.8101e-02,  ..., -7.3026e-02,\n",
            "           -3.6913e-02,  1.1567e-01],\n",
            "          [-1.8103e-02,  2.9500e-01, -2.7925e-02,  ...,  3.6364e-01,\n",
            "           -7.5705e-02,  1.6603e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.3154e-02, -1.5406e-01, -8.6829e-02,  ..., -1.5848e-01,\n",
            "           -2.4963e-03,  7.1993e-02],\n",
            "          [-1.1903e-02, -2.7887e-01,  1.4287e-01,  ..., -2.0391e-01,\n",
            "            1.4622e-01, -4.7577e-02],\n",
            "          [-3.8543e-03,  1.3996e-01, -8.8881e-02,  ...,  3.3562e-03,\n",
            "           -9.7007e-02,  8.0105e-02],\n",
            "          ...,\n",
            "          [ 9.0656e-02, -6.5014e-02,  1.0949e-01,  ..., -1.5265e-01,\n",
            "            3.6530e-01, -2.4067e-01],\n",
            "          [-4.7836e-03, -1.1415e-01,  2.5831e-02,  ...,  5.8984e-02,\n",
            "           -8.2812e-02,  1.5585e-01],\n",
            "          [ 1.2833e-01, -2.8692e-01,  1.5088e-02,  ..., -5.0289e-01,\n",
            "            6.0586e-02, -9.7262e-02]],\n",
            "\n",
            "         [[ 4.4238e-02,  2.0001e-01,  1.1895e-01,  ...,  1.9613e-01,\n",
            "            7.0342e-02,  4.0962e-02],\n",
            "          [ 1.7246e-01,  4.0585e-01,  5.9929e-02,  ...,  7.6064e-02,\n",
            "           -1.2917e-01, -1.0362e-01],\n",
            "          [ 3.4707e-01, -9.0806e-02,  2.1464e-01,  ...,  1.8019e-01,\n",
            "            3.1633e-02,  3.3068e-02],\n",
            "          ...,\n",
            "          [ 2.9411e-02,  1.4305e-01, -5.4698e-02,  ...,  3.6724e-01,\n",
            "           -8.9445e-02,  9.5861e-02],\n",
            "          [-3.9900e-02,  1.2111e-01,  6.4089e-03,  ...,  6.1071e-02,\n",
            "            1.2894e-01, -1.8670e-03],\n",
            "          [-2.0578e-02, -1.7783e-01,  1.6414e-02,  ..., -1.0888e-01,\n",
            "           -4.5988e-03, -1.3385e-01]],\n",
            "\n",
            "         [[-1.0830e-03,  1.6428e-01,  5.7535e-02,  ...,  1.5110e-01,\n",
            "           -6.3266e-02,  4.2329e-02],\n",
            "          [-1.6334e-01, -7.2823e-02, -1.7823e-01,  ..., -3.1062e-01,\n",
            "            3.4373e-03, -2.1362e-01],\n",
            "          [ 8.5999e-02,  6.2857e-02,  1.2916e-01,  ..., -3.1286e-02,\n",
            "           -2.5706e-02, -1.0577e-02],\n",
            "          ...,\n",
            "          [-2.8412e-02, -2.2523e-01, -1.1283e-01,  ..., -3.0500e-01,\n",
            "           -1.1579e-01, -3.9448e-01],\n",
            "          [-1.0476e-01,  1.0728e-01, -5.0740e-02,  ...,  2.7945e-01,\n",
            "           -1.8815e-01,  1.3241e-01],\n",
            "          [-1.3448e-01, -1.8621e-01, -6.7597e-02,  ..., -8.2599e-02,\n",
            "           -8.9466e-02, -2.1977e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.7579e-01,  1.6856e-02, -7.9763e-02,  ...,  3.6974e-02,\n",
            "           -7.2842e-02,  1.4285e-01],\n",
            "          [ 3.4977e-01, -3.5487e-01, -5.7919e-02,  ...,  4.4642e-01,\n",
            "            2.7849e-01,  5.7909e-02],\n",
            "          [-2.3398e-01, -3.4764e-01, -2.3971e-01,  ..., -2.0659e-02,\n",
            "           -1.1304e-01, -1.5681e-01],\n",
            "          ...,\n",
            "          [ 4.5850e-02,  3.0346e-01,  8.4327e-02,  ..., -1.6725e-02,\n",
            "            1.9951e-02,  1.4721e-01],\n",
            "          [-5.3965e-02,  1.5146e-01, -1.3638e-01,  ...,  9.6930e-04,\n",
            "           -1.1989e-01,  1.3986e-01],\n",
            "          [ 1.2416e-01,  2.9871e-01,  1.8190e-01,  ...,  1.9998e-01,\n",
            "            1.3294e-01,  1.3004e-01]],\n",
            "\n",
            "         [[-1.9527e-02, -2.0811e-01, -6.5674e-02,  ..., -2.8822e-02,\n",
            "           -8.5064e-02, -5.8739e-02],\n",
            "          [ 3.9985e-01, -3.4156e-01,  1.1217e-01,  ...,  1.0699e-01,\n",
            "           -1.6977e-01,  5.0982e-02],\n",
            "          [ 1.8961e-01,  2.1669e-01, -3.8463e-02,  ...,  1.7411e-01,\n",
            "           -1.0369e-01,  1.7248e-01],\n",
            "          ...,\n",
            "          [-1.6151e-01, -1.5802e-01, -1.4427e-01,  ..., -1.8993e-01,\n",
            "           -5.3702e-02,  5.2800e-03],\n",
            "          [-9.2721e-02, -1.3864e-01, -6.7509e-02,  ..., -5.2969e-03,\n",
            "           -9.8463e-02, -6.2721e-02],\n",
            "          [-3.5063e-02, -2.7136e-01, -2.8707e-02,  ..., -2.6187e-01,\n",
            "            1.1407e-03, -6.6943e-02]],\n",
            "\n",
            "         [[-4.0372e-01,  1.8697e-01, -5.0177e-01,  ...,  1.0670e-02,\n",
            "           -1.2284e-01,  1.3039e-02],\n",
            "          [-2.3930e-02,  1.1248e+00, -2.1860e-01,  ...,  4.7463e-01,\n",
            "           -6.0515e-02,  1.2880e-01],\n",
            "          [-6.6008e-02,  6.6765e-02,  2.2180e-02,  ...,  1.7667e-01,\n",
            "           -2.2572e-01,  1.0469e-01],\n",
            "          ...,\n",
            "          [-6.6070e-02,  3.2064e-01, -6.2187e-02,  ...,  2.1316e-01,\n",
            "            3.6970e-02,  5.5459e-02],\n",
            "          [-1.1592e-01,  5.7845e-02, -1.6299e-01,  ...,  5.5424e-02,\n",
            "           -1.3108e-01,  2.0457e-02],\n",
            "          [-8.4680e-02,  5.4160e-02, -5.5843e-02,  ...,  1.5449e-01,\n",
            "           -7.6594e-02,  1.1887e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8844e-01, -4.3885e-01, -2.9115e-02,  ..., -3.8869e-02,\n",
            "            4.0547e-02,  4.0413e-02],\n",
            "          [ 8.3134e-02, -1.0108e+00, -8.9881e-02,  ..., -2.7153e-01,\n",
            "            3.1457e-03,  1.2615e-02],\n",
            "          [-3.1280e-01,  2.0427e-01,  2.3859e-02,  ...,  2.2505e-01,\n",
            "           -2.0484e-01,  2.9601e-01],\n",
            "          ...,\n",
            "          [-5.0069e-03, -1.8188e-01,  7.4969e-02,  ..., -4.1000e-01,\n",
            "           -7.0985e-02, -5.3163e-02],\n",
            "          [ 5.4898e-02, -3.5427e-03,  9.3630e-02,  ..., -7.2408e-02,\n",
            "            6.4129e-02,  4.7377e-02],\n",
            "          [ 3.4544e-02, -3.0539e-01,  7.9598e-04,  ..., -1.8915e-01,\n",
            "           -4.9805e-02, -1.5701e-01]],\n",
            "\n",
            "         [[-7.2164e-02, -5.3305e-01,  9.3972e-01,  ...,  5.1209e-02,\n",
            "            3.1743e-02,  1.9013e-02],\n",
            "          [-1.9111e-01,  5.9454e-01, -2.4220e-01,  ...,  3.3689e-01,\n",
            "            2.2712e-01,  2.3106e-01],\n",
            "          [-2.6693e-02, -2.1681e-02, -8.7478e-02,  ..., -4.7466e-02,\n",
            "            1.8672e-01, -5.5950e-02],\n",
            "          ...,\n",
            "          [ 1.4770e-01,  5.1623e-02,  1.5957e-01,  ...,  2.4328e-01,\n",
            "            9.2171e-02,  1.0446e-01],\n",
            "          [ 6.8360e-02, -1.9490e-02,  8.5859e-02,  ...,  6.1043e-02,\n",
            "            1.7528e-02, -1.8127e-02],\n",
            "          [ 6.5313e-02,  7.4363e-03,  1.1809e-01,  ..., -1.4004e-02,\n",
            "            9.0701e-02, -8.6178e-02]],\n",
            "\n",
            "         [[-5.5964e-01,  4.6402e-01, -1.3109e-01,  ...,  1.1704e-01,\n",
            "            5.3091e-02, -5.5100e-02],\n",
            "          [-3.1544e-01,  4.8055e-02, -1.7763e-01,  ..., -1.1029e-01,\n",
            "           -7.4654e-02, -1.7285e-01],\n",
            "          [-3.6198e-01,  4.5947e-01, -1.3345e-01,  ...,  1.2421e-01,\n",
            "            1.2360e-01, -1.7909e-01],\n",
            "          ...,\n",
            "          [-9.1751e-02, -2.7339e-01, -1.1108e-01,  ..., -1.4901e-01,\n",
            "           -8.5007e-02, -2.6128e-01],\n",
            "          [ 6.3735e-02,  9.6935e-02, -5.8482e-03,  ...,  1.1127e-01,\n",
            "            1.1643e-03,  1.3217e-02],\n",
            "          [-2.0571e-01, -3.9524e-02, -2.0013e-01,  ..., -1.5966e-02,\n",
            "           -1.5648e-01,  8.5729e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.2747e-01,  6.9772e-02,  1.0005e-01,  ..., -1.5272e-02,\n",
            "           -6.8922e-02,  3.1196e-02],\n",
            "          [ 6.5041e-01,  1.6131e-01, -6.1963e-01,  ...,  3.0799e-01,\n",
            "            1.2332e-01,  1.2544e-01],\n",
            "          [-1.3975e-01, -4.3091e-01, -2.2105e-01,  ..., -2.6991e-01,\n",
            "           -5.5580e-02, -1.0946e-02],\n",
            "          ...,\n",
            "          [ 8.0714e-03, -3.2348e-02, -7.1397e-03,  ...,  1.8593e-01,\n",
            "            7.6497e-02,  1.0929e-01],\n",
            "          [-4.5800e-02, -1.6269e-01, -2.2106e-01,  ..., -4.7485e-02,\n",
            "           -1.3974e-01,  1.6373e-01],\n",
            "          [ 6.4064e-02,  1.1390e-02,  9.2536e-02,  ...,  1.1525e-01,\n",
            "            9.6367e-02,  1.8095e-01]],\n",
            "\n",
            "         [[ 1.0911e-01,  3.8437e-03,  1.1898e-01,  ..., -9.4951e-02,\n",
            "            6.6681e-02,  4.5354e-02],\n",
            "          [-3.9303e-01, -2.3299e-01,  1.9677e-01,  ..., -5.3204e-02,\n",
            "            4.0474e-02, -1.8027e-01],\n",
            "          [ 1.2214e-01,  1.7850e-01,  1.2294e-01,  ...,  1.7969e-01,\n",
            "            1.2869e-01,  7.1043e-02],\n",
            "          ...,\n",
            "          [-6.0800e-02, -2.5769e-01, -6.4642e-02,  ..., -4.4204e-01,\n",
            "           -7.5795e-02, -9.9142e-02],\n",
            "          [ 3.8144e-03, -1.3360e-01,  1.3807e-02,  ..., -6.8121e-02,\n",
            "            9.4926e-03, -3.2114e-02],\n",
            "          [ 4.6261e-03, -2.7051e-01,  6.0272e-02,  ..., -3.2391e-01,\n",
            "            1.9220e-03, -1.0642e-01]],\n",
            "\n",
            "         [[-2.2888e-01, -1.2358e-01, -6.1223e-04,  ..., -8.2627e-02,\n",
            "           -3.1856e-03,  9.7949e-03],\n",
            "          [-3.3658e-01,  2.7341e-01, -9.5396e-01,  ...,  4.7798e-01,\n",
            "            9.6855e-03,  3.3103e-02],\n",
            "          [-1.0109e-01, -4.5019e-02,  2.3335e-01,  ..., -3.8188e-02,\n",
            "            5.5931e-02,  9.5233e-02],\n",
            "          ...,\n",
            "          [ 1.4548e-02,  4.0612e-01, -9.9666e-02,  ...,  2.9693e-01,\n",
            "            1.6821e-02,  5.2106e-02],\n",
            "          [-6.7917e-02, -4.3511e-02,  3.4041e-02,  ..., -7.7039e-03,\n",
            "           -4.1819e-02,  5.8843e-02],\n",
            "          [ 2.8502e-02,  6.6759e-02, -8.6621e-02,  ...,  2.2189e-01,\n",
            "           -2.8021e-02,  1.9786e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2894e-01,  2.7428e-01,  1.2117e-01,  ..., -9.4319e-02,\n",
            "           -2.5724e-02,  1.4571e-02],\n",
            "          [ 6.7457e-02, -4.4467e-02, -1.4869e-01,  ...,  1.1710e-01,\n",
            "            1.2102e-01, -1.4500e-01],\n",
            "          [-2.8832e-01,  6.4493e-01,  4.2259e-02,  ...,  1.5744e-01,\n",
            "           -1.1904e-01,  1.0497e-01],\n",
            "          ...,\n",
            "          [ 2.3933e-01,  5.7220e-02,  4.7886e-02,  ..., -3.1814e-02,\n",
            "            1.8655e-01, -6.8320e-02],\n",
            "          [-4.5092e-02, -1.7903e-01, -6.6115e-02,  ..., -1.8796e-01,\n",
            "           -4.8862e-02,  2.0180e-02],\n",
            "          [ 5.5898e-02, -2.1024e-01,  3.1566e-02,  ..., -1.7034e-01,\n",
            "            2.8961e-02, -7.0730e-02]],\n",
            "\n",
            "         [[ 3.2143e-01, -3.9463e-01,  7.3100e-01,  ...,  1.6199e-01,\n",
            "            1.6422e-02,  2.1713e-02],\n",
            "          [-8.0582e-03,  3.7330e-01, -3.0873e-01,  ...,  1.2399e-01,\n",
            "           -9.7801e-02,  5.1652e-02],\n",
            "          [ 2.7735e-01, -5.3739e-01,  3.7676e-01,  ...,  1.6676e-01,\n",
            "            3.5811e-02, -3.0407e-02],\n",
            "          ...,\n",
            "          [-1.6771e-01, -5.7615e-02, -1.6984e-01,  ...,  1.2163e-01,\n",
            "           -9.1266e-02,  2.3530e-02],\n",
            "          [-3.2133e-02,  2.6949e-01, -4.4137e-02,  ...,  2.5679e-01,\n",
            "           -7.1186e-03,  5.2651e-02],\n",
            "          [-7.7788e-03, -2.4198e-01, -3.5162e-02,  ..., -2.5689e-01,\n",
            "            1.9498e-02, -1.4975e-01]],\n",
            "\n",
            "         [[ 1.0441e-01,  1.0584e-01, -5.6599e-01,  ...,  1.3916e-01,\n",
            "           -4.6926e-02,  9.0593e-02],\n",
            "          [-2.8088e-01,  1.1185e+00,  1.9191e-01,  ..., -1.7242e-01,\n",
            "           -1.6697e-02, -8.9013e-02],\n",
            "          [-7.7578e-02,  3.1357e-01, -4.3592e-01,  ..., -5.8140e-02,\n",
            "           -5.7889e-02,  7.4441e-02],\n",
            "          ...,\n",
            "          [-2.1783e-02, -2.4577e-01,  8.3192e-03,  ..., -3.1383e-01,\n",
            "           -9.3620e-03, -1.2989e-01],\n",
            "          [-2.3745e-02,  1.9975e-03, -1.0079e-01,  ...,  1.1605e-01,\n",
            "           -8.4396e-02,  3.5216e-02],\n",
            "          [-5.1826e-02, -1.4626e-01, -6.6029e-02,  ..., -1.7188e-01,\n",
            "           -6.0446e-02, -1.0308e-01]]],\n",
            "\n",
            "\n",
            "        [[[-3.0749e-01,  5.0104e-02, -1.5736e-01,  ...,  7.1804e-02,\n",
            "           -1.1710e-01,  7.2157e-02],\n",
            "          [ 9.8236e-01,  3.5062e-01,  3.2712e-01,  ...,  7.2036e-03,\n",
            "           -1.1049e-01, -6.6963e-04],\n",
            "          [-2.9678e-01, -2.5164e-01,  2.1956e-01,  ..., -6.9730e-02,\n",
            "           -2.7621e-01,  1.1996e-01],\n",
            "          ...,\n",
            "          [ 3.2799e-01,  2.3673e-01,  2.8505e-02,  ...,  3.2745e-04,\n",
            "           -3.1694e-02,  1.5776e-01],\n",
            "          [-4.5324e-02,  4.7494e-02, -2.1347e-01,  ..., -3.7234e-02,\n",
            "           -1.1956e-01,  1.2711e-01],\n",
            "          [ 1.2494e-01,  3.2649e-01,  1.3489e-01,  ...,  2.1200e-01,\n",
            "            8.1711e-02,  1.6002e-01]],\n",
            "\n",
            "         [[ 2.4956e-02, -4.9469e-02, -1.8882e-01,  ...,  8.1196e-02,\n",
            "            6.4262e-02,  3.1499e-02],\n",
            "          [-2.9977e-01,  3.0759e-02,  4.9673e-02,  ..., -4.4436e-01,\n",
            "           -1.8119e-01, -2.6765e-02],\n",
            "          [ 2.6907e-01,  1.0708e-01,  9.7340e-02,  ..., -1.2127e-01,\n",
            "           -8.6072e-03, -5.3767e-02],\n",
            "          ...,\n",
            "          [-2.3254e-01, -4.6071e-01, -5.9418e-02,  ..., -5.1292e-01,\n",
            "            3.8452e-02, -7.5384e-02],\n",
            "          [-6.9969e-02, -1.6613e-01, -8.2507e-02,  ..., -3.7041e-02,\n",
            "            7.8047e-03, -2.3533e-02],\n",
            "          [ 1.4501e-03, -3.1928e-01,  1.0911e-01,  ..., -2.8752e-01,\n",
            "           -1.9974e-02, -1.1265e-01]],\n",
            "\n",
            "         [[-1.3909e-01,  8.5131e-02, -2.2151e-01,  ..., -6.8590e-02,\n",
            "           -2.9507e-02, -2.5478e-02],\n",
            "          [ 2.3736e-01,  2.9887e-02, -1.1146e-01,  ...,  3.5530e-01,\n",
            "           -2.4369e-02, -3.3142e-02],\n",
            "          [-8.9914e-02,  4.6706e-01, -2.3434e-01,  ...,  1.1756e-01,\n",
            "           -1.7316e-01,  5.6260e-02],\n",
            "          ...,\n",
            "          [ 6.4388e-02,  3.0563e-01,  8.5047e-02,  ...,  5.1839e-01,\n",
            "           -1.4604e-01,  1.0738e-01],\n",
            "          [-1.0148e-01,  7.3526e-02, -1.6188e-01,  ...,  3.3355e-03,\n",
            "           -2.9371e-02,  4.7837e-02],\n",
            "          [-2.7689e-02,  2.1682e-01,  1.5990e-02,  ...,  2.3140e-01,\n",
            "           -4.3782e-02,  1.4059e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1215e-01, -2.1111e-01, -6.7321e-02,  ...,  1.0588e-01,\n",
            "           -9.7469e-02, -1.0892e-02],\n",
            "          [ 8.2335e-02, -3.1937e-01,  2.3270e-01,  ..., -2.9278e-01,\n",
            "            9.5025e-02, -1.6898e-02],\n",
            "          [-4.2398e-01,  1.0249e+00, -1.2989e-01,  ...,  9.6270e-02,\n",
            "           -4.1181e-02,  3.8692e-02],\n",
            "          ...,\n",
            "          [-5.6821e-03,  2.5734e-02, -6.5636e-02,  ..., -2.3918e-01,\n",
            "            8.9422e-02, -1.4740e-01],\n",
            "          [ 2.1722e-02, -2.5481e-02,  7.5838e-02,  ..., -2.0488e-01,\n",
            "           -4.1975e-02,  1.6378e-02],\n",
            "          [ 1.1029e-01, -3.7590e-01, -4.2412e-02,  ..., -1.5272e-01,\n",
            "            3.5739e-02, -9.0712e-02]],\n",
            "\n",
            "         [[ 1.4476e-01, -7.0026e-02,  2.8799e-01,  ...,  1.4129e-01,\n",
            "            5.1042e-02, -1.1992e-02],\n",
            "          [ 5.8494e-03,  6.1199e-01, -1.2415e-01,  ...,  1.5500e-01,\n",
            "           -1.9045e-01,  2.1062e-01],\n",
            "          [ 7.4039e-01, -5.4551e-01,  1.8857e-01,  ..., -1.3374e-01,\n",
            "            8.2281e-02, -2.5005e-02],\n",
            "          ...,\n",
            "          [-5.3091e-02,  2.5693e-01,  5.6816e-02,  ...,  1.4150e-02,\n",
            "           -3.8809e-02,  1.3974e-01],\n",
            "          [ 3.0828e-02, -3.6533e-02,  1.8531e-02,  ...,  2.3817e-01,\n",
            "           -7.6538e-03,  3.6558e-02],\n",
            "          [-3.8433e-05, -2.0087e-01,  1.0687e-01,  ..., -2.9289e-01,\n",
            "            2.4701e-02, -1.1793e-01]],\n",
            "\n",
            "         [[-9.8958e-02,  1.3263e-01,  3.0747e-02,  ...,  1.8923e-01,\n",
            "            2.1113e-02, -3.9959e-02],\n",
            "          [ 1.5195e-01,  2.5406e-01, -2.8477e-01,  ...,  9.3015e-02,\n",
            "           -1.4315e-01, -3.2421e-01],\n",
            "          [-5.7327e-02,  3.8739e-01, -5.7185e-01,  ...,  2.8025e-01,\n",
            "           -1.3775e-01,  9.8276e-02],\n",
            "          ...,\n",
            "          [-8.3272e-02, -2.2400e-01,  5.9345e-03,  ..., -3.5084e-01,\n",
            "           -8.1456e-02, -1.1332e-01],\n",
            "          [-7.2544e-03,  1.3879e-01, -2.0247e-01,  ...,  1.5691e-01,\n",
            "           -5.7820e-02,  4.0293e-02],\n",
            "          [-1.2480e-01, -1.8300e-01, -1.7675e-01,  ..., -1.7317e-01,\n",
            "           -7.3865e-02, -5.2762e-02]]],\n",
            "\n",
            "\n",
            "        [[[-9.6097e-02, -4.9680e-02, -4.9767e-02,  ..., -2.0810e-01,\n",
            "           -1.0386e-01,  1.2904e-01],\n",
            "          [ 6.6146e-02,  3.1645e-01,  3.8146e-01,  ...,  1.6588e-01,\n",
            "            1.8849e-01,  1.5865e-01],\n",
            "          [-1.6810e-01, -1.3072e-01, -1.5813e-01,  ..., -1.3293e-01,\n",
            "           -5.9950e-02,  5.1513e-02],\n",
            "          ...,\n",
            "          [-5.6181e-05,  7.6256e-02,  5.4222e-02,  ..., -7.3468e-03,\n",
            "            4.6917e-03,  6.2363e-02],\n",
            "          [-1.3291e-01,  1.2951e-01, -1.5087e-01,  ..., -1.2969e-01,\n",
            "           -1.7372e-01,  1.7712e-01],\n",
            "          [ 1.7999e-01,  2.0873e-01,  1.7194e-01,  ...,  1.6811e-02,\n",
            "            6.4699e-02,  1.8847e-01]],\n",
            "\n",
            "         [[ 1.3896e-01, -2.7933e-02,  3.1027e-02,  ..., -9.7103e-02,\n",
            "            9.0796e-02,  5.6614e-02],\n",
            "          [-2.4395e-01,  9.5816e-03, -9.1422e-02,  ..., -3.1752e-01,\n",
            "           -1.1157e-03, -1.7742e-01],\n",
            "          [-6.4197e-02, -3.8791e-02,  1.4447e-01,  ...,  3.5447e-02,\n",
            "            5.8024e-02,  2.3894e-02],\n",
            "          ...,\n",
            "          [-1.0772e-01, -2.6959e-01, -1.2592e-01,  ..., -5.3564e-01,\n",
            "            1.9257e-02, -1.2253e-01],\n",
            "          [-6.9858e-02, -1.8087e-01, -4.4135e-02,  ..., -5.0467e-02,\n",
            "            5.4862e-02,  2.4891e-02],\n",
            "          [ 1.2222e-02, -2.6104e-01,  2.3801e-02,  ..., -3.2228e-01,\n",
            "            4.7651e-02, -8.9373e-02]],\n",
            "\n",
            "         [[-1.0674e-01, -1.3384e-01, -9.4898e-02,  ..., -5.1170e-02,\n",
            "           -2.7595e-02,  7.2127e-02],\n",
            "          [-4.6524e-02,  6.2519e-01,  9.1672e-02,  ...,  4.2407e-01,\n",
            "           -1.9524e-02,  1.4859e-01],\n",
            "          [-2.7682e-01,  3.7234e-02, -9.1948e-02,  ..., -1.2541e-01,\n",
            "           -6.6715e-02, -1.1873e-02],\n",
            "          ...,\n",
            "          [-8.6958e-02,  4.0813e-01,  4.1228e-02,  ...,  4.2740e-01,\n",
            "           -7.9158e-02,  7.7191e-02],\n",
            "          [-1.1017e-01, -2.3817e-02, -1.4125e-01,  ..., -2.6233e-02,\n",
            "            3.5501e-02,  7.1652e-02],\n",
            "          [ 7.7392e-03,  1.9004e-01, -7.2195e-02,  ...,  2.1978e-01,\n",
            "           -2.5620e-02,  1.5379e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.7316e-02, -1.5402e-01, -1.6547e-02,  ..., -5.9630e-02,\n",
            "           -4.6039e-02,  9.6669e-02],\n",
            "          [ 2.9294e-02, -1.8150e-01,  2.2088e-01,  ..., -2.5236e-01,\n",
            "            2.9550e-01,  9.7439e-02],\n",
            "          [-8.7008e-02,  1.1237e-01, -2.2132e-01,  ...,  4.7752e-02,\n",
            "            1.9947e-02,  4.6715e-03],\n",
            "          ...,\n",
            "          [ 9.2781e-02, -1.2129e-01,  3.1609e-01,  ..., -2.8803e-01,\n",
            "            1.6786e-01, -8.6086e-02],\n",
            "          [ 5.2102e-02, -2.0284e-01, -4.4718e-03,  ..., -1.6240e-01,\n",
            "           -8.8017e-02, -6.1950e-03],\n",
            "          [ 4.6721e-02, -2.1514e-01, -4.7305e-03,  ..., -1.4593e-01,\n",
            "            7.4336e-02, -1.4455e-02]],\n",
            "\n",
            "         [[ 1.5542e-01,  2.4041e-01,  1.2612e-01,  ...,  1.7241e-01,\n",
            "            1.1839e-01,  1.2799e-01],\n",
            "          [ 6.7968e-02,  3.9863e-01, -1.0955e-01,  ...,  2.5403e-01,\n",
            "           -6.9213e-02,  1.3410e-02],\n",
            "          [ 3.2681e-01,  1.5299e-01,  2.2785e-01,  ...,  1.8485e-01,\n",
            "            1.6785e-01,  7.0518e-02],\n",
            "          ...,\n",
            "          [-1.3333e-02,  1.9084e-01, -4.9850e-02,  ...,  5.3944e-03,\n",
            "           -1.9088e-01,  8.0744e-02],\n",
            "          [-1.0477e-02,  2.5169e-01,  3.6535e-02,  ...,  3.6799e-01,\n",
            "           -5.1441e-02,  1.1318e-01],\n",
            "          [ 2.5310e-03, -2.3715e-01,  8.2495e-02,  ..., -2.9415e-01,\n",
            "           -5.0653e-02, -1.6063e-01]],\n",
            "\n",
            "         [[ 6.4568e-03,  1.6636e-01,  1.2770e-01,  ...,  1.4067e-01,\n",
            "            2.2085e-02, -2.4428e-03],\n",
            "          [-4.8292e-02, -2.1553e-01, -9.7014e-02,  ..., -2.9954e-01,\n",
            "           -5.4926e-02, -1.7615e-01],\n",
            "          [ 2.5833e-01, -4.4891e-02,  8.5206e-02,  ...,  1.9029e-01,\n",
            "            7.6326e-02,  7.1927e-02],\n",
            "          ...,\n",
            "          [-1.1555e-01, -3.2994e-01, -2.0739e-02,  ..., -1.6474e-01,\n",
            "           -9.2035e-02, -1.8871e-01],\n",
            "          [-3.1776e-02,  7.0928e-02, -1.6569e-02,  ...,  5.3962e-02,\n",
            "           -1.0421e-01,  6.0568e-02],\n",
            "          [-6.8542e-02, -1.7064e-01, -1.0952e-01,  ..., -3.1024e-01,\n",
            "            4.6225e-04, -1.7796e-01]]]], device='cuda:0',\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[-2.3849, -2.2960, -2.4041,  ..., -2.3212, -2.4281, -2.3314],\n",
            "          [-2.3088, -2.3633, -2.3659,  ..., -2.3567, -2.4470, -2.4620],\n",
            "          [-2.2586, -2.2798, -2.2610,  ..., -2.2915, -2.3607, -2.3442],\n",
            "          ...,\n",
            "          [-2.0725, -1.8208, -1.6683,  ..., -2.1295, -2.2138, -2.2835],\n",
            "          [-2.1830, -1.9588, -1.8154,  ..., -2.2324, -2.2680, -2.3183],\n",
            "          [-2.6543, -2.4419, -2.3450,  ..., -2.4317, -2.4812, -2.4327]],\n",
            "\n",
            "         [[-2.3651, -2.2044, -2.2269,  ..., -2.1906, -2.2537, -2.3389],\n",
            "          [-2.3193, -2.1467, -2.2819,  ..., -2.2999, -2.3544, -2.3827],\n",
            "          [-2.3838, -2.1940, -2.3502,  ..., -2.5085, -2.4859, -2.3924],\n",
            "          ...,\n",
            "          [-2.3495, -2.4953, -2.6958,  ..., -2.4756, -2.4982, -2.4065],\n",
            "          [-2.3425, -2.4281, -2.6077,  ..., -2.5200, -2.5733, -2.4914],\n",
            "          [-2.5284, -2.7268, -2.7691,  ..., -2.5360, -2.5441, -2.5377]],\n",
            "\n",
            "         [[-2.9093, -2.9392, -2.9593,  ..., -2.7592, -2.8542, -2.7232],\n",
            "          [-3.0582, -3.2207, -3.1569,  ..., -3.0083, -2.9842, -2.8120],\n",
            "          [-3.0547, -3.3053, -3.2062,  ..., -3.0077, -3.0130, -2.8348],\n",
            "          ...,\n",
            "          [-2.9072, -2.9741, -3.0283,  ..., -2.9535, -2.8873, -2.5298],\n",
            "          [-2.8978, -2.9983, -3.0331,  ..., -2.7825, -2.7655, -2.4776],\n",
            "          [-2.5447, -2.7458, -2.8372,  ..., -2.7440, -2.7542, -2.5619]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.0312, -3.1999, -3.2372,  ..., -2.9616, -3.0362, -3.1472],\n",
            "          [-3.1989, -3.4322, -3.5154,  ..., -3.0441, -3.1273, -3.5371],\n",
            "          [-3.0841, -3.2484, -3.4065,  ..., -2.9412, -3.0474, -3.5635],\n",
            "          ...,\n",
            "          [-2.7139, -2.7069, -2.8374,  ..., -2.8334, -3.0063, -3.2325],\n",
            "          [-2.6620, -2.5450, -2.6679,  ..., -2.7690, -2.9347, -3.1849],\n",
            "          [-2.6397, -2.3989, -2.4241,  ..., -2.6154, -2.7010, -2.8556]],\n",
            "\n",
            "         [[-2.1973, -2.2521, -2.2251,  ..., -2.3362, -2.3050, -2.2607],\n",
            "          [-2.0718, -1.9776, -1.8773,  ..., -2.3543, -2.2828, -2.1767],\n",
            "          [-2.1125, -2.1336, -2.0225,  ..., -2.3919, -2.2941, -2.2102],\n",
            "          ...,\n",
            "          [-2.6543, -2.6656, -2.5964,  ..., -2.7229, -2.5585, -2.2068],\n",
            "          [-2.6270, -2.6159, -2.5040,  ..., -2.6697, -2.5117, -2.2177],\n",
            "          [-2.5310, -2.5331, -2.4282,  ..., -2.5461, -2.4412, -2.3084]],\n",
            "\n",
            "         [[-2.8831, -3.0074, -2.9895,  ..., -2.7629, -2.7317, -2.7965],\n",
            "          [-2.9527, -3.2262, -3.2957,  ..., -2.9697, -2.9248, -2.9780],\n",
            "          [-2.9322, -3.2343, -3.3112,  ..., -2.9622, -2.9447, -2.9106],\n",
            "          ...,\n",
            "          [-2.8141, -3.0943, -3.3190,  ..., -2.8609, -3.0403, -2.9956],\n",
            "          [-2.7751, -2.9497, -3.1550,  ..., -2.7591, -2.9130, -2.8443],\n",
            "          [-2.5051, -2.7876, -2.9271,  ..., -2.8006, -2.8618, -2.7771]]],\n",
            "\n",
            "\n",
            "        [[[-2.3814, -2.1120, -2.0960,  ..., -2.3762, -2.2762, -2.2299],\n",
            "          [-2.5385, -2.3602, -2.3085,  ..., -2.4409, -2.3060, -2.2788],\n",
            "          [-2.6012, -2.4390, -2.4104,  ..., -2.4542, -2.3182, -2.2776],\n",
            "          ...,\n",
            "          [-2.6446, -2.4302, -2.2596,  ..., -2.3742, -2.1948, -2.2575],\n",
            "          [-2.7403, -2.5630, -2.3690,  ..., -2.4170, -2.2778, -2.3090],\n",
            "          [-2.9737, -2.8757, -2.8102,  ..., -2.5510, -2.5823, -2.6448]],\n",
            "\n",
            "         [[-2.5513, -2.4272, -2.4649,  ..., -2.4858, -2.6498, -2.6033],\n",
            "          [-2.4349, -2.2221, -2.3275,  ..., -2.4842, -2.5428, -2.5604],\n",
            "          [-2.5915, -2.2537, -2.3808,  ..., -2.4427, -2.4936, -2.5264],\n",
            "          ...,\n",
            "          [-2.4031, -2.5775, -2.7018,  ..., -2.5438, -2.6482, -2.7340],\n",
            "          [-2.4489, -2.7568, -2.8544,  ..., -2.6635, -2.7304, -2.7537],\n",
            "          [-2.6073, -2.7157, -2.6797,  ..., -2.6809, -2.6047, -2.5637]],\n",
            "\n",
            "         [[-2.5368, -2.6623, -2.6843,  ..., -2.6845, -2.6324, -2.6684],\n",
            "          [-2.5159, -2.7307, -2.8009,  ..., -3.0733, -3.0209, -2.9105],\n",
            "          [-2.5961, -2.7421, -2.8511,  ..., -3.0710, -3.0052, -2.9122],\n",
            "          ...,\n",
            "          [-3.0283, -3.2637, -3.2072,  ..., -2.9712, -2.9571, -2.7007],\n",
            "          [-2.9727, -3.2009, -3.1336,  ..., -2.8402, -2.8436, -2.6960],\n",
            "          [-2.7934, -2.9511, -2.9262,  ..., -2.6640, -2.6760, -2.7511]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.2401, -3.1952, -2.9948,  ..., -2.7643, -2.7382, -2.8271],\n",
            "          [-3.1594, -3.3130, -3.2821,  ..., -2.8011, -2.8059, -2.9304],\n",
            "          [-3.0075, -3.2682, -3.2632,  ..., -2.9245, -2.9265, -2.9586],\n",
            "          ...,\n",
            "          [-2.4915, -2.6881, -2.7336,  ..., -2.4396, -2.5036, -2.9208],\n",
            "          [-2.4017, -2.5628, -2.6317,  ..., -2.5206, -2.5632, -2.8861],\n",
            "          [-2.4708, -2.4174, -2.4735,  ..., -2.7296, -2.7934, -2.8370]],\n",
            "\n",
            "         [[-2.1437, -2.3219, -2.5463,  ..., -2.4743, -2.3772, -2.3150],\n",
            "          [-2.3561, -2.3648, -2.4559,  ..., -2.3740, -2.3368, -2.4420],\n",
            "          [-2.2625, -2.2719, -2.3330,  ..., -2.1220, -2.0985, -2.3151],\n",
            "          ...,\n",
            "          [-2.7364, -2.8003, -2.8219,  ..., -2.3169, -2.3676, -2.2901],\n",
            "          [-2.8299, -2.9145, -2.8893,  ..., -2.3908, -2.4144, -2.3405],\n",
            "          [-2.7483, -2.7167, -2.7226,  ..., -2.2744, -2.3053, -2.3463]],\n",
            "\n",
            "         [[-2.6812, -2.7501, -2.6342,  ..., -2.7179, -2.6507, -2.5954],\n",
            "          [-2.7214, -2.7592, -2.4895,  ..., -2.6680, -2.6640, -2.5727],\n",
            "          [-2.6838, -2.6498, -2.4065,  ..., -2.7299, -2.6942, -2.5265],\n",
            "          ...,\n",
            "          [-2.4846, -2.6005, -2.5885,  ..., -2.6406, -2.6995, -2.7052],\n",
            "          [-2.3516, -2.4037, -2.3958,  ..., -2.5711, -2.6325, -2.6082],\n",
            "          [-2.1844, -2.1872, -2.1741,  ..., -2.4506, -2.5185, -2.4198]]],\n",
            "\n",
            "\n",
            "        [[[-1.9931, -2.3511, -2.5487,  ..., -2.5379, -2.4668, -2.4149],\n",
            "          [-2.2783, -2.6390, -2.6588,  ..., -2.3046, -2.2435, -2.2930],\n",
            "          [-2.3239, -2.5677, -2.5566,  ..., -2.2389, -2.1408, -2.2372],\n",
            "          ...,\n",
            "          [-2.4749, -2.5108, -2.5375,  ..., -2.3270, -2.1131, -2.1054],\n",
            "          [-2.5497, -2.5667, -2.6073,  ..., -2.3778, -2.1922, -2.1739],\n",
            "          [-2.5605, -2.7360, -2.8005,  ..., -2.6087, -2.5053, -2.5609]],\n",
            "\n",
            "         [[-2.5634, -2.1802, -2.1110,  ..., -2.4169, -2.5044, -2.5504],\n",
            "          [-2.5803, -2.1350, -2.0572,  ..., -2.4230, -2.5404, -2.6196],\n",
            "          [-2.7602, -2.2124, -2.1530,  ..., -2.5162, -2.6188, -2.5821],\n",
            "          ...,\n",
            "          [-2.1883, -2.2875, -2.3111,  ..., -2.4303, -2.5295, -2.6362],\n",
            "          [-2.1004, -2.2399, -2.2546,  ..., -2.4086, -2.4856, -2.6310],\n",
            "          [-2.3196, -2.1970, -2.1706,  ..., -2.2407, -2.3628, -2.3983]],\n",
            "\n",
            "         [[-2.3404, -2.6391, -2.7767,  ..., -2.9721, -2.9963, -2.9346],\n",
            "          [-2.4458, -2.8695, -3.0363,  ..., -3.4384, -3.3744, -3.1246],\n",
            "          [-2.5230, -2.9594, -3.0740,  ..., -3.3060, -3.2979, -3.1199],\n",
            "          ...,\n",
            "          [-2.6257, -2.7365, -2.9192,  ..., -2.5947, -2.5351, -2.4336],\n",
            "          [-2.6355, -2.7156, -2.9113,  ..., -2.6079, -2.5379, -2.4025],\n",
            "          [-2.7008, -3.0457, -3.1984,  ..., -2.8669, -2.7898, -2.6353]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.2379, -3.2070, -3.3021,  ..., -2.8533, -2.7699, -2.7930],\n",
            "          [-3.0791, -2.9578, -3.0263,  ..., -2.8150, -2.8004, -2.8313],\n",
            "          [-3.0087, -2.8399, -2.9394,  ..., -2.8199, -2.8206, -2.8378],\n",
            "          ...,\n",
            "          [-2.7912, -2.5360, -2.6578,  ..., -2.8259, -2.9676, -3.0754],\n",
            "          [-2.8616, -2.6792, -2.8049,  ..., -2.8842, -2.9646, -3.0509],\n",
            "          [-2.7313, -2.5828, -2.6124,  ..., -2.7641, -2.8052, -2.9437]],\n",
            "\n",
            "         [[-2.6060, -2.3843, -2.4221,  ..., -2.5582, -2.5089, -2.2068],\n",
            "          [-2.6507, -2.5698, -2.4743,  ..., -2.9571, -2.9224, -2.3138],\n",
            "          [-2.5505, -2.5187, -2.4068,  ..., -2.8549, -2.8235, -2.4221],\n",
            "          ...,\n",
            "          [-2.4934, -2.6346, -2.3788,  ..., -2.5153, -2.5843, -2.4043],\n",
            "          [-2.4818, -2.4353, -2.2049,  ..., -2.4178, -2.4720, -2.4006],\n",
            "          [-2.4509, -2.3816, -2.2190,  ..., -2.4276, -2.4196, -2.4138]],\n",
            "\n",
            "         [[-2.3272, -2.3725, -2.3038,  ..., -2.5040, -2.5069, -2.6427],\n",
            "          [-2.5384, -2.6057, -2.5661,  ..., -2.7449, -2.7181, -2.8658],\n",
            "          [-2.5875, -2.7026, -2.6625,  ..., -2.8456, -2.8364, -2.8578],\n",
            "          ...,\n",
            "          [-2.4205, -2.4618, -2.5353,  ..., -2.8707, -2.8518, -2.7592],\n",
            "          [-2.4967, -2.4715, -2.5066,  ..., -2.8142, -2.7789, -2.6812],\n",
            "          [-2.5466, -2.5269, -2.5405,  ..., -2.5857, -2.6006, -2.4240]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.3770, -2.4642, -2.6375,  ..., -2.6544, -2.6435, -2.4113],\n",
            "          [-2.5978, -2.6613, -2.7305,  ..., -2.4996, -2.4655, -2.4444],\n",
            "          [-2.5999, -2.5656, -2.5832,  ..., -2.4156, -2.3725, -2.3939],\n",
            "          ...,\n",
            "          [-2.5156, -2.5705, -2.6156,  ..., -2.5415, -2.4560, -2.3707],\n",
            "          [-2.5160, -2.5892, -2.6292,  ..., -2.4894, -2.4161, -2.3916],\n",
            "          [-2.5594, -2.5742, -2.5819,  ..., -2.5540, -2.5405, -2.5952]],\n",
            "\n",
            "         [[-2.2555, -2.4304, -2.2228,  ..., -2.5897, -2.7464, -2.6110],\n",
            "          [-2.6989, -3.1386, -3.1066,  ..., -2.5146, -2.6284, -2.5225],\n",
            "          [-2.8186, -3.2253, -3.2470,  ..., -2.5716, -2.6939, -2.6355],\n",
            "          ...,\n",
            "          [-2.3800, -2.5040, -2.5258,  ..., -2.7276, -2.8798, -2.6061],\n",
            "          [-2.3209, -2.5097, -2.5105,  ..., -2.6767, -2.8149, -2.5519],\n",
            "          [-2.3511, -2.4619, -2.4193,  ..., -2.6437, -2.7116, -2.5379]],\n",
            "\n",
            "         [[-2.3506, -1.9965, -2.0868,  ..., -2.1256, -2.2389, -2.3205],\n",
            "          [-2.7415, -2.5503, -2.6387,  ..., -2.7929, -2.8060, -2.4364],\n",
            "          [-2.6253, -2.4024, -2.4808,  ..., -2.8533, -2.8965, -2.5830],\n",
            "          ...,\n",
            "          [-2.2010, -2.1294, -2.1157,  ..., -2.2514, -2.3340, -2.3282],\n",
            "          [-2.2309, -2.2036, -2.1878,  ..., -2.2629, -2.3251, -2.3021],\n",
            "          [-2.0826, -2.1786, -2.1814,  ..., -2.4294, -2.4155, -2.2818]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.6183, -3.5240, -3.4573,  ..., -3.4386, -3.2076, -3.2456],\n",
            "          [-3.5800, -3.6192, -3.4288,  ..., -3.1658, -3.0075, -3.1741],\n",
            "          [-3.7014, -3.6585, -3.4592,  ..., -3.1372, -3.0205, -3.0405],\n",
            "          ...,\n",
            "          [-3.0727, -3.1769, -3.1282,  ..., -3.0100, -2.9919, -3.0386],\n",
            "          [-2.9780, -3.0568, -3.0437,  ..., -2.9766, -2.9443, -2.9792],\n",
            "          [-2.6918, -2.8290, -2.8350,  ..., -2.7320, -2.7825, -2.8226]],\n",
            "\n",
            "         [[-1.9996, -2.3419, -2.4489,  ..., -2.2702, -2.2801, -2.4176],\n",
            "          [-1.7663, -1.5617, -1.6034,  ..., -1.8411, -1.9572, -2.2785],\n",
            "          [-1.6628, -1.4928, -1.5834,  ..., -1.8043, -1.8948, -2.1571],\n",
            "          ...,\n",
            "          [-2.3617, -2.4413, -2.5170,  ..., -2.4807, -2.3030, -2.2600],\n",
            "          [-2.4335, -2.4358, -2.4651,  ..., -2.4508, -2.2604, -2.3125],\n",
            "          [-2.5863, -2.5475, -2.5774,  ..., -2.4880, -2.3225, -2.4165]],\n",
            "\n",
            "         [[-2.5462, -2.1987, -2.1277,  ..., -2.1756, -2.0812, -2.3091],\n",
            "          [-2.3975, -2.2560, -2.0403,  ..., -2.4654, -2.4366, -2.4868],\n",
            "          [-2.5226, -2.4226, -2.1407,  ..., -2.5946, -2.6099, -2.5302],\n",
            "          ...,\n",
            "          [-2.4554, -2.2036, -2.1266,  ..., -2.5655, -2.7207, -2.6904],\n",
            "          [-2.4871, -2.1536, -2.0757,  ..., -2.5592, -2.6973, -2.6390],\n",
            "          [-2.6526, -2.4179, -2.4257,  ..., -2.5371, -2.5821, -2.5294]]],\n",
            "\n",
            "\n",
            "        [[[-2.1166, -2.1088, -2.2698,  ..., -2.4321, -2.3589, -2.2922],\n",
            "          [-2.6325, -2.9102, -3.0154,  ..., -2.7853, -2.6428, -2.5037],\n",
            "          [-2.5415, -2.8779, -2.9818,  ..., -2.8582, -2.6465, -2.4937],\n",
            "          ...,\n",
            "          [-2.5164, -2.9161, -2.9892,  ..., -2.4573, -2.2356, -2.2744],\n",
            "          [-2.5959, -2.9148, -2.9303,  ..., -2.4307, -2.2353, -2.3133],\n",
            "          [-2.7089, -3.0259, -3.1205,  ..., -2.6668, -2.5306, -2.5626]],\n",
            "\n",
            "         [[-2.2009, -2.2659, -2.1398,  ..., -2.4308, -2.6122, -2.7234],\n",
            "          [-2.3743, -2.3510, -2.3469,  ..., -2.4169, -2.5075, -2.6624],\n",
            "          [-2.5518, -2.4103, -2.4651,  ..., -2.6177, -2.7086, -2.7006],\n",
            "          ...,\n",
            "          [-2.1024, -2.4021, -2.4747,  ..., -2.6904, -2.8827, -2.9413],\n",
            "          [-2.2402, -2.6448, -2.7072,  ..., -2.7060, -2.8627, -2.9061],\n",
            "          [-2.6042, -2.8962, -2.7912,  ..., -2.7375, -2.7908, -2.7539]],\n",
            "\n",
            "         [[-2.9657, -2.9183, -2.9919,  ..., -3.0735, -2.9913, -2.6739],\n",
            "          [-3.1378, -3.2547, -3.2728,  ..., -3.5154, -3.2887, -2.7676],\n",
            "          [-3.0874, -3.2787, -3.3269,  ..., -3.4016, -3.1819, -2.7447],\n",
            "          ...,\n",
            "          [-2.6589, -3.0972, -3.1551,  ..., -2.9590, -2.8945, -2.7164],\n",
            "          [-2.6971, -3.1883, -3.3150,  ..., -2.9483, -2.8611, -2.6760],\n",
            "          [-2.5131, -2.9305, -3.0647,  ..., -2.7335, -2.6795, -2.6288]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5561, -2.5959, -2.7603,  ..., -2.8516, -2.8129, -2.8890],\n",
            "          [-2.5999, -2.4298, -2.6130,  ..., -2.9502, -2.9830, -3.2257],\n",
            "          [-2.5687, -2.2209, -2.3370,  ..., -2.9409, -3.0335, -3.1516],\n",
            "          ...,\n",
            "          [-2.6279, -2.4015, -2.3486,  ..., -2.5771, -2.7868, -3.0919],\n",
            "          [-2.6348, -2.4199, -2.4023,  ..., -2.5953, -2.7662, -3.0317],\n",
            "          [-2.3329, -2.1837, -2.2372,  ..., -2.6936, -2.7322, -2.8564]],\n",
            "\n",
            "         [[-2.7115, -2.3494, -2.2594,  ..., -2.1101, -2.0676, -2.1900],\n",
            "          [-2.7468, -2.4159, -2.3078,  ..., -2.1392, -2.1707, -2.4001],\n",
            "          [-2.5436, -2.2175, -2.1412,  ..., -2.0360, -2.0437, -2.3587],\n",
            "          ...,\n",
            "          [-2.1347, -1.7453, -1.7188,  ..., -2.1537, -2.1119, -2.1518],\n",
            "          [-1.9392, -1.6359, -1.5743,  ..., -2.0864, -2.0719, -2.1862],\n",
            "          [-2.1237, -1.9297, -1.9006,  ..., -2.0626, -2.0915, -2.2778]],\n",
            "\n",
            "         [[-2.4762, -2.6041, -2.4971,  ..., -2.8360, -2.7975, -2.6646],\n",
            "          [-2.3583, -2.4850, -2.2965,  ..., -2.6693, -2.7228, -2.6381],\n",
            "          [-2.4847, -2.6574, -2.4883,  ..., -2.7390, -2.7912, -2.6979],\n",
            "          ...,\n",
            "          [-2.8331, -2.8341, -2.7080,  ..., -2.9681, -3.0921, -2.8728],\n",
            "          [-2.8056, -2.7066, -2.5300,  ..., -2.8575, -2.9822, -2.7530],\n",
            "          [-2.7223, -2.5419, -2.4662,  ..., -2.6541, -2.7398, -2.6739]]],\n",
            "\n",
            "\n",
            "        [[[-2.3754, -2.4871, -2.6286,  ..., -2.6910, -2.6000, -2.3333],\n",
            "          [-2.4499, -2.8370, -2.9889,  ..., -2.8518, -2.7637, -2.7590],\n",
            "          [-2.4726, -2.8782, -3.0483,  ..., -2.8635, -2.7659, -2.7290],\n",
            "          ...,\n",
            "          [-2.1195, -2.4304, -2.4111,  ..., -2.5462, -2.5350, -2.5018],\n",
            "          [-2.2478, -2.4848, -2.4709,  ..., -2.6122, -2.5971, -2.5695],\n",
            "          [-2.4154, -2.5777, -2.5362,  ..., -2.6409, -2.6660, -2.6332]],\n",
            "\n",
            "         [[-2.2090, -2.1624, -2.0441,  ..., -2.0653, -2.1324, -2.1621],\n",
            "          [-2.0693, -2.0322, -2.0618,  ..., -2.2008, -2.2616, -2.0018],\n",
            "          [-2.1556, -2.0083, -2.0622,  ..., -2.3459, -2.3707, -2.0587],\n",
            "          ...,\n",
            "          [-2.6128, -2.2428, -2.1894,  ..., -2.0700, -2.1649, -2.2394],\n",
            "          [-2.5678, -2.2406, -2.1931,  ..., -2.0880, -2.1400, -2.2430],\n",
            "          [-2.7038, -2.5822, -2.5538,  ..., -2.2146, -2.2644, -2.3660]],\n",
            "\n",
            "         [[-2.5216, -2.4979, -2.6198,  ..., -2.6831, -2.7487, -2.2875],\n",
            "          [-3.0600, -3.1271, -3.2099,  ..., -3.1047, -2.9880, -2.5064],\n",
            "          [-3.0338, -3.1714, -3.2179,  ..., -3.1225, -2.9723, -2.6231],\n",
            "          ...,\n",
            "          [-2.8350, -2.7158, -2.8270,  ..., -2.5946, -2.6308, -2.4415],\n",
            "          [-2.8232, -2.7125, -2.8191,  ..., -2.6093, -2.6073, -2.4463],\n",
            "          [-2.5598, -2.5549, -2.6214,  ..., -2.6332, -2.6073, -2.4271]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.0890, -3.2034, -3.2252,  ..., -3.2124, -3.2877, -3.7069],\n",
            "          [-3.0592, -3.5082, -3.5457,  ..., -3.0679, -3.1809, -3.7891],\n",
            "          [-3.0454, -3.4208, -3.4983,  ..., -2.9178, -3.0956, -3.5865],\n",
            "          ...,\n",
            "          [-3.1767, -3.0358, -3.0336,  ..., -3.1516, -3.2147, -3.4922],\n",
            "          [-3.0331, -2.9392, -2.9698,  ..., -3.1676, -3.2434, -3.4807],\n",
            "          [-2.7660, -2.5764, -2.5156,  ..., -2.9750, -3.0360, -3.1806]],\n",
            "\n",
            "         [[-2.4228, -2.3990, -2.4490,  ..., -2.0506, -2.0009, -2.1714],\n",
            "          [-2.4620, -2.2555, -2.1904,  ..., -1.9746, -1.9723, -2.3349],\n",
            "          [-2.4327, -2.2283, -2.1634,  ..., -1.9941, -2.0230, -2.3461],\n",
            "          ...,\n",
            "          [-2.6003, -2.6745, -2.7326,  ..., -2.5703, -2.5527, -2.4048],\n",
            "          [-2.5478, -2.5458, -2.5896,  ..., -2.5828, -2.5376, -2.4150],\n",
            "          [-2.5880, -2.3935, -2.4727,  ..., -2.5381, -2.5175, -2.4069]],\n",
            "\n",
            "         [[-2.5184, -2.5260, -2.5684,  ..., -2.2262, -2.1773, -2.5989],\n",
            "          [-2.7503, -2.8433, -2.8822,  ..., -2.5864, -2.5135, -2.7513],\n",
            "          [-2.7616, -2.8651, -2.8148,  ..., -2.6197, -2.5525, -2.7266],\n",
            "          ...,\n",
            "          [-2.5088, -2.3911, -2.4002,  ..., -2.7644, -2.7407, -2.5540],\n",
            "          [-2.4575, -2.3826, -2.3519,  ..., -2.7709, -2.7596, -2.5161],\n",
            "          [-2.5052, -2.5923, -2.5944,  ..., -2.7734, -2.7575, -2.4877]]]],\n",
            "       device='cuda:0')\n",
            "tensor([[[[-1.3347e-01, -7.3951e-02, -5.2999e-02,  ...,  5.2020e-02,\n",
            "           -8.4334e-02,  6.8795e-02],\n",
            "          [ 7.5889e-02,  8.7391e-03, -5.8947e-02,  ...,  3.4320e-01,\n",
            "           -3.9205e-03,  1.3314e-01],\n",
            "          [-1.6827e-01,  1.3558e-01, -6.7783e-02,  ...,  3.0154e-01,\n",
            "           -6.4893e-02,  1.0251e-01],\n",
            "          ...,\n",
            "          [ 4.4525e-02, -5.8058e-02,  1.6698e-01,  ...,  1.4879e-01,\n",
            "           -1.6306e-02,  1.8888e-01],\n",
            "          [-5.5932e-03, -1.7029e-01, -1.0463e-01,  ..., -4.1125e-02,\n",
            "           -1.2211e-01,  8.5086e-02],\n",
            "          [-3.5971e-02,  5.2564e-02,  7.6686e-02,  ...,  1.3705e-01,\n",
            "           -6.8808e-03,  1.2629e-01]],\n",
            "\n",
            "         [[ 4.9015e-02,  3.0744e-02,  1.4934e-01,  ..., -1.1400e-01,\n",
            "            1.0721e-01,  1.0222e-01],\n",
            "          [-2.1838e-02, -2.3212e-01,  2.0689e-02,  ..., -5.0101e-02,\n",
            "           -3.2008e-02, -1.0560e-01],\n",
            "          [-1.0839e-01, -2.0348e-01,  3.8550e-02,  ..., -1.7519e-01,\n",
            "           -2.9456e-02,  2.1517e-02],\n",
            "          ...,\n",
            "          [ 2.1249e-01, -4.6755e-01,  7.2303e-02,  ..., -3.5774e-01,\n",
            "            2.0138e-01,  3.9550e-02],\n",
            "          [ 1.0360e-01,  1.6063e-02,  2.6179e-02,  ...,  1.4308e-02,\n",
            "            1.3849e-01,  1.2597e-01],\n",
            "          [ 3.0488e-02, -2.8996e-01,  4.0766e-02,  ..., -2.4624e-01,\n",
            "            6.5256e-02, -1.3223e-01]],\n",
            "\n",
            "         [[-2.3724e-01, -1.2386e-02, -6.9269e-02,  ..., -1.2566e-01,\n",
            "           -1.0598e-01, -3.1686e-02],\n",
            "          [ 1.6009e-01,  4.5878e-01,  4.4418e-04,  ...,  4.7876e-01,\n",
            "           -8.4054e-02,  2.0248e-01],\n",
            "          [-2.8089e-01, -3.7029e-02, -1.0137e-01,  ...,  9.8291e-02,\n",
            "           -1.1012e-01,  3.0475e-02],\n",
            "          ...,\n",
            "          [-1.0507e-01,  4.3544e-01,  1.7376e-02,  ...,  3.7369e-01,\n",
            "           -3.6112e-02,  2.3648e-03],\n",
            "          [ 5.3658e-02,  2.8828e-03, -2.3135e-02,  ..., -6.4947e-02,\n",
            "           -6.8841e-02, -1.1250e-02],\n",
            "          [ 8.0743e-02,  3.0461e-01,  6.1043e-03,  ...,  4.8999e-01,\n",
            "           -1.2757e-01,  1.6463e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0902e-01,  6.4140e-02, -1.3418e-01,  ...,  1.1519e-02,\n",
            "           -5.0000e-02,  8.1561e-02],\n",
            "          [ 1.7108e-01, -2.9423e-01,  1.1917e-01,  ..., -2.5694e-01,\n",
            "            9.8660e-02, -1.0032e-01],\n",
            "          [ 4.0723e-02, -2.5458e-02, -6.7935e-02,  ...,  3.4677e-03,\n",
            "           -2.4005e-02,  8.1136e-02],\n",
            "          ...,\n",
            "          [ 2.7192e-01, -1.2037e-01,  1.4702e-01,  ..., -1.0103e-01,\n",
            "            7.9480e-02, -1.9057e-02],\n",
            "          [-1.0472e-01, -2.0408e-01, -5.9548e-02,  ..., -4.5278e-02,\n",
            "           -8.0552e-02,  9.2299e-02],\n",
            "          [ 2.1640e-01, -1.9071e-01,  3.0750e-02,  ..., -3.2876e-01,\n",
            "            5.0484e-02, -8.7259e-02]],\n",
            "\n",
            "         [[ 1.8199e-02,  6.3213e-03,  1.3693e-01,  ...,  1.0718e-01,\n",
            "            1.2236e-01,  5.5009e-02],\n",
            "          [ 1.1215e-01,  3.8203e-02, -5.2437e-02,  ...,  3.2726e-01,\n",
            "            6.6126e-02,  1.9117e-01],\n",
            "          [ 4.4907e-02,  5.6435e-02,  8.9460e-03,  ...,  5.4192e-02,\n",
            "            1.3567e-02,  2.5386e-02],\n",
            "          ...,\n",
            "          [-8.3607e-02,  1.0284e-01, -5.8411e-02,  ...,  2.4450e-01,\n",
            "           -1.4893e-01,  1.1623e-01],\n",
            "          [-8.6084e-02,  2.4479e-01,  1.4344e-02,  ...,  1.2873e-01,\n",
            "            1.1319e-01,  3.3996e-02],\n",
            "          [-1.1475e-01, -2.3200e-01, -3.4944e-04,  ..., -9.6269e-02,\n",
            "            4.7750e-02, -4.0776e-02]],\n",
            "\n",
            "         [[-1.5909e-01,  2.3106e-01, -1.4714e-01,  ...,  1.2248e-01,\n",
            "           -8.5078e-03,  1.0458e-01],\n",
            "          [-8.9280e-02, -2.3626e-01, -9.6185e-02,  ..., -5.2615e-01,\n",
            "           -4.0939e-02, -1.9849e-01],\n",
            "          [-9.2410e-02,  1.7765e-01, -3.9558e-02,  ...,  2.4235e-01,\n",
            "            2.8440e-02, -1.8754e-02],\n",
            "          ...,\n",
            "          [-1.7632e-01, -2.6518e-01, -1.0227e-02,  ..., -3.7813e-01,\n",
            "           -7.2753e-02, -3.8181e-01],\n",
            "          [-1.3706e-01,  4.0465e-02, -9.9394e-02,  ...,  1.9822e-01,\n",
            "           -1.2855e-01,  1.5326e-01],\n",
            "          [ 2.1757e-02, -2.2422e-01, -1.5505e-02,  ..., -1.9300e-01,\n",
            "           -6.1018e-02, -1.0284e-01]]],\n",
            "\n",
            "\n",
            "        [[[-3.5515e-01, -4.4043e-02, -1.2620e-01,  ...,  3.4282e-01,\n",
            "           -1.8158e-01, -1.6270e-02],\n",
            "          [ 6.3444e-02,  4.7588e-01, -4.0562e-01,  ...,  2.2655e-01,\n",
            "            1.2610e-01,  1.5365e-02],\n",
            "          [-4.9743e-01,  6.2765e-02,  1.0312e-03,  ..., -8.9988e-03,\n",
            "           -2.5891e-01,  2.0193e-01],\n",
            "          ...,\n",
            "          [-9.5905e-02, -1.7255e-02, -1.9639e-01,  ..., -7.6692e-02,\n",
            "           -9.8086e-02,  2.3502e-01],\n",
            "          [-7.8509e-02,  1.6979e-01,  1.5152e-02,  ...,  1.1895e-01,\n",
            "           -2.0018e-01,  1.6259e-01],\n",
            "          [ 2.1787e-01,  1.8570e-01, -1.0743e-01,  ...,  1.7566e-01,\n",
            "            1.7407e-01,  2.5084e-01]],\n",
            "\n",
            "         [[ 4.6769e-01,  2.1440e-01,  3.5702e-01,  ...,  9.5461e-02,\n",
            "           -8.2065e-02,  9.2968e-02],\n",
            "          [ 6.6429e-02,  8.3851e-02,  2.2789e-01,  ..., -3.4238e-01,\n",
            "           -3.0209e-02, -9.4436e-02],\n",
            "          [ 3.5786e-01,  7.6527e-02,  1.0858e-01,  ..., -8.7241e-02,\n",
            "            2.1468e-02, -1.0640e-01],\n",
            "          ...,\n",
            "          [-2.6123e-01,  6.3742e-02,  1.4661e-01,  ..., -1.6410e-01,\n",
            "           -1.6938e-01, -1.4719e-01],\n",
            "          [-1.5194e-01, -5.1566e-02,  4.9177e-02,  ..., -4.7604e-02,\n",
            "           -7.0564e-02, -1.8383e-01],\n",
            "          [ 2.3238e-02, -1.0223e-02,  1.3445e-01,  ..., -2.0341e-01,\n",
            "           -1.3540e-02, -2.2073e-02]],\n",
            "\n",
            "         [[-2.1860e-01,  2.4086e-01, -2.0735e-01,  ...,  1.4922e-01,\n",
            "           -2.2773e-01,  8.6084e-03],\n",
            "          [-2.7048e-01,  6.3701e-01, -3.1401e-01,  ...,  2.7284e-01,\n",
            "            1.6593e-01,  2.4017e-02],\n",
            "          [ 1.8245e-01,  4.2477e-01, -2.6921e-02,  ...,  9.1832e-02,\n",
            "           -1.1760e-01,  2.1330e-01],\n",
            "          ...,\n",
            "          [-3.9106e-02,  2.6915e-01, -1.7786e-01,  ...,  5.4048e-01,\n",
            "           -1.1823e-01,  5.5117e-02],\n",
            "          [-2.0141e-01,  8.4708e-03, -1.4658e-01,  ...,  5.9671e-02,\n",
            "           -1.7484e-01,  7.2989e-02],\n",
            "          [-1.6162e-02,  9.9060e-02,  3.9124e-02,  ...,  6.5299e-02,\n",
            "            4.3041e-02,  3.9648e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.8291e-02,  3.5618e-01, -1.1985e-01,  ...,  5.8211e-02,\n",
            "            2.2559e-02,  1.6343e-01],\n",
            "          [-2.8387e-01, -1.2350e+00,  2.3540e-01,  ..., -4.0047e-01,\n",
            "           -9.3473e-02, -1.7475e-01],\n",
            "          [-1.8837e-01,  6.8483e-01,  2.1762e-01,  ..., -1.2234e-02,\n",
            "           -1.1280e-01,  1.1223e-01],\n",
            "          ...,\n",
            "          [ 9.1546e-02, -1.2600e-01, -5.1303e-02,  ..., -3.1327e-01,\n",
            "           -8.1974e-02, -2.4089e-01],\n",
            "          [ 6.6867e-03,  2.4237e-01,  7.6472e-02,  ..., -8.1492e-02,\n",
            "            8.3534e-02,  1.9478e-03],\n",
            "          [ 1.3719e-02, -3.5912e-01, -6.4080e-02,  ...,  1.1379e-02,\n",
            "           -6.8123e-02, -2.1422e-01]],\n",
            "\n",
            "         [[ 7.3855e-01, -1.2876e+00,  1.1520e+00,  ..., -2.8466e-01,\n",
            "            1.6374e-01, -7.1551e-02],\n",
            "          [-5.5530e-01,  1.3346e+00, -1.9903e-01,  ...,  4.1465e-01,\n",
            "           -1.5317e-01,  1.0028e-01],\n",
            "          [ 4.7239e-01, -4.1958e-01,  3.3302e-01,  ...,  3.0558e-02,\n",
            "            2.4200e-02, -8.1738e-02],\n",
            "          ...,\n",
            "          [ 9.3505e-02,  3.6559e-01, -8.1312e-02,  ...,  2.3476e-01,\n",
            "           -1.3863e-01,  2.4718e-01],\n",
            "          [ 1.1431e-01, -2.2825e-01,  1.9722e-01,  ...,  8.1354e-02,\n",
            "            1.6723e-02, -1.0337e-01],\n",
            "          [ 4.4464e-03, -3.3258e-02,  4.1302e-02,  ...,  2.4809e-02,\n",
            "            1.0356e-01, -1.6491e-01]],\n",
            "\n",
            "         [[-5.5828e-01,  1.2678e+00, -1.3157e-01,  ...,  7.3068e-01,\n",
            "            2.2901e-02,  1.8943e-02],\n",
            "          [-9.3360e-02,  1.0879e+00, -1.7522e-01,  ..., -1.0640e-02,\n",
            "           -5.8091e-02, -2.2937e-01],\n",
            "          [ 2.9331e-02,  8.3478e-01, -3.1583e-02,  ...,  2.0855e-01,\n",
            "           -2.1375e-01,  1.0843e-01],\n",
            "          ...,\n",
            "          [ 4.1137e-02,  1.6089e-01, -1.7227e-01,  ..., -2.6527e-02,\n",
            "           -1.0106e-01, -1.2946e-01],\n",
            "          [ 1.7076e-01,  7.3014e-02, -2.6222e-01,  ...,  2.6729e-01,\n",
            "           -1.7528e-01,  1.9142e-01],\n",
            "          [-1.8267e-01,  9.3139e-02, -3.7785e-02,  ..., -3.4335e-01,\n",
            "           -1.0246e-01,  9.8411e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.4672e-02, -2.1604e-02, -3.2375e-02,  ..., -1.9079e-01,\n",
            "           -1.0469e-02,  4.7053e-02],\n",
            "          [ 1.1048e-01,  1.0538e-01, -1.3585e-02,  ...,  1.3427e-01,\n",
            "            2.4929e-02,  6.1342e-02],\n",
            "          [-6.9398e-02, -1.4323e-01, -1.1960e-02,  ..., -2.3459e-01,\n",
            "           -1.5053e-01,  2.6807e-03],\n",
            "          ...,\n",
            "          [ 1.8134e-01, -4.7749e-02, -4.8901e-02,  ...,  1.8832e-02,\n",
            "            1.2142e-01,  5.7507e-02],\n",
            "          [ 1.0869e-02, -2.3084e-01, -1.5155e-01,  ..., -1.6215e-01,\n",
            "           -7.2298e-02, -3.7174e-02],\n",
            "          [-6.3841e-02,  1.9917e-01,  1.3234e-02,  ...,  8.7867e-02,\n",
            "           -1.0431e-01,  1.1588e-01]],\n",
            "\n",
            "         [[ 7.4567e-02,  5.8249e-02,  1.7597e-01,  ...,  1.3001e-01,\n",
            "            1.7889e-01,  3.5052e-02],\n",
            "          [ 6.7434e-02, -5.2792e-01, -7.2662e-02,  ..., -5.4642e-01,\n",
            "           -3.6509e-03, -1.9723e-01],\n",
            "          [ 9.8098e-02,  6.5978e-02,  1.2958e-01,  ...,  1.8822e-01,\n",
            "            9.8119e-02,  7.2205e-02],\n",
            "          ...,\n",
            "          [-1.4065e-02, -4.1116e-01,  8.7321e-03,  ..., -5.7043e-01,\n",
            "            1.1741e-01, -2.7366e-01],\n",
            "          [ 1.2284e-01, -2.9895e-02,  7.4059e-02,  ...,  2.5711e-02,\n",
            "            1.5713e-01,  1.1248e-01],\n",
            "          [-4.7249e-02, -2.0726e-01, -3.9594e-02,  ..., -2.2043e-01,\n",
            "           -4.4351e-02, -7.8552e-02]],\n",
            "\n",
            "         [[-1.3004e-01, -2.8252e-01,  1.6103e-02,  ..., -1.1484e-01,\n",
            "           -4.2967e-04,  9.0724e-02],\n",
            "          [-1.8782e-01,  2.8139e-01, -7.7510e-02,  ...,  4.0731e-01,\n",
            "            3.3320e-02,  1.5781e-01],\n",
            "          [ 5.4747e-02, -1.0354e-01, -2.1407e-02,  ..., -8.9928e-02,\n",
            "            1.8423e-02,  1.7360e-02],\n",
            "          ...,\n",
            "          [-9.1040e-02,  3.9575e-01, -1.3312e-01,  ...,  1.8720e-01,\n",
            "           -5.0857e-02, -4.9530e-02],\n",
            "          [ 8.0725e-02, -1.1078e-01,  3.8820e-02,  ...,  1.1399e-02,\n",
            "            1.3992e-01,  4.9953e-02],\n",
            "          [ 5.5071e-02,  1.1560e-01,  5.2464e-02,  ...,  2.1199e-01,\n",
            "            2.5863e-02,  1.0653e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4647e-01, -1.9269e-01, -1.0585e-01,  ...,  1.8131e-01,\n",
            "           -7.4076e-02,  4.9527e-02],\n",
            "          [ 6.9320e-02, -2.0199e-01,  2.2168e-01,  ..., -3.3110e-01,\n",
            "            1.8491e-01,  1.4260e-01],\n",
            "          [ 2.4918e-02, -8.2679e-02, -1.1317e-01,  ...,  1.5992e-01,\n",
            "           -5.8357e-02, -1.8237e-02],\n",
            "          ...,\n",
            "          [ 3.2170e-01, -2.3334e-01, -7.3062e-03,  ...,  2.9307e-02,\n",
            "            7.0595e-02, -1.1133e-01],\n",
            "          [-7.7798e-02, -1.6214e-01,  1.5609e-03,  ...,  3.9490e-03,\n",
            "           -1.0248e-01,  7.4657e-03],\n",
            "          [ 1.9443e-01, -1.0591e-01,  2.2821e-02,  ..., -1.9275e-01,\n",
            "            1.4563e-01, -4.3055e-02]],\n",
            "\n",
            "         [[-4.0504e-02,  1.0029e-01,  7.9327e-02,  ..., -1.7105e-01,\n",
            "            1.4198e-01, -5.2593e-02],\n",
            "          [-1.7973e-01,  2.9766e-01, -1.1471e-01,  ...,  3.3662e-01,\n",
            "           -2.4898e-01,  9.9996e-02],\n",
            "          [ 5.9884e-02, -1.2005e-01,  6.1103e-02,  ..., -1.0937e-01,\n",
            "            6.0921e-02, -3.0624e-03],\n",
            "          ...,\n",
            "          [-2.2700e-01, -4.2440e-02, -2.2067e-01,  ...,  1.1687e-01,\n",
            "           -2.0232e-01,  5.7394e-02],\n",
            "          [-1.5012e-02,  7.2495e-02, -3.7432e-02,  ...,  7.6972e-02,\n",
            "           -3.0096e-02,  6.4204e-03],\n",
            "          [-1.3599e-01, -1.0898e-01, -4.3910e-02,  ..., -1.6653e-01,\n",
            "           -4.2857e-02, -3.2584e-02]],\n",
            "\n",
            "         [[-4.9349e-02,  2.3540e-01, -2.2918e-02,  ...,  3.1599e-01,\n",
            "           -2.1980e-01,  8.8218e-02],\n",
            "          [-2.6188e-01,  2.0784e-01, -1.5799e-01,  ...,  2.1651e-01,\n",
            "            1.7367e-02, -1.7833e-01],\n",
            "          [-2.8184e-01,  3.9197e-01, -4.1372e-02,  ...,  2.6458e-01,\n",
            "            3.8439e-03,  1.4251e-01],\n",
            "          ...,\n",
            "          [-1.1032e-01,  9.0598e-03, -8.1097e-02,  ..., -1.9436e-01,\n",
            "           -8.9877e-02,  3.5555e-02],\n",
            "          [-1.3148e-01,  2.5660e-01, -2.5958e-01,  ...,  1.7354e-01,\n",
            "           -1.1600e-01,  1.0888e-01],\n",
            "          [ 8.3659e-02, -2.0353e-01,  6.0836e-02,  ..., -1.4351e-01,\n",
            "            1.5254e-02, -8.3577e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.4227e-01, -3.5114e-02, -1.7734e-01,  ..., -3.6699e-02,\n",
            "           -1.9344e-02,  1.1556e-01],\n",
            "          [ 2.5071e-01, -3.0719e-01, -5.1928e-03,  ...,  1.5035e-01,\n",
            "            1.6682e-01,  1.2761e-01],\n",
            "          [-1.4714e-01, -3.1823e-01, -1.7245e-01,  ..., -1.1665e-03,\n",
            "           -8.7755e-02,  1.4099e-01],\n",
            "          ...,\n",
            "          [ 1.9925e-01, -2.9728e-01, -1.7606e-02,  ..., -8.5646e-02,\n",
            "           -9.0167e-02,  1.8813e-01],\n",
            "          [ 3.6434e-02, -3.0606e-01,  1.3387e-02,  ...,  1.9430e-01,\n",
            "           -7.1119e-03,  5.7865e-02],\n",
            "          [-4.8766e-02,  8.7639e-02, -9.2317e-03,  ...,  2.0482e-01,\n",
            "           -6.8118e-02,  1.2669e-01]],\n",
            "\n",
            "         [[ 1.6105e-01,  1.5131e-01,  1.5299e-01,  ...,  1.1166e-01,\n",
            "           -8.3350e-02, -1.8300e-02],\n",
            "          [ 3.0673e-01, -5.3594e-01, -1.1164e-01,  ..., -3.5916e-01,\n",
            "           -7.8735e-02,  2.3714e-03],\n",
            "          [ 2.6817e-01,  5.6247e-02,  1.0110e-01,  ...,  6.6319e-02,\n",
            "            2.3459e-02, -5.3304e-02],\n",
            "          ...,\n",
            "          [ 1.8246e-01, -5.8177e-01, -1.0413e-01,  ..., -4.8202e-01,\n",
            "            2.5915e-03, -1.0067e-01],\n",
            "          [ 1.1164e-01,  1.2027e-01,  3.0196e-02,  ...,  1.5621e-02,\n",
            "           -2.6975e-03,  4.1538e-02],\n",
            "          [-2.0915e-02, -2.4859e-01,  2.6680e-02,  ..., -2.3118e-01,\n",
            "           -5.8187e-02, -1.1840e-01]],\n",
            "\n",
            "         [[-8.3454e-02,  6.4569e-02, -1.1530e-01,  ..., -8.0525e-02,\n",
            "           -1.2359e-01,  1.1476e-02],\n",
            "          [-6.3780e-02,  3.2373e-01, -2.2955e-01,  ...,  4.9240e-01,\n",
            "           -4.8264e-02,  2.2055e-02],\n",
            "          [ 1.1945e-01,  9.5449e-03,  5.6357e-02,  ..., -2.0035e-02,\n",
            "           -6.6140e-02,  9.1871e-03],\n",
            "          ...,\n",
            "          [-2.5528e-01,  3.0713e-01, -9.9633e-03,  ...,  4.5598e-01,\n",
            "           -1.5670e-01,  1.2006e-01],\n",
            "          [ 5.0561e-02, -1.5861e-02, -6.9642e-02,  ...,  1.0802e-01,\n",
            "            1.1859e-02,  8.9974e-02],\n",
            "          [ 1.5739e-01,  4.2697e-01, -1.5244e-02,  ...,  2.5168e-01,\n",
            "           -9.6187e-02,  1.0094e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.1293e-01, -2.0212e-02, -1.5385e-01,  ..., -9.4749e-02,\n",
            "            6.8109e-02,  5.9016e-02],\n",
            "          [ 1.8336e-01, -2.6688e-01,  1.0751e-01,  ..., -1.6432e-01,\n",
            "            8.7110e-02, -3.0853e-02],\n",
            "          [-2.5326e-01,  2.8750e-02, -1.7061e-01,  ..., -1.4500e-01,\n",
            "           -3.5094e-02,  3.2943e-02],\n",
            "          ...,\n",
            "          [ 3.0685e-01, -6.7037e-02, -3.5094e-02,  ..., -1.7577e-01,\n",
            "           -7.0039e-02, -1.8582e-01],\n",
            "          [-1.8410e-01, -1.8717e-01, -9.2572e-03,  ..., -1.0403e-01,\n",
            "            1.2086e-02,  1.3668e-01],\n",
            "          [ 3.0767e-01, -3.1444e-01,  3.8860e-02,  ..., -2.8948e-01,\n",
            "           -9.9745e-04, -1.2228e-01]],\n",
            "\n",
            "         [[ 1.0202e-01, -4.7173e-02,  2.5736e-01,  ...,  9.5660e-02,\n",
            "            1.0904e-01,  1.7480e-02],\n",
            "          [-2.9375e-01,  2.7932e-01, -5.6544e-02,  ...,  3.2885e-01,\n",
            "           -8.8259e-02,  5.7541e-02],\n",
            "          [ 9.7034e-02,  2.1248e-01,  2.5018e-02,  ...,  2.1727e-01,\n",
            "            8.0984e-02,  1.6721e-02],\n",
            "          ...,\n",
            "          [-1.4192e-01,  3.5459e-01, -7.3425e-02,  ...,  3.1588e-01,\n",
            "            9.1531e-02,  4.2772e-01],\n",
            "          [ 3.4550e-03,  6.2608e-02,  1.7020e-01,  ...,  2.1708e-02,\n",
            "            1.5901e-02, -1.1763e-01],\n",
            "          [-1.8812e-01, -1.0269e-01, -8.0709e-02,  ..., -1.0403e-01,\n",
            "            7.4454e-03,  4.0893e-03]],\n",
            "\n",
            "         [[-1.7439e-01,  4.5558e-01,  1.2549e-01,  ...,  1.5688e-01,\n",
            "            9.7320e-02, -9.9056e-02],\n",
            "          [-3.0386e-01,  2.8497e-01, -1.9483e-01,  ..., -8.0013e-02,\n",
            "           -8.6599e-02, -7.7786e-02],\n",
            "          [-1.5635e-01,  1.2263e-01, -2.1101e-01,  ...,  3.1756e-02,\n",
            "            6.8959e-02,  1.0459e-02],\n",
            "          ...,\n",
            "          [-3.0731e-01,  2.6094e-01, -4.9881e-02,  ...,  2.2202e-01,\n",
            "           -3.3451e-02,  1.6239e-01],\n",
            "          [-1.4895e-01,  7.4718e-02, -9.0055e-02,  ...,  1.9255e-01,\n",
            "           -5.4050e-02, -3.0517e-02],\n",
            "          [ 1.9611e-02,  7.8413e-02, -2.0259e-02,  ...,  1.2482e-01,\n",
            "           -1.8113e-01, -9.8839e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.0537e-01, -1.3983e-01, -1.2934e-01,  ..., -4.1252e-02,\n",
            "           -1.8931e-01, -4.8301e-02],\n",
            "          [ 2.2599e-01, -9.4459e-02,  1.2306e-01,  ...,  7.5078e-01,\n",
            "            5.6325e-01,  7.4016e-02],\n",
            "          [-9.6398e-02, -3.7338e-01, -9.2943e-02,  ..., -1.8621e-01,\n",
            "           -1.8864e-01, -8.0939e-02],\n",
            "          ...,\n",
            "          [ 6.0714e-02, -2.9885e-01, -1.4037e-03,  ...,  1.0486e-02,\n",
            "            3.3875e-02,  1.6086e-01],\n",
            "          [ 1.2312e-02, -2.6167e-01, -2.2581e-02,  ..., -2.5054e-01,\n",
            "           -1.7045e-01,  1.4541e-01],\n",
            "          [-1.3732e-02,  1.2793e-01,  3.0631e-02,  ..., -3.7545e-02,\n",
            "           -1.4343e-01,  2.7023e-01]],\n",
            "\n",
            "         [[ 1.2505e-01,  1.1648e-03,  1.5614e-01,  ...,  1.1816e-01,\n",
            "           -3.2354e-02,  1.5782e-02],\n",
            "          [ 8.1284e-02, -4.1706e-01,  7.5506e-02,  ..., -3.7707e-01,\n",
            "           -1.1850e-01, -1.0111e-01],\n",
            "          [ 1.4149e-01,  1.1285e-01,  1.6230e-01,  ...,  8.7451e-02,\n",
            "            4.0850e-01, -6.2202e-02],\n",
            "          ...,\n",
            "          [ 3.1540e-01, -4.1489e-01,  7.8960e-02,  ..., -4.3188e-01,\n",
            "            1.5664e-01, -2.1803e-02],\n",
            "          [ 1.4417e-01, -5.7187e-03, -5.9008e-02,  ..., -8.9326e-02,\n",
            "            2.0901e-01,  1.8524e-01],\n",
            "          [ 6.3186e-02, -1.8051e-01,  1.7614e-01,  ..., -2.3006e-01,\n",
            "            1.7531e-01, -7.6186e-02]],\n",
            "\n",
            "         [[-1.8417e-01, -1.4819e-01, -2.9214e-02,  ..., -1.5474e-01,\n",
            "           -1.2901e-01,  7.5285e-02],\n",
            "          [-1.7778e-01,  4.9256e-01, -4.8172e-02,  ...,  5.1364e-01,\n",
            "            2.0765e-01, -2.1281e-01],\n",
            "          [-5.7312e-02,  3.8983e-03,  2.7722e-02,  ...,  1.7233e-01,\n",
            "           -1.0015e-01,  2.3540e-01],\n",
            "          ...,\n",
            "          [-1.5542e-01,  2.2365e-01, -2.3183e-01,  ...,  2.8031e-01,\n",
            "           -2.5296e-01, -5.7708e-02],\n",
            "          [ 4.4328e-02, -9.2514e-02, -1.1097e-01,  ..., -5.8645e-02,\n",
            "            9.4898e-02,  1.5376e-01],\n",
            "          [ 1.6521e-01,  3.7459e-01, -7.7385e-03,  ...,  3.2698e-01,\n",
            "           -1.4398e-01,  1.2007e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5566e-01, -1.2884e-01, -1.2605e-01,  ...,  4.3601e-02,\n",
            "           -4.5457e-02,  4.4823e-02],\n",
            "          [ 1.2652e-01, -4.6689e-01,  1.6903e-01,  ..., -8.7090e-01,\n",
            "            2.0001e-01, -2.2035e-01],\n",
            "          [-2.0565e-01,  1.0919e-02, -1.8269e-01,  ...,  1.0671e-01,\n",
            "           -2.8716e-01,  4.0179e-01],\n",
            "          ...,\n",
            "          [ 3.0942e-01, -2.9275e-01, -2.5604e-02,  ..., -9.4743e-02,\n",
            "           -1.2758e-02, -2.3852e-01],\n",
            "          [-1.8869e-01, -1.6120e-01,  1.6204e-01,  ..., -7.8441e-03,\n",
            "           -1.3260e-01,  1.8585e-01],\n",
            "          [ 2.9106e-01, -2.0012e-01,  1.1888e-01,  ..., -4.2502e-01,\n",
            "            5.5265e-02, -7.3887e-02]],\n",
            "\n",
            "         [[ 8.5127e-02,  1.4911e-01,  9.4772e-02,  ...,  9.5454e-03,\n",
            "            2.3401e-01, -2.7167e-01],\n",
            "          [-6.4607e-02,  2.7745e-01, -1.2330e-01,  ...,  7.2610e-01,\n",
            "           -3.0468e-01,  4.6756e-01],\n",
            "          [ 1.8307e-01,  2.0627e-01,  8.4671e-02,  ..., -2.2093e-01,\n",
            "            6.7294e-01, -2.4355e-01],\n",
            "          ...,\n",
            "          [-1.3578e-01,  3.1811e-01,  5.0713e-02,  ...,  1.1618e-01,\n",
            "           -2.3792e-01,  1.5121e-01],\n",
            "          [-9.2943e-02,  1.8401e-02,  2.1400e-01,  ...,  2.3672e-01,\n",
            "            5.7124e-02, -5.1870e-02],\n",
            "          [-1.4845e-01, -1.6297e-02, -6.3090e-02,  ..., -2.8662e-01,\n",
            "           -9.2012e-02, -7.3901e-02]],\n",
            "\n",
            "         [[-1.1773e-01,  2.8117e-01,  2.0840e-03,  ...,  2.7390e-01,\n",
            "           -2.2516e-02, -2.0356e-02],\n",
            "          [-3.5273e-01, -6.1211e-02, -1.1652e-01,  ...,  2.9909e-02,\n",
            "           -8.3975e-02,  8.6905e-02],\n",
            "          [-2.1000e-02,  1.1517e-01, -7.9601e-03,  ...,  3.5462e-01,\n",
            "            1.9367e-01,  1.8061e-01],\n",
            "          ...,\n",
            "          [-3.7152e-01, -8.1923e-02, -1.6869e-01,  ..., -2.4667e-01,\n",
            "           -1.3503e-01, -2.4402e-01],\n",
            "          [-1.5040e-01,  1.6520e-01, -3.0411e-01,  ...,  1.6954e-01,\n",
            "           -2.6511e-01,  2.2045e-01],\n",
            "          [ 8.6384e-02, -6.3821e-03,  2.4169e-02,  ..., -1.3520e-01,\n",
            "           -2.5114e-02, -2.3547e-01]]],\n",
            "\n",
            "\n",
            "        [[[-3.4439e-02, -1.0611e-01, -8.8286e-02,  ...,  1.8017e-02,\n",
            "           -6.2787e-02,  6.8802e-02],\n",
            "          [ 8.5892e-02,  1.6316e-01,  7.6132e-02,  ...,  2.5346e-01,\n",
            "            2.2884e-01,  2.0232e-02],\n",
            "          [-1.8369e-01,  1.0651e-01, -9.3933e-02,  ..., -2.0698e-01,\n",
            "           -1.6682e-01,  7.8376e-03],\n",
            "          ...,\n",
            "          [ 2.4172e-01,  5.2376e-02,  1.4840e-01,  ..., -2.6082e-02,\n",
            "            1.3917e-01,  1.1031e-01],\n",
            "          [ 1.1118e-04, -9.3755e-02, -8.4451e-02,  ..., -2.6443e-01,\n",
            "           -1.5086e-01,  1.7978e-01],\n",
            "          [ 8.1808e-03,  1.6805e-01,  1.1093e-01,  ...,  1.0082e-01,\n",
            "            4.1647e-02,  2.2475e-01]],\n",
            "\n",
            "         [[ 2.6397e-02,  1.1286e-02,  9.2411e-02,  ..., -1.4764e-01,\n",
            "            7.1557e-02,  6.1296e-02],\n",
            "          [-7.2062e-02, -2.4063e-01, -1.2258e-01,  ..., -3.7593e-01,\n",
            "           -4.5886e-02,  4.6908e-02],\n",
            "          [-5.8386e-02, -1.8957e-01,  4.8153e-02,  ...,  2.1235e-01,\n",
            "            2.4986e-02,  5.1754e-02],\n",
            "          ...,\n",
            "          [ 2.8266e-02, -5.5075e-01,  5.9426e-02,  ..., -6.1887e-01,\n",
            "            4.8458e-02, -9.7773e-02],\n",
            "          [ 9.7613e-02, -5.7912e-02, -3.7969e-02,  ..., -1.8957e-02,\n",
            "            7.1687e-02,  1.8693e-03],\n",
            "          [-1.5291e-02, -2.6942e-01,  1.9199e-03,  ..., -3.1170e-01,\n",
            "            4.9743e-02, -6.0572e-02]],\n",
            "\n",
            "         [[-1.5405e-01,  2.1232e-02, -1.6517e-01,  ..., -4.9158e-02,\n",
            "           -6.1345e-02,  7.7527e-03],\n",
            "          [ 1.6339e-01,  7.0780e-01, -8.2130e-02,  ...,  3.8761e-01,\n",
            "            2.6929e-02,  1.2370e-01],\n",
            "          [-1.3550e-01, -2.5428e-02, -8.1543e-02,  ...,  7.5755e-02,\n",
            "           -6.3373e-02,  1.4459e-01],\n",
            "          ...,\n",
            "          [-7.5411e-02,  2.1532e-01,  8.7616e-02,  ...,  2.5948e-01,\n",
            "            2.8338e-02,  6.5327e-02],\n",
            "          [ 4.3200e-02, -9.2712e-02, -5.3967e-02,  ..., -3.4526e-02,\n",
            "            4.2019e-02,  1.0899e-01],\n",
            "          [ 6.3403e-02,  2.9371e-01,  1.0837e-02,  ...,  2.7409e-01,\n",
            "           -1.5152e-02,  1.6312e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8701e-01, -6.7150e-02, -8.7638e-02,  ..., -8.9962e-02,\n",
            "           -6.4452e-03,  7.8562e-02],\n",
            "          [ 2.0015e-01, -3.6571e-01,  1.2753e-01,  ..., -4.5798e-01,\n",
            "            9.9556e-02, -6.0165e-02],\n",
            "          [ 5.1361e-02, -4.0451e-02, -6.8657e-02,  ..., -4.2869e-02,\n",
            "           -2.0458e-01,  2.0559e-01],\n",
            "          ...,\n",
            "          [ 2.0146e-01, -9.7601e-02,  1.4205e-01,  ..., -1.5886e-01,\n",
            "            1.6554e-01, -9.7870e-02],\n",
            "          [-2.2632e-02, -1.9850e-01,  4.2359e-02,  ..., -1.4670e-01,\n",
            "           -7.5557e-02,  2.4405e-02],\n",
            "          [ 2.0264e-01, -1.1562e-01,  9.2777e-02,  ..., -2.3885e-01,\n",
            "            6.0625e-02, -2.8483e-02]],\n",
            "\n",
            "         [[ 7.2567e-02,  1.1637e-01,  2.5067e-01,  ...,  2.5527e-01,\n",
            "            8.9312e-02,  5.7627e-02],\n",
            "          [-9.4338e-02,  1.3250e-01, -4.3156e-02,  ..., -1.7463e-01,\n",
            "           -2.8492e-02,  8.7544e-02],\n",
            "          [ 1.9686e-02,  1.4561e-01,  5.5374e-02,  ...,  1.4047e-01,\n",
            "            1.3913e-01, -2.3017e-02],\n",
            "          ...,\n",
            "          [-1.3221e-01,  2.8669e-02, -2.2626e-02,  ..., -2.6858e-03,\n",
            "           -1.6437e-01, -1.3354e-01],\n",
            "          [ 3.0989e-02,  1.9373e-01, -8.8669e-04,  ...,  2.6746e-01,\n",
            "           -3.1544e-02,  6.5621e-02],\n",
            "          [-1.4131e-01, -1.1516e-01, -3.4673e-02,  ..., -2.9488e-01,\n",
            "           -8.1383e-02, -1.7769e-01]],\n",
            "\n",
            "         [[-5.1002e-02,  1.3589e-01,  1.3792e-01,  ...,  8.6416e-02,\n",
            "            6.9074e-02,  6.1588e-02],\n",
            "          [-1.1911e-02, -2.4584e-01, -2.2896e-01,  ..., -2.2878e-01,\n",
            "           -2.1639e-02, -8.2393e-02],\n",
            "          [-5.3687e-02,  2.3611e-01, -5.3835e-02,  ...,  1.6473e-01,\n",
            "            4.6964e-02, -3.2532e-02],\n",
            "          ...,\n",
            "          [-2.4725e-01, -1.6809e-01, -1.2652e-01,  ..., -3.0420e-01,\n",
            "           -2.4985e-02, -2.3183e-01],\n",
            "          [-4.0947e-02,  9.0123e-02, -1.2832e-01,  ...,  1.0778e-01,\n",
            "           -1.3371e-01,  9.7963e-02],\n",
            "          [ 7.3107e-02, -1.9781e-01,  2.0666e-02,  ..., -2.2279e-01,\n",
            "            1.4462e-02, -1.6532e-01]]]], device='cuda:0',\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[-2.5449, -2.4755, -2.4944,  ..., -2.4813, -2.4984, -2.4500],\n",
            "          [-2.6166, -2.6734, -2.6976,  ..., -2.4055, -2.4525, -2.4892],\n",
            "          [-2.6545, -2.7568, -2.7442,  ..., -2.3900, -2.4355, -2.4960],\n",
            "          ...,\n",
            "          [-2.4324, -2.3111, -2.2809,  ..., -2.1996, -2.2323, -2.2311],\n",
            "          [-2.4781, -2.3763, -2.3455,  ..., -2.2635, -2.2873, -2.3686],\n",
            "          [-2.5030, -2.4283, -2.3652,  ..., -2.4197, -2.4322, -2.5283]],\n",
            "\n",
            "         [[-2.7500, -2.8424, -2.8247,  ..., -2.5295, -2.4805, -2.5496],\n",
            "          [-2.7998, -2.8139, -2.8048,  ..., -2.4965, -2.4856, -2.4991],\n",
            "          [-2.8725, -2.8814, -2.8831,  ..., -2.5038, -2.5317, -2.4834],\n",
            "          ...,\n",
            "          [-2.5657, -2.6434, -2.6854,  ..., -2.4370, -2.5008, -2.3189],\n",
            "          [-2.5103, -2.5617, -2.5788,  ..., -2.4600, -2.5150, -2.3784],\n",
            "          [-2.7312, -2.5926, -2.5733,  ..., -2.4983, -2.4753, -2.3308]],\n",
            "\n",
            "         [[-2.7234, -2.5209, -2.5483,  ..., -2.8566, -2.7936, -2.5226],\n",
            "          [-2.8526, -2.7828, -2.6860,  ..., -2.9075, -2.9369, -2.6287],\n",
            "          [-2.7724, -2.7139, -2.6736,  ..., -2.8777, -2.9194, -2.6048],\n",
            "          ...,\n",
            "          [-2.6636, -2.6508, -2.5553,  ..., -2.3324, -2.4608, -2.2410],\n",
            "          [-2.6904, -2.7232, -2.6549,  ..., -2.4317, -2.5452, -2.3102],\n",
            "          [-2.9027, -3.1627, -3.1080,  ..., -2.6824, -2.7283, -2.4467]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9173, -2.8111, -2.8837,  ..., -2.8023, -2.7648, -2.9008],\n",
            "          [-3.0625, -3.1006, -3.2272,  ..., -3.1332, -3.0484, -3.2214],\n",
            "          [-3.0457, -3.1263, -3.2506,  ..., -3.1620, -3.1054, -3.2943],\n",
            "          ...,\n",
            "          [-2.6329, -2.6672, -2.7082,  ..., -2.9119, -2.8080, -2.9179],\n",
            "          [-2.5933, -2.5913, -2.6143,  ..., -2.8567, -2.7516, -2.8875],\n",
            "          [-2.5840, -2.5713, -2.5816,  ..., -2.8653, -2.8701, -2.8186]],\n",
            "\n",
            "         [[-2.4264, -2.5391, -2.5819,  ..., -2.4713, -2.5097, -2.3741],\n",
            "          [-2.7658, -2.7481, -2.7760,  ..., -2.8673, -2.8441, -2.5602],\n",
            "          [-2.7437, -2.6553, -2.6667,  ..., -2.8812, -2.8480, -2.6152],\n",
            "          ...,\n",
            "          [-2.8926, -2.8139, -2.8201,  ..., -2.7256, -2.6481, -2.6675],\n",
            "          [-2.9632, -2.8179, -2.7567,  ..., -2.6148, -2.5167, -2.6185],\n",
            "          [-2.7961, -2.6118, -2.6241,  ..., -2.5009, -2.4600, -2.5813]],\n",
            "\n",
            "         [[-2.4962, -2.6952, -2.7439,  ..., -2.6907, -2.6146, -2.6593],\n",
            "          [-2.1603, -2.3368, -2.3480,  ..., -2.5720, -2.6286, -2.5999],\n",
            "          [-2.1460, -2.2336, -2.2540,  ..., -2.5648, -2.6390, -2.5947],\n",
            "          ...,\n",
            "          [-2.4493, -2.3684, -2.4079,  ..., -2.5856, -2.6717, -2.7156],\n",
            "          [-2.4270, -2.3202, -2.3592,  ..., -2.5966, -2.6524, -2.6171],\n",
            "          [-2.4535, -2.5505, -2.5965,  ..., -2.5021, -2.5510, -2.5599]]],\n",
            "\n",
            "\n",
            "        [[[-2.4401, -2.7254, -2.8498,  ..., -2.6867, -2.6059, -2.3166],\n",
            "          [-2.7032, -3.0900, -3.1840,  ..., -2.2917, -2.2492, -2.0800],\n",
            "          [-2.6550, -2.9968, -3.0302,  ..., -2.2487, -2.1921, -1.9868],\n",
            "          ...,\n",
            "          [-2.6118, -2.5111, -2.4832,  ..., -2.9422, -2.9015, -2.6812],\n",
            "          [-2.4987, -2.4217, -2.4505,  ..., -3.0299, -3.0019, -2.6827],\n",
            "          [-2.7561, -2.6588, -2.6924,  ..., -2.9573, -2.9675, -2.7856]],\n",
            "\n",
            "         [[-2.7748, -2.5683, -2.4860,  ..., -2.2727, -2.2909, -2.1116],\n",
            "          [-2.7215, -2.4915, -2.4163,  ..., -2.2911, -2.2844, -2.2028],\n",
            "          [-2.8500, -2.4042, -2.3597,  ..., -2.3031, -2.3339, -2.3755],\n",
            "          ...,\n",
            "          [-2.3873, -2.4195, -2.5068,  ..., -2.7260, -2.7948, -2.6961],\n",
            "          [-2.5389, -2.4673, -2.5475,  ..., -2.7493, -2.7976, -2.6718],\n",
            "          [-2.8324, -2.6856, -2.5510,  ..., -2.6336, -2.6771, -2.6363]],\n",
            "\n",
            "         [[-2.3455, -2.4935, -2.5338,  ..., -2.6501, -2.7095, -2.5691],\n",
            "          [-2.3535, -2.2952, -2.3043,  ..., -3.1438, -3.0558, -2.7812],\n",
            "          [-2.3679, -2.3280, -2.3140,  ..., -3.3216, -3.1768, -2.9477],\n",
            "          ...,\n",
            "          [-2.8950, -2.8071, -2.7178,  ..., -2.3649, -2.4020, -2.3888],\n",
            "          [-2.8036, -2.7932, -2.7293,  ..., -2.2587, -2.2978, -2.4035],\n",
            "          [-2.4692, -2.5969, -2.6064,  ..., -2.5818, -2.5489, -2.5728]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9026, -2.9268, -3.0226,  ..., -2.5806, -2.4943, -2.8553],\n",
            "          [-3.2216, -3.5132, -3.6609,  ..., -2.8508, -2.7928, -2.9306],\n",
            "          [-3.2648, -3.4731, -3.6468,  ..., -2.7125, -2.7391, -2.7582],\n",
            "          ...,\n",
            "          [-2.8546, -2.8452, -2.7447,  ..., -2.3091, -2.4100, -2.5587],\n",
            "          [-2.9797, -2.9904, -2.8884,  ..., -2.3397, -2.4099, -2.5669],\n",
            "          [-2.6986, -2.6456, -2.5971,  ..., -2.2741, -2.3535, -2.3545]],\n",
            "\n",
            "         [[-2.7748, -2.7889, -2.8528,  ..., -2.2539, -2.3313, -2.5826],\n",
            "          [-2.6496, -2.6982, -2.8401,  ..., -2.3634, -2.5236, -2.9457],\n",
            "          [-2.4720, -2.5832, -2.7668,  ..., -2.1919, -2.3999, -2.9058],\n",
            "          ...,\n",
            "          [-2.0487, -2.2359, -2.1817,  ..., -2.2119, -2.1690, -2.4167],\n",
            "          [-1.9410, -2.1427, -2.0470,  ..., -2.1897, -2.1469, -2.4133],\n",
            "          [-1.9225, -2.0428, -2.0475,  ..., -2.0696, -2.0388, -2.3929]],\n",
            "\n",
            "         [[-2.1552, -2.0424, -1.9724,  ..., -2.3852, -2.4261, -2.7014],\n",
            "          [-2.2688, -2.0682, -1.9464,  ..., -2.6139, -2.6189, -2.7570],\n",
            "          [-2.3475, -2.0822, -1.9322,  ..., -2.7324, -2.7549, -2.7874],\n",
            "          ...,\n",
            "          [-2.6815, -2.6759, -2.6395,  ..., -3.1353, -3.1296, -2.8516],\n",
            "          [-2.7483, -2.6505, -2.5479,  ..., -3.0508, -3.0445, -2.7653],\n",
            "          [-2.7457, -2.6738, -2.5831,  ..., -2.9448, -2.9545, -2.7006]]],\n",
            "\n",
            "\n",
            "        [[[-2.3804, -2.2052, -2.3259,  ..., -2.3668, -2.4397, -2.3465],\n",
            "          [-2.2605, -2.2231, -2.2881,  ..., -2.1995, -2.2131, -2.2215],\n",
            "          [-2.2125, -2.2221, -2.2964,  ..., -2.2075, -2.1825, -2.1643],\n",
            "          ...,\n",
            "          [-2.3762, -2.3808, -2.2859,  ..., -2.5587, -2.5315, -2.4489],\n",
            "          [-2.3835, -2.3904, -2.2861,  ..., -2.4893, -2.4837, -2.4474],\n",
            "          [-2.6669, -2.6746, -2.6151,  ..., -2.6520, -2.6467, -2.6134]],\n",
            "\n",
            "         [[-2.5430, -2.6862, -2.6374,  ..., -2.5395, -2.5496, -2.2485],\n",
            "          [-2.6004, -2.8655, -2.8460,  ..., -2.5153, -2.5737, -2.3852],\n",
            "          [-2.6461, -2.8473, -2.8368,  ..., -2.5080, -2.5700, -2.3745],\n",
            "          ...,\n",
            "          [-2.4588, -2.3224, -2.2993,  ..., -2.1927, -2.3733, -2.1778],\n",
            "          [-2.4812, -2.3087, -2.3530,  ..., -2.2719, -2.4036, -2.2373],\n",
            "          [-2.6188, -2.4274, -2.4393,  ..., -2.2997, -2.4029, -2.3208]],\n",
            "\n",
            "         [[-2.6926, -2.6926, -2.7966,  ..., -2.7289, -2.8022, -2.6285],\n",
            "          [-3.0011, -3.0204, -3.0960,  ..., -3.2226, -3.2056, -2.8231],\n",
            "          [-3.0126, -3.1317, -3.1978,  ..., -3.3855, -3.3203, -2.8118],\n",
            "          ...,\n",
            "          [-2.4026, -2.6369, -2.6911,  ..., -2.6351, -2.6783, -2.4453],\n",
            "          [-2.4229, -2.6484, -2.6533,  ..., -2.6092, -2.6739, -2.5110],\n",
            "          [-2.4073, -2.8524, -2.9059,  ..., -2.8244, -2.7819, -2.6380]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5693, -2.7394, -2.7897,  ..., -2.6443, -2.4754, -2.6892],\n",
            "          [-2.7460, -2.9518, -2.8583,  ..., -2.8237, -2.7652, -3.0971],\n",
            "          [-2.7129, -2.8593, -2.7973,  ..., -2.8674, -2.8383, -3.1114],\n",
            "          ...,\n",
            "          [-3.0784, -3.0355, -3.0572,  ..., -3.1105, -2.9576, -2.7592],\n",
            "          [-2.9412, -2.8917, -2.9216,  ..., -2.9910, -2.8333, -2.7068],\n",
            "          [-2.8344, -2.5836, -2.6142,  ..., -2.7937, -2.7449, -2.6953]],\n",
            "\n",
            "         [[-2.3009, -2.2457, -2.3094,  ..., -2.1935, -2.1481, -2.4929],\n",
            "          [-2.3246, -2.2084, -2.2476,  ..., -2.2814, -2.1953, -2.6289],\n",
            "          [-2.2742, -2.1377, -2.1522,  ..., -2.1213, -2.0728, -2.6214],\n",
            "          ...,\n",
            "          [-2.3288, -2.3246, -2.3722,  ..., -2.1601, -2.0585, -2.5534],\n",
            "          [-2.4674, -2.4447, -2.4595,  ..., -2.2594, -2.1536, -2.5831],\n",
            "          [-2.5811, -2.5704, -2.5700,  ..., -2.3207, -2.2303, -2.5065]],\n",
            "\n",
            "         [[-2.6252, -2.8088, -2.7592,  ..., -2.9922, -2.8450, -2.7084],\n",
            "          [-2.6538, -2.7871, -2.7107,  ..., -3.0673, -2.9625, -2.5754],\n",
            "          [-2.7293, -2.7517, -2.6609,  ..., -3.1812, -3.0943, -2.5771],\n",
            "          ...,\n",
            "          [-2.8996, -2.8645, -2.7630,  ..., -2.6329, -2.7936, -2.8252],\n",
            "          [-2.7891, -2.7757, -2.6924,  ..., -2.5556, -2.6788, -2.6772],\n",
            "          [-2.6081, -2.5887, -2.5409,  ..., -2.3804, -2.4641, -2.4903]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.3658, -2.4164, -2.5180,  ..., -2.8501, -2.8584, -2.7106],\n",
            "          [-2.5342, -2.4943, -2.5650,  ..., -2.8719, -2.8527, -2.5621],\n",
            "          [-2.5946, -2.4537, -2.5019,  ..., -2.7205, -2.6615, -2.4632],\n",
            "          ...,\n",
            "          [-2.5218, -2.3850, -2.3147,  ..., -2.3080, -2.2658, -2.1343],\n",
            "          [-2.6483, -2.5898, -2.5679,  ..., -2.3854, -2.3353, -2.2013],\n",
            "          [-2.7809, -2.8886, -2.9348,  ..., -2.8403, -2.8336, -2.5001]],\n",
            "\n",
            "         [[-2.7275, -2.6816, -2.7220,  ..., -2.2533, -2.1959, -2.3202],\n",
            "          [-2.5896, -2.4789, -2.5585,  ..., -2.2286, -2.1850, -2.3971],\n",
            "          [-2.5540, -2.4892, -2.5779,  ..., -2.3518, -2.3354, -2.4327],\n",
            "          ...,\n",
            "          [-2.5072, -2.3058, -2.3696,  ..., -2.5054, -2.5912, -2.5792],\n",
            "          [-2.4457, -2.1916, -2.2386,  ..., -2.4631, -2.5575, -2.5699],\n",
            "          [-2.4806, -2.1725, -2.1135,  ..., -2.2223, -2.2552, -2.4334]],\n",
            "\n",
            "         [[-2.4584, -2.5337, -2.6183,  ..., -2.8715, -2.7910, -2.5148],\n",
            "          [-2.6524, -2.8501, -2.8296,  ..., -3.3234, -3.1386, -2.6878],\n",
            "          [-2.6723, -2.9410, -2.9394,  ..., -3.4429, -3.2827, -2.7595],\n",
            "          ...,\n",
            "          [-2.4524, -2.8256, -2.8282,  ..., -2.7709, -2.7955, -2.5691],\n",
            "          [-2.4595, -2.8006, -2.7877,  ..., -2.7704, -2.7844, -2.6178],\n",
            "          [-2.4472, -2.8034, -2.8344,  ..., -2.9462, -2.9209, -2.7891]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7358, -2.7176, -2.6542,  ..., -2.6884, -2.6112, -2.5784],\n",
            "          [-2.9086, -2.8920, -2.9297,  ..., -2.5388, -2.5619, -2.4958],\n",
            "          [-2.7965, -2.8044, -2.8367,  ..., -2.4901, -2.5131, -2.4293],\n",
            "          ...,\n",
            "          [-2.4532, -2.4996, -2.4137,  ..., -2.2557, -2.3107, -2.3753],\n",
            "          [-2.4091, -2.3955, -2.3326,  ..., -2.2534, -2.2858, -2.4281],\n",
            "          [-2.3096, -2.3158, -2.3149,  ..., -2.1974, -2.2693, -2.4542]],\n",
            "\n",
            "         [[-2.3078, -2.1306, -2.2417,  ..., -2.2437, -2.2889, -2.4814],\n",
            "          [-2.4887, -2.3055, -2.3736,  ..., -2.3784, -2.4014, -2.6818],\n",
            "          [-2.4536, -2.2617, -2.2952,  ..., -2.3225, -2.3140, -2.6017],\n",
            "          ...,\n",
            "          [-2.5524, -2.4021, -2.4654,  ..., -2.3565, -2.2201, -2.4085],\n",
            "          [-2.5288, -2.3816, -2.3912,  ..., -2.3055, -2.1754, -2.3600],\n",
            "          [-2.4851, -2.4786, -2.4577,  ..., -2.4108, -2.3348, -2.4572]],\n",
            "\n",
            "         [[-2.3106, -2.3279, -2.3645,  ..., -2.3980, -2.4391, -2.3650],\n",
            "          [-2.4353, -2.4795, -2.4463,  ..., -2.4522, -2.4330, -2.2296],\n",
            "          [-2.4880, -2.5868, -2.5812,  ..., -2.5872, -2.5953, -2.3666],\n",
            "          ...,\n",
            "          [-2.6596, -2.6223, -2.6370,  ..., -3.1363, -3.1862, -2.9396],\n",
            "          [-2.6551, -2.6295, -2.5902,  ..., -2.9669, -3.0103, -2.7882],\n",
            "          [-2.6104, -2.6353, -2.6201,  ..., -2.7432, -2.7637, -2.4955]]],\n",
            "\n",
            "\n",
            "        [[[-2.7322, -2.5672, -2.6371,  ..., -2.1942, -2.2386, -2.4001],\n",
            "          [-2.8271, -2.6172, -2.5515,  ..., -2.1323, -2.1863, -2.3215],\n",
            "          [-2.7921, -2.5495, -2.4665,  ..., -2.0672, -2.1140, -2.2071],\n",
            "          ...,\n",
            "          [-2.2620, -2.1295, -2.0164,  ..., -2.3772, -2.4360, -2.4930],\n",
            "          [-2.3626, -2.2473, -2.1501,  ..., -2.4578, -2.4993, -2.5868],\n",
            "          [-2.6141, -2.6059, -2.5564,  ..., -2.6374, -2.6640, -2.6889]],\n",
            "\n",
            "         [[-2.1845, -2.1348, -2.1301,  ..., -2.0679, -2.0895, -2.1912],\n",
            "          [-2.2659, -2.1505, -2.1458,  ..., -2.4612, -2.3310, -2.3027],\n",
            "          [-2.5269, -2.2795, -2.2408,  ..., -2.5564, -2.3942, -2.3063],\n",
            "          ...,\n",
            "          [-2.3415, -2.1900, -2.1892,  ..., -2.1540, -2.1290, -2.2332],\n",
            "          [-2.3886, -2.2457, -2.2596,  ..., -2.1799, -2.1548, -2.2455],\n",
            "          [-2.7761, -2.5950, -2.5658,  ..., -2.4340, -2.3793, -2.3469]],\n",
            "\n",
            "         [[-2.7635, -2.7896, -2.8817,  ..., -3.1601, -3.1037, -2.7305],\n",
            "          [-2.9057, -3.0632, -3.1590,  ..., -3.7321, -3.5914, -2.9600],\n",
            "          [-2.8495, -3.0845, -3.1880,  ..., -3.7843, -3.6630, -3.0897],\n",
            "          ...,\n",
            "          [-3.1152, -3.2755, -3.2884,  ..., -2.8425, -2.8168, -2.5677],\n",
            "          [-2.9906, -3.1643, -3.1818,  ..., -2.8603, -2.8334, -2.5728],\n",
            "          [-2.6949, -3.0181, -3.0391,  ..., -2.8136, -2.7840, -2.6106]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5814, -2.5483, -2.4968,  ..., -2.7712, -2.7079, -2.7649],\n",
            "          [-2.5723, -2.6162, -2.5525,  ..., -2.7363, -2.7369, -2.8049],\n",
            "          [-2.6740, -2.6735, -2.6376,  ..., -2.7044, -2.7237, -2.6833],\n",
            "          ...,\n",
            "          [-2.7209, -2.5056, -2.5197,  ..., -2.5812, -2.5967, -2.5360],\n",
            "          [-2.6754, -2.4742, -2.5263,  ..., -2.5593, -2.5473, -2.5195],\n",
            "          [-2.5308, -2.3018, -2.2675,  ..., -2.3600, -2.4033, -2.4413]],\n",
            "\n",
            "         [[-2.2527, -2.3069, -2.3976,  ..., -2.2900, -2.3646, -2.4742],\n",
            "          [-2.3751, -2.3522, -2.4212,  ..., -2.2463, -2.3088, -2.4095],\n",
            "          [-2.2999, -2.2370, -2.3486,  ..., -2.2366, -2.3489, -2.4648],\n",
            "          ...,\n",
            "          [-2.3648, -2.3968, -2.4449,  ..., -2.4133, -2.4511, -2.7046],\n",
            "          [-2.3335, -2.3491, -2.3543,  ..., -2.3841, -2.4328, -2.6687],\n",
            "          [-2.3918, -2.2238, -2.2775,  ..., -2.3939, -2.3871, -2.5933]],\n",
            "\n",
            "         [[-2.6114, -2.7412, -2.6241,  ..., -2.4833, -2.4774, -2.5501],\n",
            "          [-2.7642, -2.7625, -2.6448,  ..., -2.5156, -2.5155, -2.4278],\n",
            "          [-2.9055, -2.8821, -2.7581,  ..., -2.5455, -2.5501, -2.5291],\n",
            "          ...,\n",
            "          [-2.9166, -3.1594, -3.1968,  ..., -2.8965, -2.9194, -2.8206],\n",
            "          [-2.7858, -3.0307, -3.0392,  ..., -2.8301, -2.8530, -2.6878],\n",
            "          [-2.7025, -2.8030, -2.8316,  ..., -2.7206, -2.7009, -2.5578]]],\n",
            "\n",
            "\n",
            "        [[[-2.3781, -2.3057, -2.3795,  ..., -2.5491, -2.4765, -2.5352],\n",
            "          [-2.7153, -2.7715, -2.7348,  ..., -2.5760, -2.4569, -2.5780],\n",
            "          [-2.7542, -2.8027, -2.7576,  ..., -2.5396, -2.3931, -2.4888],\n",
            "          ...,\n",
            "          [-2.6846, -2.6715, -2.5630,  ..., -2.4683, -2.3928, -2.3465],\n",
            "          [-2.7282, -2.6687, -2.5270,  ..., -2.4862, -2.4185, -2.3767],\n",
            "          [-2.7743, -2.6618, -2.5934,  ..., -2.6049, -2.5702, -2.6193]],\n",
            "\n",
            "         [[-2.2300, -2.3408, -2.4021,  ..., -2.6435, -2.7118, -2.8236],\n",
            "          [-2.0822, -2.0772, -2.1926,  ..., -2.3512, -2.4539, -2.4967],\n",
            "          [-2.1728, -2.0927, -2.2354,  ..., -2.3931, -2.5041, -2.4431],\n",
            "          ...,\n",
            "          [-2.1714, -2.2743, -2.4475,  ..., -2.4157, -2.4669, -2.4963],\n",
            "          [-2.1133, -2.1639, -2.3718,  ..., -2.4967, -2.5422, -2.5296],\n",
            "          [-2.2744, -2.2892, -2.2830,  ..., -2.2358, -2.2851, -2.2788]],\n",
            "\n",
            "         [[-2.9496, -2.9020, -2.9276,  ..., -2.8657, -2.7713, -2.5244],\n",
            "          [-2.9687, -3.1213, -3.0633,  ..., -3.0522, -2.9429, -2.6105],\n",
            "          [-2.9064, -3.1091, -3.0143,  ..., -3.0792, -2.9848, -2.7100],\n",
            "          ...,\n",
            "          [-2.9669, -2.9874, -2.9100,  ..., -2.6410, -2.5561, -2.3497],\n",
            "          [-2.8978, -2.9495, -2.8298,  ..., -2.5592, -2.5166, -2.4167],\n",
            "          [-2.6126, -2.7801, -2.7914,  ..., -2.7024, -2.6722, -2.5941]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7519, -2.8244, -2.7556,  ..., -2.5349, -2.5349, -2.7136],\n",
            "          [-2.8623, -2.8350, -2.6884,  ..., -2.6534, -2.6624, -2.9030],\n",
            "          [-2.8806, -2.9126, -2.7548,  ..., -2.7352, -2.7711, -2.9209],\n",
            "          ...,\n",
            "          [-3.0072, -2.7942, -2.6948,  ..., -2.7807, -2.8173, -2.7924],\n",
            "          [-2.8748, -2.7269, -2.7210,  ..., -2.7958, -2.8207, -2.8280],\n",
            "          [-2.7174, -2.6331, -2.5768,  ..., -2.7069, -2.7227, -2.8003]],\n",
            "\n",
            "         [[-2.2458, -2.1360, -2.1912,  ..., -2.0646, -2.1029, -2.0516],\n",
            "          [-2.5252, -2.4086, -2.4417,  ..., -2.2302, -2.2358, -2.3915],\n",
            "          [-2.5283, -2.3800, -2.4071,  ..., -2.1964, -2.2228, -2.4539],\n",
            "          ...,\n",
            "          [-2.2588, -2.2348, -2.1940,  ..., -2.2550, -2.2817, -2.4661],\n",
            "          [-2.3177, -2.3630, -2.2899,  ..., -2.3063, -2.3155, -2.4471],\n",
            "          [-2.4271, -2.4134, -2.4099,  ..., -2.4032, -2.4053, -2.5226]],\n",
            "\n",
            "         [[-2.5425, -2.7243, -2.6476,  ..., -2.3863, -2.3384, -2.3520],\n",
            "          [-2.3756, -2.5098, -2.4069,  ..., -2.5947, -2.5657, -2.4020],\n",
            "          [-2.3652, -2.4575, -2.3129,  ..., -2.5537, -2.5352, -2.3322],\n",
            "          ...,\n",
            "          [-2.7109, -2.7362, -2.6991,  ..., -2.7043, -2.7192, -2.5329],\n",
            "          [-2.6680, -2.6998, -2.6584,  ..., -2.7236, -2.7044, -2.4819],\n",
            "          [-2.5052, -2.5214, -2.5566,  ..., -2.4929, -2.4881, -2.3182]]]],\n",
            "       device='cuda:0')\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 333, in <module>\n",
            "    model = train(train_loader, val_loader, w_class, class_encoding)\n",
            "  File \"main.py\", line 219, in train\n",
            "    epoch_loss, (iou, miou) = train.run_epoch(args.print_step)\n",
            "  File \"/content/drive/MyDrive/Enet/train.py\", line 61, in run_epoch\n",
            "    print(outputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 305, in __repr__\n",
            "    return torch._tensor_str._str(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor_str.py\", line 434, in _str\n",
            "    return _str_intern(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor_str.py\", line 409, in _str_intern\n",
            "    tensor_str = _tensor_str(self, indent)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor_str.py\", line 264, in _tensor_str\n",
            "    formatter = _Formatter(get_summarized_data(self) if summarize else self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor_str.py\", line 100, in __init__\n",
            "    nonzero_finite_vals = torch.masked_select(tensor_view, torch.isfinite(tensor_view) & tensor_view.ne(0))\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    }
  ]
}