{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemanticSegmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Segmentation"
      ],
      "metadata": {
        "id": "7i-6SZAXHEiM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements"
      ],
      "metadata": {
        "id": "J5hdyjORHIzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leC5WqbykBZI",
        "outputId": "35c41b9d-d035-42c1-ff69-c048e5911164"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/Enet/\n",
        "!ls\n",
        "\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8emTfBE-WhL9",
        "outputId": "40b492d8-fac5-4b31-95b3-751d4694f0de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1yc9lWfIDJcLuTNpU5RLZGjPFlwAtqoby/Enet\n",
            "1.jpeg\t Dockerfile\t  metric\t   requirements_dev.txt  transforms.py\n",
            "2.jpeg\t LICENSE\t  models\t   requirements.txt\t utils.py\n",
            "args.py  lr_scheduler.py  ohem_ce_loss.py  save\n",
            "CamVid2  main.py\t  __pycache__\t   test.py\n",
            "data\t meters.py\t  README.md\t   train.py\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.21.6)\n",
            "Requirement already satisfied: Pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (2022.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.15.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->-r requirements.txt (line 2)) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.2.2->-r requirements.txt (line 11)) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->-r requirements.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->-r requirements.txt (line 11)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->-r requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->-r requirements.txt (line 11)) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# E net with 300 epoches"
      ],
      "metadata": {
        "id": "RrAlVbzOHK_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py -m train --save-dir save/ENet_CamVid/ --dataset camvid --dataset-dir ../CamVid2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiAhRS4Obg1_",
        "outputId": "9947eb5a-fd7e-4555-c877-79362cf53ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: ../CamVid2/\n",
            "Save directory: save/ENet_CamVid/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 360, 480])\n",
            "Label size: torch.Size([10, 360, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0217,  3.4469, 15.9119,  9.0202, 32.0138, 32.4789,\n",
            "        13.2071, 38.3877, 44.1345,  0.0000], device='cuda:0')\n",
            "\n",
            "Training...\n",
            "\n",
            "ENet(\n",
            "  (initial_block): InitialBlock(\n",
            "    (main_branch): Conv2d(3, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (ext_branch): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (downsample1_0): DownsamplingBottleneck(\n",
            "    (main_max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(16, 4, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (downsample2_0): DownsamplingBottleneck(\n",
            "    (main_max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular2_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric2_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular2_5): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_6): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric2_7): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_8): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular3_0): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric3_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular3_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_5): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric3_6): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_7): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (upsample4_0): UpsamplingBottleneck(\n",
            "    (main_conv1): Sequential(\n",
            "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (main_unpool1): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_tconv1): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "    (ext_tconv1_bnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (ext_tconv1_activation): ReLU()\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular4_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular4_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (upsample5_0): UpsamplingBottleneck(\n",
            "    (main_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (main_unpool1): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_tconv1): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "    (ext_tconv1_bnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (ext_tconv1_activation): ReLU()\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular5_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (transposed_conv): ConvTranspose2d(16, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            ")\n",
            "\n",
            ">>>> [Epoch: 0] Training\n",
            ">>>> [Epoch: 0] Avg. loss: 2.3403 | Mean IoU: 0.0681\n",
            ">>>> [Epoch: 1] Training\n",
            ">>>> [Epoch: 1] Avg. loss: 1.9978 | Mean IoU: 0.1453\n",
            ">>>> [Epoch: 2] Training\n",
            ">>>> [Epoch: 2] Avg. loss: 1.6976 | Mean IoU: 0.2308\n",
            ">>>> [Epoch: 3] Training\n",
            ">>>> [Epoch: 3] Avg. loss: 1.4954 | Mean IoU: 0.2831\n",
            ">>>> [Epoch: 4] Training\n",
            ">>>> [Epoch: 4] Avg. loss: 1.3579 | Mean IoU: 0.3102\n",
            ">>>> [Epoch: 5] Training\n",
            ">>>> [Epoch: 5] Avg. loss: 1.2677 | Mean IoU: 0.3251\n",
            ">>>> [Epoch: 6] Training\n",
            ">>>> [Epoch: 6] Avg. loss: 1.2130 | Mean IoU: 0.3330\n",
            ">>>> [Epoch: 7] Training\n",
            ">>>> [Epoch: 7] Avg. loss: 1.1206 | Mean IoU: 0.3491\n",
            ">>>> [Epoch: 8] Training\n",
            ">>>> [Epoch: 8] Avg. loss: 1.0585 | Mean IoU: 0.3645\n",
            ">>>> [Epoch: 9] Training\n",
            ">>>> [Epoch: 9] Avg. loss: 1.0086 | Mean IoU: 0.3762\n",
            ">>>> [Epoch: 9] Validation\n",
            ">>>> [Epoch: 9] Avg. loss: 1.1697 | Mean IoU: 0.4079\n",
            "sky: 0.9259\n",
            "building: 0.7295\n",
            "pole: 0.0026\n",
            "road: 0.9054\n",
            "pavement: 0.6537\n",
            "tree: 0.8221\n",
            "sign_symbol: 0.0023\n",
            "fence: 0.1932\n",
            "car: 0.2450\n",
            "pedestrian: 0.0072\n",
            "bicyclist: 0.0000\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 10] Training\n",
            ">>>> [Epoch: 10] Avg. loss: 0.9612 | Mean IoU: 0.3889\n",
            ">>>> [Epoch: 11] Training\n",
            ">>>> [Epoch: 11] Avg. loss: 0.9291 | Mean IoU: 0.3996\n",
            ">>>> [Epoch: 12] Training\n",
            ">>>> [Epoch: 12] Avg. loss: 0.9014 | Mean IoU: 0.4060\n",
            ">>>> [Epoch: 13] Training\n",
            ">>>> [Epoch: 13] Avg. loss: 0.8638 | Mean IoU: 0.4172\n",
            ">>>> [Epoch: 14] Training\n",
            ">>>> [Epoch: 14] Avg. loss: 0.8295 | Mean IoU: 0.4283\n",
            ">>>> [Epoch: 15] Training\n",
            ">>>> [Epoch: 15] Avg. loss: 0.7930 | Mean IoU: 0.4415\n",
            ">>>> [Epoch: 16] Training\n",
            ">>>> [Epoch: 16] Avg. loss: 0.7727 | Mean IoU: 0.4444\n",
            ">>>> [Epoch: 17] Training\n",
            ">>>> [Epoch: 17] Avg. loss: 0.7507 | Mean IoU: 0.4513\n",
            ">>>> [Epoch: 18] Training\n",
            ">>>> [Epoch: 18] Avg. loss: 0.7321 | Mean IoU: 0.4577\n",
            ">>>> [Epoch: 19] Training\n",
            ">>>> [Epoch: 19] Avg. loss: 0.7031 | Mean IoU: 0.4711\n",
            ">>>> [Epoch: 19] Validation\n",
            ">>>> [Epoch: 19] Avg. loss: 0.7600 | Mean IoU: 0.4732\n",
            "sky: 0.9349\n",
            "building: 0.7226\n",
            "pole: 0.0004\n",
            "road: 0.9345\n",
            "pavement: 0.7635\n",
            "tree: 0.8785\n",
            "sign_symbol: 0.0729\n",
            "fence: 0.2789\n",
            "car: 0.5655\n",
            "pedestrian: 0.0533\n",
            "bicyclist: 0.0002\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 20] Training\n",
            ">>>> [Epoch: 20] Avg. loss: 0.6926 | Mean IoU: 0.4709\n",
            ">>>> [Epoch: 21] Training\n",
            ">>>> [Epoch: 21] Avg. loss: 0.6771 | Mean IoU: 0.4782\n",
            ">>>> [Epoch: 22] Training\n",
            ">>>> [Epoch: 22] Avg. loss: 0.6690 | Mean IoU: 0.4819\n",
            ">>>> [Epoch: 23] Training\n",
            ">>>> [Epoch: 23] Avg. loss: 0.6466 | Mean IoU: 0.4961\n",
            ">>>> [Epoch: 24] Training\n",
            ">>>> [Epoch: 24] Avg. loss: 0.6173 | Mean IoU: 0.5075\n",
            ">>>> [Epoch: 25] Training\n",
            ">>>> [Epoch: 25] Avg. loss: 0.6192 | Mean IoU: 0.5062\n",
            ">>>> [Epoch: 26] Training\n",
            ">>>> [Epoch: 26] Avg. loss: 0.5875 | Mean IoU: 0.5240\n",
            ">>>> [Epoch: 27] Training\n",
            ">>>> [Epoch: 27] Avg. loss: 0.5804 | Mean IoU: 0.5264\n",
            ">>>> [Epoch: 28] Training\n",
            ">>>> [Epoch: 28] Avg. loss: 0.5675 | Mean IoU: 0.5347\n",
            ">>>> [Epoch: 29] Training\n",
            ">>>> [Epoch: 29] Avg. loss: 0.5414 | Mean IoU: 0.5457\n",
            ">>>> [Epoch: 29] Validation\n",
            ">>>> [Epoch: 29] Avg. loss: 0.6426 | Mean IoU: 0.5316\n",
            "sky: 0.9245\n",
            "building: 0.7566\n",
            "pole: 0.0358\n",
            "road: 0.9459\n",
            "pavement: 0.7334\n",
            "tree: 0.8746\n",
            "sign_symbol: 0.2082\n",
            "fence: 0.5358\n",
            "car: 0.6899\n",
            "pedestrian: 0.1309\n",
            "bicyclist: 0.0120\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 30] Training\n",
            ">>>> [Epoch: 30] Avg. loss: 0.5360 | Mean IoU: 0.5498\n",
            ">>>> [Epoch: 31] Training\n",
            ">>>> [Epoch: 31] Avg. loss: 0.5315 | Mean IoU: 0.5497\n",
            ">>>> [Epoch: 32] Training\n",
            ">>>> [Epoch: 32] Avg. loss: 0.5125 | Mean IoU: 0.5582\n",
            ">>>> [Epoch: 33] Training\n",
            ">>>> [Epoch: 33] Avg. loss: 0.5219 | Mean IoU: 0.5546\n",
            ">>>> [Epoch: 34] Training\n",
            ">>>> [Epoch: 34] Avg. loss: 0.5035 | Mean IoU: 0.5614\n",
            ">>>> [Epoch: 35] Training\n",
            ">>>> [Epoch: 35] Avg. loss: 0.4863 | Mean IoU: 0.5717\n",
            ">>>> [Epoch: 36] Training\n",
            ">>>> [Epoch: 36] Avg. loss: 0.4663 | Mean IoU: 0.5812\n",
            ">>>> [Epoch: 37] Training\n",
            ">>>> [Epoch: 37] Avg. loss: 0.4702 | Mean IoU: 0.5796\n",
            ">>>> [Epoch: 38] Training\n",
            ">>>> [Epoch: 38] Avg. loss: 0.4587 | Mean IoU: 0.5814\n",
            ">>>> [Epoch: 39] Training\n",
            ">>>> [Epoch: 39] Avg. loss: 0.4547 | Mean IoU: 0.5887\n",
            ">>>> [Epoch: 39] Validation\n",
            ">>>> [Epoch: 39] Avg. loss: 0.5235 | Mean IoU: 0.5536\n",
            "sky: 0.9275\n",
            "building: 0.7590\n",
            "pole: 0.0454\n",
            "road: 0.9487\n",
            "pavement: 0.7974\n",
            "tree: 0.8840\n",
            "sign_symbol: 0.2368\n",
            "fence: 0.6325\n",
            "car: 0.6713\n",
            "pedestrian: 0.1361\n",
            "bicyclist: 0.0509\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 40] Training\n",
            ">>>> [Epoch: 40] Avg. loss: 0.4458 | Mean IoU: 0.5965\n",
            ">>>> [Epoch: 41] Training\n",
            ">>>> [Epoch: 41] Avg. loss: 0.4314 | Mean IoU: 0.5969\n",
            ">>>> [Epoch: 42] Training\n",
            ">>>> [Epoch: 42] Avg. loss: 0.4207 | Mean IoU: 0.6042\n",
            ">>>> [Epoch: 43] Training\n",
            ">>>> [Epoch: 43] Avg. loss: 0.4181 | Mean IoU: 0.6094\n",
            ">>>> [Epoch: 44] Training\n",
            ">>>> [Epoch: 44] Avg. loss: 0.3979 | Mean IoU: 0.6187\n",
            ">>>> [Epoch: 45] Training\n",
            ">>>> [Epoch: 45] Avg. loss: 0.3934 | Mean IoU: 0.6206\n",
            ">>>> [Epoch: 46] Training\n",
            ">>>> [Epoch: 46] Avg. loss: 0.3922 | Mean IoU: 0.6229\n",
            ">>>> [Epoch: 47] Training\n",
            ">>>> [Epoch: 47] Avg. loss: 0.3837 | Mean IoU: 0.6372\n",
            ">>>> [Epoch: 48] Training\n",
            ">>>> [Epoch: 48] Avg. loss: 0.3827 | Mean IoU: 0.6304\n",
            ">>>> [Epoch: 49] Training\n",
            ">>>> [Epoch: 49] Avg. loss: 0.3731 | Mean IoU: 0.6410\n",
            ">>>> [Epoch: 49] Validation\n",
            ">>>> [Epoch: 49] Avg. loss: 0.4712 | Mean IoU: 0.6211\n",
            "sky: 0.9366\n",
            "building: 0.7919\n",
            "pole: 0.0696\n",
            "road: 0.9525\n",
            "pavement: 0.8141\n",
            "tree: 0.8922\n",
            "sign_symbol: 0.2878\n",
            "fence: 0.6112\n",
            "car: 0.6702\n",
            "pedestrian: 0.2321\n",
            "bicyclist: 0.5739\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 50] Training\n",
            ">>>> [Epoch: 50] Avg. loss: 0.3598 | Mean IoU: 0.6509\n",
            ">>>> [Epoch: 51] Training\n",
            ">>>> [Epoch: 51] Avg. loss: 0.3656 | Mean IoU: 0.6455\n",
            ">>>> [Epoch: 52] Training\n",
            ">>>> [Epoch: 52] Avg. loss: 0.3546 | Mean IoU: 0.6541\n",
            ">>>> [Epoch: 53] Training\n",
            ">>>> [Epoch: 53] Avg. loss: 0.3505 | Mean IoU: 0.6587\n",
            ">>>> [Epoch: 54] Training\n",
            ">>>> [Epoch: 54] Avg. loss: 0.3384 | Mean IoU: 0.6680\n",
            ">>>> [Epoch: 55] Training\n",
            ">>>> [Epoch: 55] Avg. loss: 0.3309 | Mean IoU: 0.6706\n",
            ">>>> [Epoch: 56] Training\n",
            ">>>> [Epoch: 56] Avg. loss: 0.3332 | Mean IoU: 0.6697\n",
            ">>>> [Epoch: 57] Training\n",
            ">>>> [Epoch: 57] Avg. loss: 0.3380 | Mean IoU: 0.6692\n",
            ">>>> [Epoch: 58] Training\n",
            ">>>> [Epoch: 58] Avg. loss: 0.3211 | Mean IoU: 0.6837\n",
            ">>>> [Epoch: 59] Training\n",
            ">>>> [Epoch: 59] Avg. loss: 0.3214 | Mean IoU: 0.6821\n",
            ">>>> [Epoch: 59] Validation\n",
            ">>>> [Epoch: 59] Avg. loss: 0.4674 | Mean IoU: 0.6368\n",
            "sky: 0.9292\n",
            "building: 0.8197\n",
            "pole: 0.0788\n",
            "road: 0.9557\n",
            "pavement: 0.8118\n",
            "tree: 0.8912\n",
            "sign_symbol: 0.2889\n",
            "fence: 0.6088\n",
            "car: 0.7117\n",
            "pedestrian: 0.2882\n",
            "bicyclist: 0.6209\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 60] Training\n",
            ">>>> [Epoch: 60] Avg. loss: 0.3272 | Mean IoU: 0.6780\n",
            ">>>> [Epoch: 61] Training\n",
            ">>>> [Epoch: 61] Avg. loss: 0.3173 | Mean IoU: 0.6838\n",
            ">>>> [Epoch: 62] Training\n",
            ">>>> [Epoch: 62] Avg. loss: 0.3092 | Mean IoU: 0.6951\n",
            ">>>> [Epoch: 63] Training\n",
            ">>>> [Epoch: 63] Avg. loss: 0.3032 | Mean IoU: 0.6961\n",
            ">>>> [Epoch: 64] Training\n",
            ">>>> [Epoch: 64] Avg. loss: 0.2894 | Mean IoU: 0.7037\n",
            ">>>> [Epoch: 65] Training\n",
            ">>>> [Epoch: 65] Avg. loss: 0.2929 | Mean IoU: 0.7055\n",
            ">>>> [Epoch: 66] Training\n",
            ">>>> [Epoch: 66] Avg. loss: 0.2933 | Mean IoU: 0.7024\n",
            ">>>> [Epoch: 67] Training\n",
            ">>>> [Epoch: 67] Avg. loss: 0.2873 | Mean IoU: 0.7043\n",
            ">>>> [Epoch: 68] Training\n",
            ">>>> [Epoch: 68] Avg. loss: 0.2847 | Mean IoU: 0.7117\n",
            ">>>> [Epoch: 69] Training\n",
            ">>>> [Epoch: 69] Avg. loss: 0.2807 | Mean IoU: 0.7139\n",
            ">>>> [Epoch: 69] Validation\n",
            ">>>> [Epoch: 69] Avg. loss: 0.4673 | Mean IoU: 0.6479\n",
            "sky: 0.9253\n",
            "building: 0.8229\n",
            "pole: 0.0902\n",
            "road: 0.9599\n",
            "pavement: 0.8345\n",
            "tree: 0.8818\n",
            "sign_symbol: 0.2987\n",
            "fence: 0.6382\n",
            "car: 0.7305\n",
            "pedestrian: 0.2930\n",
            "bicyclist: 0.6522\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 70] Training\n",
            ">>>> [Epoch: 70] Avg. loss: 0.2757 | Mean IoU: 0.7193\n",
            ">>>> [Epoch: 71] Training\n",
            ">>>> [Epoch: 71] Avg. loss: 0.2734 | Mean IoU: 0.7199\n",
            ">>>> [Epoch: 72] Training\n",
            ">>>> [Epoch: 72] Avg. loss: 0.2676 | Mean IoU: 0.7192\n",
            ">>>> [Epoch: 73] Training\n",
            ">>>> [Epoch: 73] Avg. loss: 0.2679 | Mean IoU: 0.7221\n",
            ">>>> [Epoch: 74] Training\n",
            ">>>> [Epoch: 74] Avg. loss: 0.2707 | Mean IoU: 0.7173\n",
            ">>>> [Epoch: 75] Training\n",
            ">>>> [Epoch: 75] Avg. loss: 0.2604 | Mean IoU: 0.7303\n",
            ">>>> [Epoch: 76] Training\n",
            ">>>> [Epoch: 76] Avg. loss: 0.2625 | Mean IoU: 0.7177\n",
            ">>>> [Epoch: 77] Training\n",
            ">>>> [Epoch: 77] Avg. loss: 0.2598 | Mean IoU: 0.7268\n",
            ">>>> [Epoch: 78] Training\n",
            ">>>> [Epoch: 78] Avg. loss: 0.2617 | Mean IoU: 0.7265\n",
            ">>>> [Epoch: 79] Training\n",
            ">>>> [Epoch: 79] Avg. loss: 0.2641 | Mean IoU: 0.7239\n",
            ">>>> [Epoch: 79] Validation\n",
            ">>>> [Epoch: 79] Avg. loss: 0.4218 | Mean IoU: 0.6449\n",
            ">>>> [Epoch: 80] Training\n",
            ">>>> [Epoch: 80] Avg. loss: 0.2671 | Mean IoU: 0.7198\n",
            ">>>> [Epoch: 81] Training\n",
            ">>>> [Epoch: 81] Avg. loss: 0.2549 | Mean IoU: 0.7302\n",
            ">>>> [Epoch: 82] Training\n",
            ">>>> [Epoch: 82] Avg. loss: 0.2510 | Mean IoU: 0.7342\n",
            ">>>> [Epoch: 83] Training\n",
            ">>>> [Epoch: 83] Avg. loss: 0.2522 | Mean IoU: 0.7328\n",
            ">>>> [Epoch: 84] Training\n",
            ">>>> [Epoch: 84] Avg. loss: 0.2459 | Mean IoU: 0.7366\n",
            ">>>> [Epoch: 85] Training\n",
            ">>>> [Epoch: 85] Avg. loss: 0.2358 | Mean IoU: 0.7440\n",
            ">>>> [Epoch: 86] Training\n",
            ">>>> [Epoch: 86] Avg. loss: 0.2392 | Mean IoU: 0.7401\n",
            ">>>> [Epoch: 87] Training\n",
            ">>>> [Epoch: 87] Avg. loss: 0.2357 | Mean IoU: 0.7436\n",
            ">>>> [Epoch: 88] Training\n",
            ">>>> [Epoch: 88] Avg. loss: 0.2313 | Mean IoU: 0.7468\n",
            ">>>> [Epoch: 89] Training\n",
            ">>>> [Epoch: 89] Avg. loss: 0.2320 | Mean IoU: 0.7466\n",
            ">>>> [Epoch: 89] Validation\n",
            ">>>> [Epoch: 89] Avg. loss: 0.4657 | Mean IoU: 0.6407\n",
            ">>>> [Epoch: 90] Training\n",
            ">>>> [Epoch: 90] Avg. loss: 0.2433 | Mean IoU: 0.7419\n",
            ">>>> [Epoch: 91] Training\n",
            ">>>> [Epoch: 91] Avg. loss: 0.2354 | Mean IoU: 0.7442\n",
            ">>>> [Epoch: 92] Training\n",
            ">>>> [Epoch: 92] Avg. loss: 0.2249 | Mean IoU: 0.7507\n",
            ">>>> [Epoch: 93] Training\n",
            ">>>> [Epoch: 93] Avg. loss: 0.2241 | Mean IoU: 0.7518\n",
            ">>>> [Epoch: 94] Training\n",
            ">>>> [Epoch: 94] Avg. loss: 0.2226 | Mean IoU: 0.7527\n",
            ">>>> [Epoch: 95] Training\n",
            ">>>> [Epoch: 95] Avg. loss: 0.2180 | Mean IoU: 0.7582\n",
            ">>>> [Epoch: 96] Training\n",
            ">>>> [Epoch: 96] Avg. loss: 0.2292 | Mean IoU: 0.7474\n",
            ">>>> [Epoch: 97] Training\n",
            ">>>> [Epoch: 97] Avg. loss: 0.2253 | Mean IoU: 0.7504\n",
            ">>>> [Epoch: 98] Training\n",
            ">>>> [Epoch: 98] Avg. loss: 0.2247 | Mean IoU: 0.7538\n",
            ">>>> [Epoch: 99] Training\n",
            ">>>> [Epoch: 99] Avg. loss: 0.2323 | Mean IoU: 0.7438\n",
            ">>>> [Epoch: 99] Validation\n",
            ">>>> [Epoch: 99] Avg. loss: 0.4608 | Mean IoU: 0.6452\n",
            ">>>> [Epoch: 100] Training\n",
            ">>>> [Epoch: 100] Avg. loss: 0.2160 | Mean IoU: 0.7580\n",
            ">>>> [Epoch: 101] Training\n",
            ">>>> [Epoch: 101] Avg. loss: 0.2031 | Mean IoU: 0.7680\n",
            ">>>> [Epoch: 102] Training\n",
            ">>>> [Epoch: 102] Avg. loss: 0.1981 | Mean IoU: 0.7735\n",
            ">>>> [Epoch: 103] Training\n",
            ">>>> [Epoch: 103] Avg. loss: 0.1992 | Mean IoU: 0.7728\n",
            ">>>> [Epoch: 104] Training\n",
            ">>>> [Epoch: 104] Avg. loss: 0.1975 | Mean IoU: 0.7725\n",
            ">>>> [Epoch: 105] Training\n",
            ">>>> [Epoch: 105] Avg. loss: 0.1988 | Mean IoU: 0.7748\n",
            ">>>> [Epoch: 106] Training\n",
            ">>>> [Epoch: 106] Avg. loss: 0.1943 | Mean IoU: 0.7765\n",
            ">>>> [Epoch: 107] Training\n",
            ">>>> [Epoch: 107] Avg. loss: 0.1946 | Mean IoU: 0.7781\n",
            ">>>> [Epoch: 108] Training\n",
            ">>>> [Epoch: 108] Avg. loss: 0.1934 | Mean IoU: 0.7791\n",
            ">>>> [Epoch: 109] Training\n",
            ">>>> [Epoch: 109] Avg. loss: 0.1917 | Mean IoU: 0.7760\n",
            ">>>> [Epoch: 109] Validation\n",
            ">>>> [Epoch: 109] Avg. loss: 0.4556 | Mean IoU: 0.6631\n",
            "sky: 0.9319\n",
            "building: 0.8429\n",
            "pole: 0.0814\n",
            "road: 0.9642\n",
            "pavement: 0.8485\n",
            "tree: 0.8952\n",
            "sign_symbol: 0.3389\n",
            "fence: 0.6590\n",
            "car: 0.7082\n",
            "pedestrian: 0.3539\n",
            "bicyclist: 0.6704\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 110] Training\n",
            ">>>> [Epoch: 110] Avg. loss: 0.1945 | Mean IoU: 0.7806\n",
            ">>>> [Epoch: 111] Training\n",
            ">>>> [Epoch: 111] Avg. loss: 0.1923 | Mean IoU: 0.7770\n",
            ">>>> [Epoch: 112] Training\n",
            ">>>> [Epoch: 112] Avg. loss: 0.1900 | Mean IoU: 0.7803\n",
            ">>>> [Epoch: 113] Training\n",
            ">>>> [Epoch: 113] Avg. loss: 0.1914 | Mean IoU: 0.7796\n",
            ">>>> [Epoch: 114] Training\n",
            ">>>> [Epoch: 114] Avg. loss: 0.1880 | Mean IoU: 0.7805\n",
            ">>>> [Epoch: 115] Training\n",
            ">>>> [Epoch: 115] Avg. loss: 0.1885 | Mean IoU: 0.7817\n",
            ">>>> [Epoch: 116] Training\n",
            ">>>> [Epoch: 116] Avg. loss: 0.1901 | Mean IoU: 0.7814\n",
            ">>>> [Epoch: 117] Training\n",
            ">>>> [Epoch: 117] Avg. loss: 0.1905 | Mean IoU: 0.7808\n",
            ">>>> [Epoch: 118] Training\n",
            ">>>> [Epoch: 118] Avg. loss: 0.1885 | Mean IoU: 0.7817\n",
            ">>>> [Epoch: 119] Training\n",
            ">>>> [Epoch: 119] Avg. loss: 0.1900 | Mean IoU: 0.7822\n",
            ">>>> [Epoch: 119] Validation\n",
            ">>>> [Epoch: 119] Avg. loss: 0.4573 | Mean IoU: 0.6666\n",
            "sky: 0.9330\n",
            "building: 0.8474\n",
            "pole: 0.0789\n",
            "road: 0.9640\n",
            "pavement: 0.8495\n",
            "tree: 0.8976\n",
            "sign_symbol: 0.3396\n",
            "fence: 0.6668\n",
            "car: 0.7285\n",
            "pedestrian: 0.3515\n",
            "bicyclist: 0.6759\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 120] Training\n",
            ">>>> [Epoch: 120] Avg. loss: 0.1882 | Mean IoU: 0.7803\n",
            ">>>> [Epoch: 121] Training\n",
            ">>>> [Epoch: 121] Avg. loss: 0.1885 | Mean IoU: 0.7836\n",
            ">>>> [Epoch: 122] Training\n",
            ">>>> [Epoch: 122] Avg. loss: 0.1881 | Mean IoU: 0.7830\n",
            ">>>> [Epoch: 123] Training\n",
            ">>>> [Epoch: 123] Avg. loss: 0.1905 | Mean IoU: 0.7799\n",
            ">>>> [Epoch: 124] Training\n",
            ">>>> [Epoch: 124] Avg. loss: 0.1875 | Mean IoU: 0.7827\n",
            ">>>> [Epoch: 125] Training\n",
            ">>>> [Epoch: 125] Avg. loss: 0.1858 | Mean IoU: 0.7840\n",
            ">>>> [Epoch: 126] Training\n",
            ">>>> [Epoch: 126] Avg. loss: 0.1863 | Mean IoU: 0.7850\n",
            ">>>> [Epoch: 127] Training\n",
            ">>>> [Epoch: 127] Avg. loss: 0.1833 | Mean IoU: 0.7843\n",
            ">>>> [Epoch: 128] Training\n",
            ">>>> [Epoch: 128] Avg. loss: 0.1848 | Mean IoU: 0.7831\n",
            ">>>> [Epoch: 129] Training\n",
            ">>>> [Epoch: 129] Avg. loss: 0.1856 | Mean IoU: 0.7839\n",
            ">>>> [Epoch: 129] Validation\n",
            ">>>> [Epoch: 129] Avg. loss: 0.4361 | Mean IoU: 0.6671\n",
            "sky: 0.9312\n",
            "building: 0.8432\n",
            "pole: 0.0782\n",
            "road: 0.9638\n",
            "pavement: 0.8488\n",
            "tree: 0.8961\n",
            "sign_symbol: 0.3401\n",
            "fence: 0.6626\n",
            "car: 0.7186\n",
            "pedestrian: 0.3580\n",
            "bicyclist: 0.6967\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 130] Training\n",
            ">>>> [Epoch: 130] Avg. loss: 0.1823 | Mean IoU: 0.7864\n",
            ">>>> [Epoch: 131] Training\n",
            ">>>> [Epoch: 131] Avg. loss: 0.1845 | Mean IoU: 0.7844\n",
            ">>>> [Epoch: 132] Training\n",
            ">>>> [Epoch: 132] Avg. loss: 0.1793 | Mean IoU: 0.7880\n",
            ">>>> [Epoch: 133] Training\n",
            ">>>> [Epoch: 133] Avg. loss: 0.1829 | Mean IoU: 0.7877\n",
            ">>>> [Epoch: 134] Training\n",
            ">>>> [Epoch: 134] Avg. loss: 0.1819 | Mean IoU: 0.7872\n",
            ">>>> [Epoch: 135] Training\n",
            ">>>> [Epoch: 135] Avg. loss: 0.1835 | Mean IoU: 0.7844\n",
            ">>>> [Epoch: 136] Training\n",
            ">>>> [Epoch: 136] Avg. loss: 0.1852 | Mean IoU: 0.7867\n",
            ">>>> [Epoch: 137] Training\n",
            ">>>> [Epoch: 137] Avg. loss: 0.1818 | Mean IoU: 0.7865\n",
            ">>>> [Epoch: 138] Training\n",
            ">>>> [Epoch: 138] Avg. loss: 0.1823 | Mean IoU: 0.7870\n",
            ">>>> [Epoch: 139] Training\n",
            ">>>> [Epoch: 139] Avg. loss: 0.1835 | Mean IoU: 0.7814\n",
            ">>>> [Epoch: 139] Validation\n",
            ">>>> [Epoch: 139] Avg. loss: 0.4529 | Mean IoU: 0.6671\n",
            "sky: 0.9329\n",
            "building: 0.8464\n",
            "pole: 0.0755\n",
            "road: 0.9646\n",
            "pavement: 0.8506\n",
            "tree: 0.8956\n",
            "sign_symbol: 0.3398\n",
            "fence: 0.6567\n",
            "car: 0.7148\n",
            "pedestrian: 0.3679\n",
            "bicyclist: 0.6938\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 140] Training\n",
            ">>>> [Epoch: 140] Avg. loss: 0.1799 | Mean IoU: 0.7897\n",
            ">>>> [Epoch: 141] Training\n",
            ">>>> [Epoch: 141] Avg. loss: 0.1815 | Mean IoU: 0.7863\n",
            ">>>> [Epoch: 142] Training\n",
            ">>>> [Epoch: 142] Avg. loss: 0.1814 | Mean IoU: 0.7877\n",
            ">>>> [Epoch: 143] Training\n",
            ">>>> [Epoch: 143] Avg. loss: 0.1815 | Mean IoU: 0.7883\n",
            ">>>> [Epoch: 144] Training\n",
            ">>>> [Epoch: 144] Avg. loss: 0.1796 | Mean IoU: 0.7878\n",
            ">>>> [Epoch: 145] Training\n",
            ">>>> [Epoch: 145] Avg. loss: 0.1780 | Mean IoU: 0.7906\n",
            ">>>> [Epoch: 146] Training\n",
            ">>>> [Epoch: 146] Avg. loss: 0.1800 | Mean IoU: 0.7884\n",
            ">>>> [Epoch: 147] Training\n",
            ">>>> [Epoch: 147] Avg. loss: 0.1810 | Mean IoU: 0.7888\n",
            ">>>> [Epoch: 148] Training\n",
            ">>>> [Epoch: 148] Avg. loss: 0.1819 | Mean IoU: 0.7844\n",
            ">>>> [Epoch: 149] Training\n",
            ">>>> [Epoch: 149] Avg. loss: 0.1826 | Mean IoU: 0.7890\n",
            ">>>> [Epoch: 149] Validation\n",
            ">>>> [Epoch: 149] Avg. loss: 0.4715 | Mean IoU: 0.6666\n",
            ">>>> [Epoch: 150] Training\n",
            ">>>> [Epoch: 150] Avg. loss: 0.1784 | Mean IoU: 0.7884\n",
            ">>>> [Epoch: 151] Training\n",
            ">>>> [Epoch: 151] Avg. loss: 0.1789 | Mean IoU: 0.7901\n",
            ">>>> [Epoch: 152] Training\n",
            ">>>> [Epoch: 152] Avg. loss: 0.1789 | Mean IoU: 0.7913\n",
            ">>>> [Epoch: 153] Training\n",
            ">>>> [Epoch: 153] Avg. loss: 0.1783 | Mean IoU: 0.7897\n",
            ">>>> [Epoch: 154] Training\n",
            ">>>> [Epoch: 154] Avg. loss: 0.1803 | Mean IoU: 0.7865\n",
            ">>>> [Epoch: 155] Training\n",
            ">>>> [Epoch: 155] Avg. loss: 0.1775 | Mean IoU: 0.7892\n",
            ">>>> [Epoch: 156] Training\n",
            ">>>> [Epoch: 156] Avg. loss: 0.1759 | Mean IoU: 0.7925\n",
            ">>>> [Epoch: 157] Training\n",
            ">>>> [Epoch: 157] Avg. loss: 0.1778 | Mean IoU: 0.7899\n",
            ">>>> [Epoch: 158] Training\n",
            ">>>> [Epoch: 158] Avg. loss: 0.1777 | Mean IoU: 0.7896\n",
            ">>>> [Epoch: 159] Training\n",
            ">>>> [Epoch: 159] Avg. loss: 0.1787 | Mean IoU: 0.7900\n",
            ">>>> [Epoch: 159] Validation\n",
            ">>>> [Epoch: 159] Avg. loss: 0.4519 | Mean IoU: 0.6702\n",
            "sky: 0.9341\n",
            "building: 0.8494\n",
            "pole: 0.0784\n",
            "road: 0.9644\n",
            "pavement: 0.8504\n",
            "tree: 0.8979\n",
            "sign_symbol: 0.3435\n",
            "fence: 0.6678\n",
            "car: 0.7130\n",
            "pedestrian: 0.3750\n",
            "bicyclist: 0.6986\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 160] Training\n",
            ">>>> [Epoch: 160] Avg. loss: 0.1766 | Mean IoU: 0.7900\n",
            ">>>> [Epoch: 161] Training\n",
            ">>>> [Epoch: 161] Avg. loss: 0.1764 | Mean IoU: 0.7910\n",
            ">>>> [Epoch: 162] Training\n",
            ">>>> [Epoch: 162] Avg. loss: 0.1760 | Mean IoU: 0.7910\n",
            ">>>> [Epoch: 163] Training\n",
            ">>>> [Epoch: 163] Avg. loss: 0.1759 | Mean IoU: 0.7910\n",
            ">>>> [Epoch: 164] Training\n",
            ">>>> [Epoch: 164] Avg. loss: 0.1763 | Mean IoU: 0.7920\n",
            ">>>> [Epoch: 165] Training\n",
            ">>>> [Epoch: 165] Avg. loss: 0.1768 | Mean IoU: 0.7911\n",
            ">>>> [Epoch: 166] Training\n",
            ">>>> [Epoch: 166] Avg. loss: 0.1761 | Mean IoU: 0.7913\n",
            ">>>> [Epoch: 167] Training\n",
            ">>>> [Epoch: 167] Avg. loss: 0.1752 | Mean IoU: 0.7919\n",
            ">>>> [Epoch: 168] Training\n",
            ">>>> [Epoch: 168] Avg. loss: 0.1760 | Mean IoU: 0.7912\n",
            ">>>> [Epoch: 169] Training\n",
            ">>>> [Epoch: 169] Avg. loss: 0.1739 | Mean IoU: 0.7926\n",
            ">>>> [Epoch: 169] Validation\n",
            ">>>> [Epoch: 169] Avg. loss: 0.4758 | Mean IoU: 0.6659\n",
            ">>>> [Epoch: 170] Training\n",
            ">>>> [Epoch: 170] Avg. loss: 0.1736 | Mean IoU: 0.7940\n",
            ">>>> [Epoch: 171] Training\n",
            ">>>> [Epoch: 171] Avg. loss: 0.1768 | Mean IoU: 0.7912\n",
            ">>>> [Epoch: 172] Training\n",
            ">>>> [Epoch: 172] Avg. loss: 0.1733 | Mean IoU: 0.7937\n",
            ">>>> [Epoch: 173] Training\n",
            ">>>> [Epoch: 173] Avg. loss: 0.1710 | Mean IoU: 0.7958\n",
            ">>>> [Epoch: 174] Training\n",
            ">>>> [Epoch: 174] Avg. loss: 0.1760 | Mean IoU: 0.7927\n",
            ">>>> [Epoch: 175] Training\n",
            ">>>> [Epoch: 175] Avg. loss: 0.1767 | Mean IoU: 0.7917\n",
            ">>>> [Epoch: 176] Training\n",
            ">>>> [Epoch: 176] Avg. loss: 0.1767 | Mean IoU: 0.7912\n",
            ">>>> [Epoch: 177] Training\n",
            ">>>> [Epoch: 177] Avg. loss: 0.1766 | Mean IoU: 0.7890\n",
            ">>>> [Epoch: 178] Training\n",
            ">>>> [Epoch: 178] Avg. loss: 0.1715 | Mean IoU: 0.7943\n",
            ">>>> [Epoch: 179] Training\n",
            ">>>> [Epoch: 179] Avg. loss: 0.1738 | Mean IoU: 0.7938\n",
            ">>>> [Epoch: 179] Validation\n",
            ">>>> [Epoch: 179] Avg. loss: 0.4884 | Mean IoU: 0.6659\n",
            ">>>> [Epoch: 180] Training\n",
            ">>>> [Epoch: 180] Avg. loss: 0.1711 | Mean IoU: 0.7941\n",
            ">>>> [Epoch: 181] Training\n",
            ">>>> [Epoch: 181] Avg. loss: 0.1713 | Mean IoU: 0.7950\n",
            ">>>> [Epoch: 182] Training\n",
            ">>>> [Epoch: 182] Avg. loss: 0.1711 | Mean IoU: 0.7960\n",
            ">>>> [Epoch: 183] Training\n",
            ">>>> [Epoch: 183] Avg. loss: 0.1736 | Mean IoU: 0.7914\n",
            ">>>> [Epoch: 184] Training\n",
            ">>>> [Epoch: 184] Avg. loss: 0.1725 | Mean IoU: 0.7928\n",
            ">>>> [Epoch: 185] Training\n",
            ">>>> [Epoch: 185] Avg. loss: 0.1727 | Mean IoU: 0.7924\n",
            ">>>> [Epoch: 186] Training\n",
            ">>>> [Epoch: 186] Avg. loss: 0.1733 | Mean IoU: 0.7944\n",
            ">>>> [Epoch: 187] Training\n",
            ">>>> [Epoch: 187] Avg. loss: 0.1693 | Mean IoU: 0.7977\n",
            ">>>> [Epoch: 188] Training\n",
            ">>>> [Epoch: 188] Avg. loss: 0.1693 | Mean IoU: 0.7965\n",
            ">>>> [Epoch: 189] Training\n",
            ">>>> [Epoch: 189] Avg. loss: 0.1691 | Mean IoU: 0.7965\n",
            ">>>> [Epoch: 189] Validation\n",
            ">>>> [Epoch: 189] Avg. loss: 0.4876 | Mean IoU: 0.6631\n",
            ">>>> [Epoch: 190] Training\n",
            ">>>> [Epoch: 190] Avg. loss: 0.1695 | Mean IoU: 0.7945\n",
            ">>>> [Epoch: 191] Training\n",
            ">>>> [Epoch: 191] Avg. loss: 0.1686 | Mean IoU: 0.7968\n",
            ">>>> [Epoch: 192] Training\n",
            ">>>> [Epoch: 192] Avg. loss: 0.1719 | Mean IoU: 0.7946\n",
            ">>>> [Epoch: 193] Training\n",
            ">>>> [Epoch: 193] Avg. loss: 0.1701 | Mean IoU: 0.7959\n",
            ">>>> [Epoch: 194] Training\n",
            ">>>> [Epoch: 194] Avg. loss: 0.1715 | Mean IoU: 0.7953\n",
            ">>>> [Epoch: 195] Training\n",
            ">>>> [Epoch: 195] Avg. loss: 0.1677 | Mean IoU: 0.7980\n",
            ">>>> [Epoch: 196] Training\n",
            ">>>> [Epoch: 196] Avg. loss: 0.1701 | Mean IoU: 0.7947\n",
            ">>>> [Epoch: 197] Training\n",
            ">>>> [Epoch: 197] Avg. loss: 0.1664 | Mean IoU: 0.8002\n",
            ">>>> [Epoch: 198] Training\n",
            ">>>> [Epoch: 198] Avg. loss: 0.1692 | Mean IoU: 0.7968\n",
            ">>>> [Epoch: 199] Training\n",
            ">>>> [Epoch: 199] Avg. loss: 0.1701 | Mean IoU: 0.7956\n",
            ">>>> [Epoch: 199] Validation\n",
            ">>>> [Epoch: 199] Avg. loss: 0.4901 | Mean IoU: 0.6670\n",
            ">>>> [Epoch: 200] Training\n",
            ">>>> [Epoch: 200] Avg. loss: 0.1683 | Mean IoU: 0.7967\n",
            ">>>> [Epoch: 201] Training\n",
            ">>>> [Epoch: 201] Avg. loss: 0.1663 | Mean IoU: 0.7990\n",
            ">>>> [Epoch: 202] Training\n",
            ">>>> [Epoch: 202] Avg. loss: 0.1687 | Mean IoU: 0.7985\n",
            ">>>> [Epoch: 203] Training\n",
            ">>>> [Epoch: 203] Avg. loss: 0.1673 | Mean IoU: 0.7979\n",
            ">>>> [Epoch: 204] Training\n",
            ">>>> [Epoch: 204] Avg. loss: 0.1679 | Mean IoU: 0.7976\n",
            ">>>> [Epoch: 205] Training\n",
            ">>>> [Epoch: 205] Avg. loss: 0.1668 | Mean IoU: 0.7987\n",
            ">>>> [Epoch: 206] Training\n",
            ">>>> [Epoch: 206] Avg. loss: 0.1673 | Mean IoU: 0.7981\n",
            ">>>> [Epoch: 207] Training\n",
            ">>>> [Epoch: 207] Avg. loss: 0.1681 | Mean IoU: 0.7989\n",
            ">>>> [Epoch: 208] Training\n",
            ">>>> [Epoch: 208] Avg. loss: 0.1654 | Mean IoU: 0.7994\n",
            ">>>> [Epoch: 209] Training\n",
            ">>>> [Epoch: 209] Avg. loss: 0.1631 | Mean IoU: 0.7999\n",
            ">>>> [Epoch: 209] Validation\n",
            ">>>> [Epoch: 209] Avg. loss: 0.4824 | Mean IoU: 0.6672\n",
            ">>>> [Epoch: 210] Training\n",
            ">>>> [Epoch: 210] Avg. loss: 0.1673 | Mean IoU: 0.7981\n",
            ">>>> [Epoch: 211] Training\n",
            ">>>> [Epoch: 211] Avg. loss: 0.1677 | Mean IoU: 0.7984\n",
            ">>>> [Epoch: 212] Training\n",
            ">>>> [Epoch: 212] Avg. loss: 0.1647 | Mean IoU: 0.7989\n",
            ">>>> [Epoch: 213] Training\n",
            ">>>> [Epoch: 213] Avg. loss: 0.1657 | Mean IoU: 0.7998\n",
            ">>>> [Epoch: 214] Training\n",
            ">>>> [Epoch: 214] Avg. loss: 0.1655 | Mean IoU: 0.7984\n",
            ">>>> [Epoch: 215] Training\n",
            ">>>> [Epoch: 215] Avg. loss: 0.1679 | Mean IoU: 0.7989\n",
            ">>>> [Epoch: 216] Training\n",
            ">>>> [Epoch: 216] Avg. loss: 0.1662 | Mean IoU: 0.7991\n",
            ">>>> [Epoch: 217] Training\n",
            ">>>> [Epoch: 217] Avg. loss: 0.1646 | Mean IoU: 0.7999\n",
            ">>>> [Epoch: 218] Training\n",
            ">>>> [Epoch: 218] Avg. loss: 0.1662 | Mean IoU: 0.7990\n",
            ">>>> [Epoch: 219] Training\n",
            ">>>> [Epoch: 219] Avg. loss: 0.1669 | Mean IoU: 0.8001\n",
            ">>>> [Epoch: 219] Validation\n",
            ">>>> [Epoch: 219] Avg. loss: 0.4844 | Mean IoU: 0.6680\n",
            ">>>> [Epoch: 220] Training\n",
            ">>>> [Epoch: 220] Avg. loss: 0.1668 | Mean IoU: 0.7988\n",
            ">>>> [Epoch: 221] Training\n",
            ">>>> [Epoch: 221] Avg. loss: 0.1679 | Mean IoU: 0.7988\n",
            ">>>> [Epoch: 222] Training\n",
            ">>>> [Epoch: 222] Avg. loss: 0.1674 | Mean IoU: 0.7979\n",
            ">>>> [Epoch: 223] Training\n",
            ">>>> [Epoch: 223] Avg. loss: 0.1642 | Mean IoU: 0.8000\n",
            ">>>> [Epoch: 224] Training\n",
            ">>>> [Epoch: 224] Avg. loss: 0.1668 | Mean IoU: 0.7981\n",
            ">>>> [Epoch: 225] Training\n",
            ">>>> [Epoch: 225] Avg. loss: 0.1643 | Mean IoU: 0.8005\n",
            ">>>> [Epoch: 226] Training\n",
            ">>>> [Epoch: 226] Avg. loss: 0.1648 | Mean IoU: 0.8006\n",
            ">>>> [Epoch: 227] Training\n",
            ">>>> [Epoch: 227] Avg. loss: 0.1663 | Mean IoU: 0.7983\n",
            ">>>> [Epoch: 228] Training\n",
            ">>>> [Epoch: 228] Avg. loss: 0.1654 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 229] Training\n",
            ">>>> [Epoch: 229] Avg. loss: 0.1674 | Mean IoU: 0.7970\n",
            ">>>> [Epoch: 229] Validation\n",
            ">>>> [Epoch: 229] Avg. loss: 0.4852 | Mean IoU: 0.6679\n",
            ">>>> [Epoch: 230] Training\n",
            ">>>> [Epoch: 230] Avg. loss: 0.1664 | Mean IoU: 0.7992\n",
            ">>>> [Epoch: 231] Training\n",
            ">>>> [Epoch: 231] Avg. loss: 0.1656 | Mean IoU: 0.7995\n",
            ">>>> [Epoch: 232] Training\n",
            ">>>> [Epoch: 232] Avg. loss: 0.1640 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 233] Training\n",
            ">>>> [Epoch: 233] Avg. loss: 0.1641 | Mean IoU: 0.8004\n",
            ">>>> [Epoch: 234] Training\n",
            ">>>> [Epoch: 234] Avg. loss: 0.1637 | Mean IoU: 0.8004\n",
            ">>>> [Epoch: 235] Training\n",
            ">>>> [Epoch: 235] Avg. loss: 0.1657 | Mean IoU: 0.7994\n",
            ">>>> [Epoch: 236] Training\n",
            ">>>> [Epoch: 236] Avg. loss: 0.1671 | Mean IoU: 0.7982\n",
            ">>>> [Epoch: 237] Training\n",
            ">>>> [Epoch: 237] Avg. loss: 0.1661 | Mean IoU: 0.7993\n",
            ">>>> [Epoch: 238] Training\n",
            ">>>> [Epoch: 238] Avg. loss: 0.1652 | Mean IoU: 0.7999\n",
            ">>>> [Epoch: 239] Training\n",
            ">>>> [Epoch: 239] Avg. loss: 0.1662 | Mean IoU: 0.7995\n",
            ">>>> [Epoch: 239] Validation\n",
            ">>>> [Epoch: 239] Avg. loss: 0.4925 | Mean IoU: 0.6660\n",
            ">>>> [Epoch: 240] Training\n",
            ">>>> [Epoch: 240] Avg. loss: 0.1643 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 241] Training\n",
            ">>>> [Epoch: 241] Avg. loss: 0.1678 | Mean IoU: 0.7994\n",
            ">>>> [Epoch: 242] Training\n",
            ">>>> [Epoch: 242] Avg. loss: 0.1653 | Mean IoU: 0.7996\n",
            ">>>> [Epoch: 243] Training\n",
            ">>>> [Epoch: 243] Avg. loss: 0.1653 | Mean IoU: 0.7993\n",
            ">>>> [Epoch: 244] Training\n",
            ">>>> [Epoch: 244] Avg. loss: 0.1651 | Mean IoU: 0.8009\n",
            ">>>> [Epoch: 245] Training\n",
            ">>>> [Epoch: 245] Avg. loss: 0.1645 | Mean IoU: 0.8000\n",
            ">>>> [Epoch: 246] Training\n",
            ">>>> [Epoch: 246] Avg. loss: 0.1644 | Mean IoU: 0.8001\n",
            ">>>> [Epoch: 247] Training\n",
            ">>>> [Epoch: 247] Avg. loss: 0.1668 | Mean IoU: 0.7977\n",
            ">>>> [Epoch: 248] Training\n",
            ">>>> [Epoch: 248] Avg. loss: 0.1654 | Mean IoU: 0.7992\n",
            ">>>> [Epoch: 249] Training\n",
            ">>>> [Epoch: 249] Avg. loss: 0.1681 | Mean IoU: 0.7987\n",
            ">>>> [Epoch: 249] Validation\n",
            ">>>> [Epoch: 249] Avg. loss: 0.4888 | Mean IoU: 0.6687\n",
            ">>>> [Epoch: 250] Training\n",
            ">>>> [Epoch: 250] Avg. loss: 0.1639 | Mean IoU: 0.8004\n",
            ">>>> [Epoch: 251] Training\n",
            ">>>> [Epoch: 251] Avg. loss: 0.1689 | Mean IoU: 0.7977\n",
            ">>>> [Epoch: 252] Training\n",
            ">>>> [Epoch: 252] Avg. loss: 0.1646 | Mean IoU: 0.8005\n",
            ">>>> [Epoch: 253] Training\n",
            ">>>> [Epoch: 253] Avg. loss: 0.1636 | Mean IoU: 0.8006\n",
            ">>>> [Epoch: 254] Training\n",
            ">>>> [Epoch: 254] Avg. loss: 0.1670 | Mean IoU: 0.7993\n",
            ">>>> [Epoch: 255] Training\n",
            ">>>> [Epoch: 255] Avg. loss: 0.1666 | Mean IoU: 0.7983\n",
            ">>>> [Epoch: 256] Training\n",
            ">>>> [Epoch: 256] Avg. loss: 0.1652 | Mean IoU: 0.7991\n",
            ">>>> [Epoch: 257] Training\n",
            ">>>> [Epoch: 257] Avg. loss: 0.1678 | Mean IoU: 0.7982\n",
            ">>>> [Epoch: 258] Training\n",
            ">>>> [Epoch: 258] Avg. loss: 0.1644 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 259] Training\n",
            ">>>> [Epoch: 259] Avg. loss: 0.1653 | Mean IoU: 0.7995\n",
            ">>>> [Epoch: 259] Validation\n",
            ">>>> [Epoch: 259] Avg. loss: 0.4866 | Mean IoU: 0.6657\n",
            ">>>> [Epoch: 260] Training\n",
            ">>>> [Epoch: 260] Avg. loss: 0.1666 | Mean IoU: 0.7999\n",
            ">>>> [Epoch: 261] Training\n",
            ">>>> [Epoch: 261] Avg. loss: 0.1671 | Mean IoU: 0.7993\n",
            ">>>> [Epoch: 262] Training\n",
            ">>>> [Epoch: 262] Avg. loss: 0.1660 | Mean IoU: 0.7988\n",
            ">>>> [Epoch: 263] Training\n",
            ">>>> [Epoch: 263] Avg. loss: 0.1656 | Mean IoU: 0.7989\n",
            ">>>> [Epoch: 264] Training\n",
            ">>>> [Epoch: 264] Avg. loss: 0.1651 | Mean IoU: 0.7995\n",
            ">>>> [Epoch: 265] Training\n",
            ">>>> [Epoch: 265] Avg. loss: 0.1641 | Mean IoU: 0.7993\n",
            ">>>> [Epoch: 266] Training\n",
            ">>>> [Epoch: 266] Avg. loss: 0.1660 | Mean IoU: 0.8024\n",
            ">>>> [Epoch: 267] Training\n",
            ">>>> [Epoch: 267] Avg. loss: 0.1627 | Mean IoU: 0.8009\n",
            ">>>> [Epoch: 268] Training\n",
            ">>>> [Epoch: 268] Avg. loss: 0.1649 | Mean IoU: 0.7994\n",
            ">>>> [Epoch: 269] Training\n",
            ">>>> [Epoch: 269] Avg. loss: 0.1644 | Mean IoU: 0.8021\n",
            ">>>> [Epoch: 269] Validation\n",
            ">>>> [Epoch: 269] Avg. loss: 0.4908 | Mean IoU: 0.6670\n",
            ">>>> [Epoch: 270] Training\n",
            ">>>> [Epoch: 270] Avg. loss: 0.1641 | Mean IoU: 0.8016\n",
            ">>>> [Epoch: 271] Training\n",
            ">>>> [Epoch: 271] Avg. loss: 0.1648 | Mean IoU: 0.7987\n",
            ">>>> [Epoch: 272] Training\n",
            ">>>> [Epoch: 272] Avg. loss: 0.1686 | Mean IoU: 0.7976\n",
            ">>>> [Epoch: 273] Training\n",
            ">>>> [Epoch: 273] Avg. loss: 0.1617 | Mean IoU: 0.8019\n",
            ">>>> [Epoch: 274] Training\n",
            ">>>> [Epoch: 274] Avg. loss: 0.1648 | Mean IoU: 0.8020\n",
            ">>>> [Epoch: 275] Training\n",
            ">>>> [Epoch: 275] Avg. loss: 0.1675 | Mean IoU: 0.7978\n",
            ">>>> [Epoch: 276] Training\n",
            ">>>> [Epoch: 276] Avg. loss: 0.1644 | Mean IoU: 0.7999\n",
            ">>>> [Epoch: 277] Training\n",
            ">>>> [Epoch: 277] Avg. loss: 0.1636 | Mean IoU: 0.8006\n",
            ">>>> [Epoch: 278] Training\n",
            ">>>> [Epoch: 278] Avg. loss: 0.1663 | Mean IoU: 0.8007\n",
            ">>>> [Epoch: 279] Training\n",
            ">>>> [Epoch: 279] Avg. loss: 0.1632 | Mean IoU: 0.8016\n",
            ">>>> [Epoch: 279] Validation\n",
            ">>>> [Epoch: 279] Avg. loss: 0.4813 | Mean IoU: 0.6664\n",
            ">>>> [Epoch: 280] Training\n",
            ">>>> [Epoch: 280] Avg. loss: 0.1619 | Mean IoU: 0.8022\n",
            ">>>> [Epoch: 281] Training\n",
            ">>>> [Epoch: 281] Avg. loss: 0.1663 | Mean IoU: 0.7993\n",
            ">>>> [Epoch: 282] Training\n",
            ">>>> [Epoch: 282] Avg. loss: 0.1642 | Mean IoU: 0.8013\n",
            ">>>> [Epoch: 283] Training\n",
            ">>>> [Epoch: 283] Avg. loss: 0.1654 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 284] Training\n",
            ">>>> [Epoch: 284] Avg. loss: 0.1646 | Mean IoU: 0.8005\n",
            ">>>> [Epoch: 285] Training\n",
            ">>>> [Epoch: 285] Avg. loss: 0.1634 | Mean IoU: 0.8018\n",
            ">>>> [Epoch: 286] Training\n",
            ">>>> [Epoch: 286] Avg. loss: 0.1635 | Mean IoU: 0.8006\n",
            ">>>> [Epoch: 287] Training\n",
            ">>>> [Epoch: 287] Avg. loss: 0.1636 | Mean IoU: 0.8030\n",
            ">>>> [Epoch: 288] Training\n",
            ">>>> [Epoch: 288] Avg. loss: 0.1636 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 289] Training\n",
            ">>>> [Epoch: 289] Avg. loss: 0.1655 | Mean IoU: 0.8001\n",
            ">>>> [Epoch: 289] Validation\n",
            ">>>> [Epoch: 289] Avg. loss: 0.4880 | Mean IoU: 0.6663\n",
            ">>>> [Epoch: 290] Training\n",
            ">>>> [Epoch: 290] Avg. loss: 0.1627 | Mean IoU: 0.8012\n",
            ">>>> [Epoch: 291] Training\n",
            ">>>> [Epoch: 291] Avg. loss: 0.1649 | Mean IoU: 0.8016\n",
            ">>>> [Epoch: 292] Training\n",
            ">>>> [Epoch: 292] Avg. loss: 0.1665 | Mean IoU: 0.7979\n",
            ">>>> [Epoch: 293] Training\n",
            ">>>> [Epoch: 293] Avg. loss: 0.1627 | Mean IoU: 0.8009\n",
            ">>>> [Epoch: 294] Training\n",
            ">>>> [Epoch: 294] Avg. loss: 0.1668 | Mean IoU: 0.7996\n",
            ">>>> [Epoch: 295] Training\n",
            ">>>> [Epoch: 295] Avg. loss: 0.1621 | Mean IoU: 0.8017\n",
            ">>>> [Epoch: 296] Training\n",
            ">>>> [Epoch: 296] Avg. loss: 0.1620 | Mean IoU: 0.8020\n",
            ">>>> [Epoch: 297] Training\n",
            ">>>> [Epoch: 297] Avg. loss: 0.1619 | Mean IoU: 0.8026\n",
            ">>>> [Epoch: 298] Training\n",
            ">>>> [Epoch: 298] Avg. loss: 0.1633 | Mean IoU: 0.8031\n",
            ">>>> [Epoch: 299] Training\n",
            ">>>> [Epoch: 299] Avg. loss: 0.1697 | Mean IoU: 0.7952\n",
            ">>>> [Epoch: 299] Validation\n",
            ">>>> [Epoch: 299] Avg. loss: 0.4820 | Mean IoU: 0.6669\n",
            "sky: 0.9326\n",
            "building: 0.8492\n",
            "pole: 0.0750\n",
            "road: 0.9654\n",
            "pavement: 0.8542\n",
            "tree: 0.8965\n",
            "sign_symbol: 0.3345\n",
            "fence: 0.6706\n",
            "car: 0.7146\n",
            "pedestrian: 0.3598\n",
            "bicyclist: 0.6834\n",
            "unlabeled: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -m test --save-dir save/ENet_CamVid/ --dataset camvid --dataset-dir ../CamVid2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-MMm-fYw2g8",
        "outputId": "9b509c51-8c9d-49cf-bd8e-40891a210c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: ../CamVid2/\n",
            "Save directory: save/ENet_CamVid/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 360, 480])\n",
            "Label size: torch.Size([10, 360, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0217,  3.4469, 15.9119,  9.0202, 32.0138, 32.4789,\n",
            "        13.2071, 38.3877, 44.1345,  0.0000], device='cuda:0')\n",
            "ENet(\n",
            "  (initial_block): InitialBlock(\n",
            "    (main_branch): Conv2d(3, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (ext_branch): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (downsample1_0): DownsamplingBottleneck(\n",
            "    (main_max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(16, 4, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (downsample2_0): DownsamplingBottleneck(\n",
            "    (main_max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular2_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric2_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular2_5): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_6): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric2_7): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_8): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular3_0): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric3_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular3_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_5): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric3_6): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_7): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (upsample4_0): UpsamplingBottleneck(\n",
            "    (main_conv1): Sequential(\n",
            "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (main_unpool1): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_tconv1): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "    (ext_tconv1_bnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (ext_tconv1_activation): ReLU()\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular4_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular4_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (upsample5_0): UpsamplingBottleneck(\n",
            "    (main_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (main_unpool1): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_tconv1): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "    (ext_tconv1_bnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (ext_tconv1_activation): ReLU()\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular5_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (transposed_conv): ConvTranspose2d(16, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            ")\n",
            "\n",
            "Testing...\n",
            "\n",
            ">>>> Running test dataset\n",
            ">>>> Avg. loss: 1.0176 | Mean IoU: 0.5277\n",
            "sky: 0.9008\n",
            "building: 0.6868\n",
            "pole: 0.2110\n",
            "road: 0.9205\n",
            "pavement: 0.7441\n",
            "tree: 0.6543\n",
            "sign_symbol: 0.2131\n",
            "fence: 0.1291\n",
            "car: 0.6907\n",
            "pedestrian: 0.2882\n",
            "bicyclist: 0.3662\n",
            "unlabeled: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/Enet/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aSoQxdqgop4",
        "outputId": "8ed885ba-e476-4f6f-fed8-e46af6915b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Enet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PSPNet with resnet 18 backbone"
      ],
      "metadata": {
        "id": "zawaP8iwHTC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py -m train --save-dir save/ --dataset camvid --dataset-dir ../CamVid2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "999c8a17-5258-452b-c2cc-59d533eb69e1",
        "id": "-JPOvfmWgo3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: ../CamVid2/\n",
            "Save directory: save/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 360, 480])\n",
            "Label size: torch.Size([10, 360, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 305, in <module>\n",
            "    loaders, w_class, class_encoding = load_dataset(dataset)\n",
            "  File \"main.py\", line 124, in load_dataset\n",
            "    class_weights = enet_weighing(train_loader, num_classes)\n",
            "  File \"/content/drive/My Drive/Enet/data/utils.py\", line 114, in enet_weighing\n",
            "    for _, label in dataloader:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 530, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1207, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1173, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1011, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\", line 295, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 85, in get_connection\n",
            "    from .connection import Client\n",
            "  File \"<frozen importlib._bootstrap>\", line 416, in parent\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -m test --save-dir save/ENet_CamVid/ --dataset camvid --dataset-dir ../CamVid2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A4LuIVWm8gT",
        "outputId": "fba26c64-d42f-4dd7-f83e-0a886ccaf5b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: ../CamVid2/\n",
            "Save directory: save/ENet_CamVid/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 360, 480])\n",
            "Label size: torch.Size([10, 360, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0217,  3.4469, 15.9119,  9.0202, 32.0138, 32.4789,\n",
            "        13.2071, 38.3877, 44.1345,  0.0000], device='cuda:0')\n",
            "PSPNet(\n",
            "  (feats): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (psp): PSPModule(\n",
            "    (stages): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(2, 2))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(3, 3))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck): Conv2d(2560, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (drop_1): Dropout2d(p=0.3, inplace=False)\n",
            "  (up_1): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (up_2): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (up_3): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (drop_2): Dropout2d(p=0.15, inplace=False)\n",
            "  (final): Sequential(\n",
            "    (0): Conv2d(64, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): LogSoftmax(dim=None)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=256, out_features=12, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "Testing...\n",
            "\n",
            ">>>> Running test dataset\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            ">>>> Avg. loss: 1.1493 | Mean IoU: 0.5488\n",
            "sky: 0.8942\n",
            "building: 0.7516\n",
            "pole: 0.2247\n",
            "road: 0.9107\n",
            "pavement: 0.7199\n",
            "tree: 0.6670\n",
            "sign_symbol: 0.2570\n",
            "fence: 0.1488\n",
            "car: 0.7134\n",
            "pedestrian: 0.3887\n",
            "bicyclist: 0.3606\n",
            "unlabeled: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PSPNet with resnet 101 backbone"
      ],
      "metadata": {
        "id": "_Gp3RcdZHZqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py -m train --save-dir save/ --dataset camvid --dataset-dir CamVid2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoVzcSejHmxz",
        "outputId": "3cec9f1c-5b33-46af-8df1-2a70a3017589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: CamVid2/\n",
            "Save directory: save/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 360, 480])\n",
            "Label size: torch.Size([10, 360, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0217,  3.4469, 15.9119,  9.0202, 32.0138, 32.4789,\n",
            "        13.2071, 38.3877, 44.1345,  0.0000], device='cuda:0')\n",
            "\n",
            "Training...\n",
            "\n",
            "PSPNet(\n",
            "  (feats): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (4): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (5): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (psp): PSPModule(\n",
            "    (stages): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(2, 2))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(3, 3))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck): Conv2d(2560, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (drop_1): Dropout2d(p=0.3, inplace=False)\n",
            "  (up_1): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (up_2): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (up_3): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (drop_2): Dropout2d(p=0.15, inplace=False)\n",
            "  (final): Sequential(\n",
            "    (0): Conv2d(64, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): LogSoftmax(dim=None)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=256, out_features=12, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            ">>>> [Epoch: 0] Training\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            ">>>> [Epoch: 0] Avg. loss: 1.6345 | Mean IoU: 0.2455\n",
            ">>>> [Epoch: 1] Training\n",
            ">>>> [Epoch: 1] Avg. loss: 1.2545 | Mean IoU: 0.3177\n",
            ">>>> [Epoch: 2] Training\n",
            ">>>> [Epoch: 2] Avg. loss: 1.1289 | Mean IoU: 0.3488\n",
            ">>>> [Epoch: 3] Training\n",
            ">>>> [Epoch: 3] Avg. loss: 1.0338 | Mean IoU: 0.3749\n",
            ">>>> [Epoch: 4] Training\n",
            ">>>> [Epoch: 4] Avg. loss: 0.9553 | Mean IoU: 0.3947\n",
            ">>>> [Epoch: 5] Training\n",
            ">>>> [Epoch: 5] Avg. loss: 0.9151 | Mean IoU: 0.4043\n",
            ">>>> [Epoch: 6] Training\n",
            ">>>> [Epoch: 6] Avg. loss: 0.8777 | Mean IoU: 0.4200\n",
            ">>>> [Epoch: 7] Training\n",
            ">>>> [Epoch: 7] Avg. loss: 0.8317 | Mean IoU: 0.4340\n",
            ">>>> [Epoch: 8] Training\n",
            ">>>> [Epoch: 8] Avg. loss: 0.7937 | Mean IoU: 0.4508\n",
            ">>>> [Epoch: 9] Training\n",
            ">>>> [Epoch: 9] Avg. loss: 0.7709 | Mean IoU: 0.4570\n",
            ">>>> [Epoch: 9] Validation\n",
            ">>>> [Epoch: 9] Avg. loss: 0.7015 | Mean IoU: 0.4350\n",
            "sky: 0.2129\n",
            "building: 0.6304\n",
            "pole: 0.0001\n",
            "road: 0.8847\n",
            "pavement: 0.7054\n",
            "tree: 0.7036\n",
            "sign_symbol: 0.2402\n",
            "fence: 0.4576\n",
            "car: 0.4859\n",
            "pedestrian: 0.1008\n",
            "bicyclist: 0.3640\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 10] Training\n",
            ">>>> [Epoch: 10] Avg. loss: 0.7151 | Mean IoU: 0.4791\n",
            ">>>> [Epoch: 11] Training\n",
            ">>>> [Epoch: 11] Avg. loss: 0.6750 | Mean IoU: 0.4916\n",
            ">>>> [Epoch: 12] Training\n",
            ">>>> [Epoch: 12] Avg. loss: 0.6645 | Mean IoU: 0.4964\n",
            ">>>> [Epoch: 13] Training\n",
            ">>>> [Epoch: 13] Avg. loss: 0.6325 | Mean IoU: 0.5126\n",
            ">>>> [Epoch: 14] Training\n",
            ">>>> [Epoch: 14] Avg. loss: 0.6143 | Mean IoU: 0.5140\n",
            ">>>> [Epoch: 15] Training\n",
            ">>>> [Epoch: 15] Avg. loss: 0.5945 | Mean IoU: 0.5321\n",
            ">>>> [Epoch: 16] Training\n",
            ">>>> [Epoch: 16] Avg. loss: 0.5441 | Mean IoU: 0.5517\n",
            ">>>> [Epoch: 17] Training\n",
            ">>>> [Epoch: 17] Avg. loss: 0.5111 | Mean IoU: 0.5710\n",
            ">>>> [Epoch: 18] Training\n",
            ">>>> [Epoch: 18] Avg. loss: 0.5032 | Mean IoU: 0.5724\n",
            ">>>> [Epoch: 19] Training\n",
            ">>>> [Epoch: 19] Avg. loss: 0.4992 | Mean IoU: 0.5751\n",
            ">>>> [Epoch: 19] Validation\n",
            ">>>> [Epoch: 19] Avg. loss: 0.5203 | Mean IoU: 0.5752\n",
            "sky: 0.9200\n",
            "building: 0.7033\n",
            "pole: 0.0581\n",
            "road: 0.9469\n",
            "pavement: 0.7621\n",
            "tree: 0.8385\n",
            "sign_symbol: 0.3138\n",
            "fence: 0.5086\n",
            "car: 0.5821\n",
            "pedestrian: 0.1844\n",
            "bicyclist: 0.5096\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 20] Training\n",
            ">>>> [Epoch: 20] Avg. loss: 0.4651 | Mean IoU: 0.5944\n",
            ">>>> [Epoch: 21] Training\n",
            ">>>> [Epoch: 21] Avg. loss: 0.4644 | Mean IoU: 0.5900\n",
            ">>>> [Epoch: 22] Training\n",
            ">>>> [Epoch: 22] Avg. loss: 0.4514 | Mean IoU: 0.6003\n",
            ">>>> [Epoch: 23] Training\n",
            ">>>> [Epoch: 23] Avg. loss: 0.4119 | Mean IoU: 0.6221\n",
            ">>>> [Epoch: 24] Training\n",
            ">>>> [Epoch: 24] Avg. loss: 0.3828 | Mean IoU: 0.6382\n",
            ">>>> [Epoch: 25] Training\n",
            ">>>> [Epoch: 25] Avg. loss: 0.3562 | Mean IoU: 0.6536\n",
            ">>>> [Epoch: 26] Training\n",
            ">>>> [Epoch: 26] Avg. loss: 0.3581 | Mean IoU: 0.6488\n",
            ">>>> [Epoch: 27] Training\n",
            ">>>> [Epoch: 27] Avg. loss: 0.3551 | Mean IoU: 0.6509\n",
            ">>>> [Epoch: 28] Training\n",
            ">>>> [Epoch: 28] Avg. loss: 0.3620 | Mean IoU: 0.6413\n",
            ">>>> [Epoch: 29] Training\n",
            ">>>> [Epoch: 29] Avg. loss: 0.3540 | Mean IoU: 0.6537\n",
            ">>>> [Epoch: 29] Validation\n",
            ">>>> [Epoch: 29] Avg. loss: 0.6702 | Mean IoU: 0.5834\n",
            "sky: 0.9249\n",
            "building: 0.7454\n",
            "pole: 0.1379\n",
            "road: 0.9595\n",
            "pavement: 0.7923\n",
            "tree: 0.8558\n",
            "sign_symbol: 0.3395\n",
            "fence: 0.2657\n",
            "car: 0.6010\n",
            "pedestrian: 0.2251\n",
            "bicyclist: 0.5699\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 30] Training\n",
            ">>>> [Epoch: 30] Avg. loss: 0.3086 | Mean IoU: 0.6804\n",
            ">>>> [Epoch: 31] Training\n",
            ">>>> [Epoch: 31] Avg. loss: 0.3078 | Mean IoU: 0.6799\n",
            ">>>> [Epoch: 32] Training\n",
            ">>>> [Epoch: 32] Avg. loss: 0.2983 | Mean IoU: 0.6880\n",
            ">>>> [Epoch: 33] Training\n",
            ">>>> [Epoch: 33] Avg. loss: 0.2871 | Mean IoU: 0.6892\n",
            ">>>> [Epoch: 34] Training\n",
            ">>>> [Epoch: 34] Avg. loss: 0.3001 | Mean IoU: 0.6858\n",
            ">>>> [Epoch: 35] Training\n",
            ">>>> [Epoch: 35] Avg. loss: 0.3441 | Mean IoU: 0.6596\n",
            ">>>> [Epoch: 36] Training\n",
            ">>>> [Epoch: 36] Avg. loss: 0.3287 | Mean IoU: 0.6608\n",
            ">>>> [Epoch: 37] Training\n",
            ">>>> [Epoch: 37] Avg. loss: 0.2900 | Mean IoU: 0.6906\n",
            ">>>> [Epoch: 38] Training\n",
            ">>>> [Epoch: 38] Avg. loss: 0.2483 | Mean IoU: 0.7182\n",
            ">>>> [Epoch: 39] Training\n",
            ">>>> [Epoch: 39] Avg. loss: 0.2291 | Mean IoU: 0.7339\n",
            ">>>> [Epoch: 39] Validation\n",
            ">>>> [Epoch: 39] Avg. loss: 0.5900 | Mean IoU: 0.6167\n",
            "sky: 0.9249\n",
            "building: 0.8496\n",
            "pole: 0.0580\n",
            "road: 0.9602\n",
            "pavement: 0.8486\n",
            "tree: 0.8814\n",
            "sign_symbol: 0.2874\n",
            "fence: 0.6156\n",
            "car: 0.7124\n",
            "pedestrian: 0.2340\n",
            "bicyclist: 0.4120\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 40] Training\n",
            ">>>> [Epoch: 40] Avg. loss: 0.2195 | Mean IoU: 0.7424\n",
            ">>>> [Epoch: 41] Training\n",
            ">>>> [Epoch: 41] Avg. loss: 0.2181 | Mean IoU: 0.7439\n",
            ">>>> [Epoch: 42] Training\n",
            ">>>> [Epoch: 42] Avg. loss: 0.2228 | Mean IoU: 0.7342\n",
            ">>>> [Epoch: 43] Training\n",
            ">>>> [Epoch: 43] Avg. loss: 0.2292 | Mean IoU: 0.7329\n",
            ">>>> [Epoch: 44] Training\n",
            ">>>> [Epoch: 44] Avg. loss: 0.2440 | Mean IoU: 0.7186\n",
            ">>>> [Epoch: 45] Training\n",
            ">>>> [Epoch: 45] Avg. loss: 0.2829 | Mean IoU: 0.6916\n",
            ">>>> [Epoch: 46] Training\n",
            ">>>> [Epoch: 46] Avg. loss: 0.3003 | Mean IoU: 0.6811\n",
            ">>>> [Epoch: 47] Training\n",
            ">>>> [Epoch: 47] Avg. loss: 0.2212 | Mean IoU: 0.7370\n",
            ">>>> [Epoch: 48] Training\n",
            ">>>> [Epoch: 48] Avg. loss: 0.2045 | Mean IoU: 0.7513\n",
            ">>>> [Epoch: 49] Training\n",
            ">>>> [Epoch: 49] Avg. loss: 0.1879 | Mean IoU: 0.7652\n",
            ">>>> [Epoch: 49] Validation\n",
            ">>>> [Epoch: 49] Avg. loss: 0.4292 | Mean IoU: 0.6445\n",
            "sky: 0.9276\n",
            "building: 0.8365\n",
            "pole: 0.0565\n",
            "road: 0.9612\n",
            "pavement: 0.8432\n",
            "tree: 0.8862\n",
            "sign_symbol: 0.2856\n",
            "fence: 0.6646\n",
            "car: 0.6222\n",
            "pedestrian: 0.3437\n",
            "bicyclist: 0.6629\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 50] Training\n",
            ">>>> [Epoch: 50] Avg. loss: 0.1870 | Mean IoU: 0.7642\n",
            ">>>> [Epoch: 51] Training\n",
            ">>>> [Epoch: 51] Avg. loss: 0.2459 | Mean IoU: 0.7099\n",
            ">>>> [Epoch: 52] Training\n",
            ">>>> [Epoch: 52] Avg. loss: 0.3287 | Mean IoU: 0.6608\n",
            ">>>> [Epoch: 53] Training\n",
            ">>>> [Epoch: 53] Avg. loss: 0.2993 | Mean IoU: 0.6819\n",
            ">>>> [Epoch: 54] Training\n",
            ">>>> [Epoch: 54] Avg. loss: 0.2443 | Mean IoU: 0.7182\n",
            ">>>> [Epoch: 55] Training\n",
            ">>>> [Epoch: 55] Avg. loss: 0.2205 | Mean IoU: 0.7338\n",
            ">>>> [Epoch: 56] Training\n",
            ">>>> [Epoch: 56] Avg. loss: 0.1947 | Mean IoU: 0.7584\n",
            ">>>> [Epoch: 57] Training\n",
            ">>>> [Epoch: 57] Avg. loss: 0.1728 | Mean IoU: 0.7748\n",
            ">>>> [Epoch: 58] Training\n",
            ">>>> [Epoch: 58] Avg. loss: 0.1664 | Mean IoU: 0.7805\n",
            ">>>> [Epoch: 59] Training\n",
            ">>>> [Epoch: 59] Avg. loss: 0.1652 | Mean IoU: 0.7815\n",
            ">>>> [Epoch: 59] Validation\n",
            ">>>> [Epoch: 59] Avg. loss: 0.4356 | Mean IoU: 0.6465\n",
            "sky: 0.9334\n",
            "building: 0.8094\n",
            "pole: 0.0834\n",
            "road: 0.9601\n",
            "pavement: 0.8318\n",
            "tree: 0.8886\n",
            "sign_symbol: 0.3314\n",
            "fence: 0.6220\n",
            "car: 0.5927\n",
            "pedestrian: 0.4015\n",
            "bicyclist: 0.6569\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 60] Training\n",
            ">>>> [Epoch: 60] Avg. loss: 0.1749 | Mean IoU: 0.7723\n",
            ">>>> [Epoch: 61] Training\n",
            ">>>> [Epoch: 61] Avg. loss: 0.1915 | Mean IoU: 0.7572\n",
            ">>>> [Epoch: 62] Training\n",
            ">>>> [Epoch: 62] Avg. loss: 0.1894 | Mean IoU: 0.7594\n",
            ">>>> [Epoch: 63] Training\n",
            ">>>> [Epoch: 63] Avg. loss: 0.2084 | Mean IoU: 0.7420\n",
            ">>>> [Epoch: 64] Training\n",
            ">>>> [Epoch: 64] Avg. loss: 0.2281 | Mean IoU: 0.7329\n",
            ">>>> [Epoch: 65] Training\n",
            ">>>> [Epoch: 65] Avg. loss: 0.2417 | Mean IoU: 0.7226\n",
            ">>>> [Epoch: 66] Training\n",
            ">>>> [Epoch: 66] Avg. loss: 0.2016 | Mean IoU: 0.7491\n",
            ">>>> [Epoch: 67] Training\n",
            ">>>> [Epoch: 67] Avg. loss: 0.1696 | Mean IoU: 0.7761\n",
            ">>>> [Epoch: 68] Training\n",
            ">>>> [Epoch: 68] Avg. loss: 0.1499 | Mean IoU: 0.7947\n",
            ">>>> [Epoch: 69] Training\n",
            ">>>> [Epoch: 69] Avg. loss: 0.1421 | Mean IoU: 0.8016\n",
            ">>>> [Epoch: 69] Validation\n",
            ">>>> [Epoch: 69] Avg. loss: 0.5031 | Mean IoU: 0.6509\n",
            "sky: 0.9363\n",
            "building: 0.8537\n",
            "pole: 0.0971\n",
            "road: 0.9650\n",
            "pavement: 0.8437\n",
            "tree: 0.9070\n",
            "sign_symbol: 0.2795\n",
            "fence: 0.7109\n",
            "car: 0.6400\n",
            "pedestrian: 0.3329\n",
            "bicyclist: 0.5936\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 70] Training\n",
            ">>>> [Epoch: 70] Avg. loss: 0.1393 | Mean IoU: 0.8056\n",
            ">>>> [Epoch: 71] Training\n",
            ">>>> [Epoch: 71] Avg. loss: 0.1544 | Mean IoU: 0.7930\n",
            ">>>> [Epoch: 72] Training\n",
            ">>>> [Epoch: 72] Avg. loss: 0.1527 | Mean IoU: 0.7904\n",
            ">>>> [Epoch: 73] Training\n",
            ">>>> [Epoch: 73] Avg. loss: 0.1618 | Mean IoU: 0.7850\n",
            ">>>> [Epoch: 74] Training\n",
            ">>>> [Epoch: 74] Avg. loss: 0.1607 | Mean IoU: 0.7840\n",
            ">>>> [Epoch: 75] Training\n",
            ">>>> [Epoch: 75] Avg. loss: 0.1516 | Mean IoU: 0.7934\n",
            ">>>> [Epoch: 76] Training\n",
            ">>>> [Epoch: 76] Avg. loss: 0.1469 | Mean IoU: 0.7986\n",
            ">>>> [Epoch: 77] Training\n",
            ">>>> [Epoch: 77] Avg. loss: 0.1452 | Mean IoU: 0.8001\n",
            ">>>> [Epoch: 78] Training\n",
            ">>>> [Epoch: 78] Avg. loss: 0.1359 | Mean IoU: 0.8054\n",
            ">>>> [Epoch: 79] Training\n",
            ">>>> [Epoch: 79] Avg. loss: 0.1293 | Mean IoU: 0.8130\n",
            ">>>> [Epoch: 79] Validation\n",
            ">>>> [Epoch: 79] Avg. loss: 0.4100 | Mean IoU: 0.6706\n",
            "sky: 0.9306\n",
            "building: 0.8387\n",
            "pole: 0.0937\n",
            "road: 0.9651\n",
            "pavement: 0.8657\n",
            "tree: 0.8890\n",
            "sign_symbol: 0.3108\n",
            "fence: 0.6833\n",
            "car: 0.7093\n",
            "pedestrian: 0.3984\n",
            "bicyclist: 0.6925\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 80] Training\n",
            ">>>> [Epoch: 80] Avg. loss: 0.1266 | Mean IoU: 0.8155\n",
            ">>>> [Epoch: 81] Training\n",
            ">>>> [Epoch: 81] Avg. loss: 0.1236 | Mean IoU: 0.8185\n",
            ">>>> [Epoch: 82] Training\n",
            ">>>> [Epoch: 82] Avg. loss: 0.1224 | Mean IoU: 0.8207\n",
            ">>>> [Epoch: 83] Training\n",
            ">>>> [Epoch: 83] Avg. loss: 0.1412 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 84] Training\n",
            ">>>> [Epoch: 84] Avg. loss: 0.2402 | Mean IoU: 0.7269\n",
            ">>>> [Epoch: 85] Training\n",
            ">>>> [Epoch: 85] Avg. loss: 0.5372 | Mean IoU: 0.5533\n",
            ">>>> [Epoch: 86] Training\n",
            ">>>> [Epoch: 86] Avg. loss: 0.3257 | Mean IoU: 0.6644\n",
            ">>>> [Epoch: 87] Training\n",
            ">>>> [Epoch: 87] Avg. loss: 0.2437 | Mean IoU: 0.7184\n",
            ">>>> [Epoch: 88] Training\n",
            ">>>> [Epoch: 88] Avg. loss: 0.1886 | Mean IoU: 0.7623\n",
            ">>>> [Epoch: 89] Training\n",
            ">>>> [Epoch: 89] Avg. loss: 0.1668 | Mean IoU: 0.7782\n",
            ">>>> [Epoch: 89] Validation\n",
            ">>>> [Epoch: 89] Avg. loss: 0.4507 | Mean IoU: 0.6833\n",
            "sky: 0.9263\n",
            "building: 0.8719\n",
            "pole: 0.1024\n",
            "road: 0.9566\n",
            "pavement: 0.8402\n",
            "tree: 0.8866\n",
            "sign_symbol: 0.2886\n",
            "fence: 0.6883\n",
            "car: 0.7940\n",
            "pedestrian: 0.4531\n",
            "bicyclist: 0.7080\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 90] Training\n",
            ">>>> [Epoch: 90] Avg. loss: 0.1501 | Mean IoU: 0.7964\n",
            ">>>> [Epoch: 91] Training\n",
            ">>>> [Epoch: 91] Avg. loss: 0.1358 | Mean IoU: 0.8070\n",
            ">>>> [Epoch: 92] Training\n",
            ">>>> [Epoch: 92] Avg. loss: 0.1254 | Mean IoU: 0.8177\n",
            ">>>> [Epoch: 93] Training\n",
            ">>>> [Epoch: 93] Avg. loss: 0.1208 | Mean IoU: 0.8214\n",
            ">>>> [Epoch: 94] Training\n",
            ">>>> [Epoch: 94] Avg. loss: 0.1198 | Mean IoU: 0.8231\n",
            ">>>> [Epoch: 95] Training\n",
            ">>>> [Epoch: 95] Avg. loss: 0.1187 | Mean IoU: 0.8248\n",
            ">>>> [Epoch: 96] Training\n",
            ">>>> [Epoch: 96] Avg. loss: 0.1174 | Mean IoU: 0.8254\n",
            ">>>> [Epoch: 97] Training\n",
            ">>>> [Epoch: 97] Avg. loss: 0.1181 | Mean IoU: 0.8250\n",
            ">>>> [Epoch: 98] Training\n",
            ">>>> [Epoch: 98] Avg. loss: 0.1129 | Mean IoU: 0.8288\n",
            ">>>> [Epoch: 99] Training\n",
            ">>>> [Epoch: 99] Avg. loss: 0.1148 | Mean IoU: 0.8281\n",
            ">>>> [Epoch: 99] Validation\n",
            ">>>> [Epoch: 99] Avg. loss: 0.4964 | Mean IoU: 0.6762\n",
            ">>>> [Epoch: 100] Training\n",
            ">>>> [Epoch: 100] Avg. loss: 0.1033 | Mean IoU: 0.8400\n",
            ">>>> [Epoch: 101] Training\n",
            ">>>> [Epoch: 101] Avg. loss: 0.0958 | Mean IoU: 0.8477\n",
            ">>>> [Epoch: 102] Training\n",
            ">>>> [Epoch: 102] Avg. loss: 0.0926 | Mean IoU: 0.8523\n",
            ">>>> [Epoch: 103] Training\n",
            ">>>> [Epoch: 103] Avg. loss: 0.0903 | Mean IoU: 0.8547\n",
            ">>>> [Epoch: 104] Training\n",
            ">>>> [Epoch: 104] Avg. loss: 0.0889 | Mean IoU: 0.8564\n",
            ">>>> [Epoch: 105] Training\n",
            ">>>> [Epoch: 105] Avg. loss: 0.0869 | Mean IoU: 0.8589\n",
            ">>>> [Epoch: 106] Training\n",
            ">>>> [Epoch: 106] Avg. loss: 0.0864 | Mean IoU: 0.8601\n",
            ">>>> [Epoch: 107] Training\n",
            ">>>> [Epoch: 107] Avg. loss: 0.0849 | Mean IoU: 0.8609\n",
            ">>>> [Epoch: 108] Training\n",
            ">>>> [Epoch: 108] Avg. loss: 0.0839 | Mean IoU: 0.8633\n",
            ">>>> [Epoch: 109] Training\n",
            ">>>> [Epoch: 109] Avg. loss: 0.0834 | Mean IoU: 0.8644\n",
            ">>>> [Epoch: 109] Validation\n",
            ">>>> [Epoch: 109] Avg. loss: 0.4720 | Mean IoU: 0.6895\n",
            "sky: 0.9325\n",
            "building: 0.8735\n",
            "pole: 0.1379\n",
            "road: 0.9670\n",
            "pavement: 0.8628\n",
            "tree: 0.9040\n",
            "sign_symbol: 0.3156\n",
            "fence: 0.7338\n",
            "car: 0.6801\n",
            "pedestrian: 0.4540\n",
            "bicyclist: 0.7236\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 110] Training\n",
            ">>>> [Epoch: 110] Avg. loss: 0.0831 | Mean IoU: 0.8637\n",
            ">>>> [Epoch: 111] Training\n",
            ">>>> [Epoch: 111] Avg. loss: 0.0817 | Mean IoU: 0.8665\n",
            ">>>> [Epoch: 112] Training\n",
            ">>>> [Epoch: 112] Avg. loss: 0.0806 | Mean IoU: 0.8670\n",
            ">>>> [Epoch: 113] Training\n",
            ">>>> [Epoch: 113] Avg. loss: 0.0804 | Mean IoU: 0.8680\n",
            ">>>> [Epoch: 114] Training\n",
            ">>>> [Epoch: 114] Avg. loss: 0.0805 | Mean IoU: 0.8677\n",
            ">>>> [Epoch: 115] Training\n",
            ">>>> [Epoch: 115] Avg. loss: 0.0791 | Mean IoU: 0.8687\n",
            ">>>> [Epoch: 116] Training\n",
            ">>>> [Epoch: 116] Avg. loss: 0.0794 | Mean IoU: 0.8695\n",
            ">>>> [Epoch: 117] Training\n",
            ">>>> [Epoch: 117] Avg. loss: 0.0783 | Mean IoU: 0.8703\n",
            ">>>> [Epoch: 118] Training\n",
            ">>>> [Epoch: 118] Avg. loss: 0.0777 | Mean IoU: 0.8712\n",
            ">>>> [Epoch: 119] Training\n",
            ">>>> [Epoch: 119] Avg. loss: 0.0773 | Mean IoU: 0.8719\n",
            ">>>> [Epoch: 119] Validation\n",
            ">>>> [Epoch: 119] Avg. loss: 0.5076 | Mean IoU: 0.6906\n",
            "sky: 0.9306\n",
            "building: 0.8782\n",
            "pole: 0.1379\n",
            "road: 0.9678\n",
            "pavement: 0.8679\n",
            "tree: 0.9060\n",
            "sign_symbol: 0.3023\n",
            "fence: 0.7288\n",
            "car: 0.7137\n",
            "pedestrian: 0.4512\n",
            "bicyclist: 0.7119\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 120] Training\n",
            ">>>> [Epoch: 120] Avg. loss: 0.0766 | Mean IoU: 0.8719\n",
            ">>>> [Epoch: 121] Training\n",
            ">>>> [Epoch: 121] Avg. loss: 0.0763 | Mean IoU: 0.8734\n",
            ">>>> [Epoch: 122] Training\n",
            ">>>> [Epoch: 122] Avg. loss: 0.0760 | Mean IoU: 0.8728\n",
            ">>>> [Epoch: 123] Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -m test --save-dir save/ --dataset camvid --dataset-dir CamVid2/ --name 34ResNet120"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwnrFJ2TkAGw",
        "outputId": "1fadc5ee-a749-4540-8912-33890f17b86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: CamVid2/\n",
            "Save directory: save/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 360, 480])\n",
            "Label size: torch.Size([10, 360, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0217,  3.4469, 15.9119,  9.0202, 32.0138, 32.4789,\n",
            "        13.2071, 38.3877, 44.1345,  0.0000], device='cuda:0')\n",
            "PSPNet(\n",
            "  (feats): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (4): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (5): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (psp): PSPModule(\n",
            "    (stages): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(2, 2))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(3, 3))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (bottleneck): Conv2d(2560, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (drop_1): Dropout2d(p=0.3, inplace=False)\n",
            "  (up_1): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (up_2): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (up_3): PSPUpsample(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (drop_2): Dropout2d(p=0.15, inplace=False)\n",
            "  (final): Sequential(\n",
            "    (0): Conv2d(64, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): LogSoftmax(dim=None)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=256, out_features=12, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "Testing...\n",
            "\n",
            ">>>> Running test dataset\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n",
            ">>>> Avg. loss: 1.1613 | Mean IoU: 0.5580\n",
            "sky: 0.8991\n",
            "building: 0.7569\n",
            "pole: 0.2534\n",
            "road: 0.9227\n",
            "pavement: 0.7529\n",
            "tree: 0.6508\n",
            "sign_symbol: 0.2523\n",
            "fence: 0.1573\n",
            "car: 0.7211\n",
            "pedestrian: 0.3953\n",
            "bicyclist: 0.3761\n",
            "unlabeled: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distillation\n",
        " distill from resnet 34(55%) to ENet(52%)"
      ],
      "metadata": {
        "id": "mZiIP6kC3tjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py -m train --save-dir save/ --dataset camvid --dataset-dir ../CamVid2/ --name BiSeNet1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcDVs2kjQlf8",
        "outputId": "f63e498a-df38-4a2f-bdb1-e3f8da91d7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: ../CamVid2/\n",
            "Save directory: save/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 640, 480])\n",
            "Label size: torch.Size([10, 640, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0252,  3.4468, 15.9117,  9.0204, 32.0129, 32.4791,\n",
            "        13.2076, 38.3884, 44.1342,  0.0000], device='cuda:0')\n",
            "\n",
            "Training...\n",
            "\n",
            "\n",
            ">>>> [Epoch: 0] Training\n",
            ">>>> [Epoch: 0] Avg. loss: 0.9795 | Mean IoU: 0.3920\n",
            ">>>> [Epoch: 1] Training\n",
            ">>>> [Epoch: 1] Avg. loss: 0.5386 | Mean IoU: 0.5483\n",
            ">>>> [Epoch: 2] Training\n",
            ">>>> [Epoch: 2] Avg. loss: 0.4206 | Mean IoU: 0.6097\n",
            ">>>> [Epoch: 3] Training\n",
            ">>>> [Epoch: 3] Avg. loss: 0.3661 | Mean IoU: 0.6379\n",
            ">>>> [Epoch: 4] Training\n",
            ">>>> [Epoch: 4] Avg. loss: 0.3083 | Mean IoU: 0.6793\n",
            ">>>> [Epoch: 5] Training\n",
            ">>>> [Epoch: 5] Avg. loss: 0.2648 | Mean IoU: 0.7069\n",
            ">>>> [Epoch: 6] Training\n",
            ">>>> [Epoch: 6] Avg. loss: 0.2393 | Mean IoU: 0.7235\n",
            ">>>> [Epoch: 7] Training\n",
            ">>>> [Epoch: 7] Avg. loss: 0.2200 | Mean IoU: 0.7353\n",
            ">>>> [Epoch: 8] Training\n",
            ">>>> [Epoch: 8] Avg. loss: 0.2044 | Mean IoU: 0.7473\n",
            ">>>> [Epoch: 9] Training\n",
            ">>>> [Epoch: 9] Avg. loss: 0.1932 | Mean IoU: 0.7551\n",
            ">>>> [Epoch: 9] Validation\n",
            ">>>> [Epoch: 9] Avg. loss: 0.3742 | Mean IoU: 0.6807\n",
            "sky: 0.9394\n",
            "building: 0.8673\n",
            "pole: 0.0871\n",
            "road: 0.9579\n",
            "pavement: 0.8572\n",
            "tree: 0.9138\n",
            "sign_symbol: 0.4164\n",
            "fence: 0.6465\n",
            "car: 0.8222\n",
            "pedestrian: 0.3694\n",
            "bicyclist: 0.6109\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 10] Training\n",
            ">>>> [Epoch: 10] Avg. loss: 0.1780 | Mean IoU: 0.7662\n",
            ">>>> [Epoch: 11] Training\n",
            ">>>> [Epoch: 11] Avg. loss: 0.1674 | Mean IoU: 0.7744\n",
            ">>>> [Epoch: 12] Training\n",
            ">>>> [Epoch: 12] Avg. loss: 0.1589 | Mean IoU: 0.7830\n",
            ">>>> [Epoch: 13] Training\n",
            ">>>> [Epoch: 13] Avg. loss: 0.1537 | Mean IoU: 0.7852\n",
            ">>>> [Epoch: 14] Training\n",
            ">>>> [Epoch: 14] Avg. loss: 0.1536 | Mean IoU: 0.7889\n",
            ">>>> [Epoch: 15] Training\n",
            ">>>> [Epoch: 15] Avg. loss: 0.1464 | Mean IoU: 0.7933\n",
            ">>>> [Epoch: 16] Training\n",
            ">>>> [Epoch: 16] Avg. loss: 0.1393 | Mean IoU: 0.7992\n",
            ">>>> [Epoch: 17] Training\n",
            ">>>> [Epoch: 17] Avg. loss: 0.1383 | Mean IoU: 0.8006\n",
            ">>>> [Epoch: 18] Training\n",
            ">>>> [Epoch: 18] Avg. loss: 0.1342 | Mean IoU: 0.8037\n",
            ">>>> [Epoch: 19] Training\n",
            ">>>> [Epoch: 19] Avg. loss: 0.1253 | Mean IoU: 0.8104\n",
            ">>>> [Epoch: 19] Validation\n",
            ">>>> [Epoch: 19] Avg. loss: 0.3760 | Mean IoU: 0.6834\n",
            "sky: 0.9327\n",
            "building: 0.8654\n",
            "pole: 0.0776\n",
            "road: 0.9622\n",
            "pavement: 0.8635\n",
            "tree: 0.9150\n",
            "sign_symbol: 0.4761\n",
            "fence: 0.7029\n",
            "car: 0.5892\n",
            "pedestrian: 0.4440\n",
            "bicyclist: 0.6885\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 20] Training\n",
            ">>>> [Epoch: 20] Avg. loss: 0.1391 | Mean IoU: 0.7929\n",
            ">>>> [Epoch: 21] Training\n",
            ">>>> [Epoch: 21] Avg. loss: 0.2830 | Mean IoU: 0.6798\n",
            ">>>> [Epoch: 22] Training\n",
            ">>>> [Epoch: 22] Avg. loss: 0.4037 | Mean IoU: 0.6103\n",
            ">>>> [Epoch: 23] Training\n",
            ">>>> [Epoch: 23] Avg. loss: 0.2351 | Mean IoU: 0.7232\n",
            ">>>> [Epoch: 24] Training\n",
            ">>>> [Epoch: 24] Avg. loss: 0.1761 | Mean IoU: 0.7692\n",
            ">>>> [Epoch: 25] Training\n",
            ">>>> [Epoch: 25] Avg. loss: 0.1466 | Mean IoU: 0.7945\n",
            ">>>> [Epoch: 26] Training\n",
            ">>>> [Epoch: 26] Avg. loss: 0.1323 | Mean IoU: 0.8059\n",
            ">>>> [Epoch: 27] Training\n",
            ">>>> [Epoch: 27] Avg. loss: 0.1239 | Mean IoU: 0.8147\n",
            ">>>> [Epoch: 28] Training\n",
            ">>>> [Epoch: 28] Avg. loss: 0.1174 | Mean IoU: 0.8207\n",
            ">>>> [Epoch: 29] Training\n",
            ">>>> [Epoch: 29] Avg. loss: 0.1108 | Mean IoU: 0.8273\n",
            ">>>> [Epoch: 29] Validation\n",
            ">>>> [Epoch: 29] Avg. loss: 0.3934 | Mean IoU: 0.6948\n",
            "sky: 0.9380\n",
            "building: 0.8795\n",
            "pole: 0.1041\n",
            "road: 0.9637\n",
            "pavement: 0.8489\n",
            "tree: 0.9130\n",
            "sign_symbol: 0.4797\n",
            "fence: 0.7159\n",
            "car: 0.7804\n",
            "pedestrian: 0.3866\n",
            "bicyclist: 0.6327\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 30] Training\n",
            ">>>> [Epoch: 30] Avg. loss: 0.1096 | Mean IoU: 0.8286\n",
            ">>>> [Epoch: 31] Training\n",
            ">>>> [Epoch: 31] Avg. loss: 0.1094 | Mean IoU: 0.8301\n",
            ">>>> [Epoch: 32] Training\n",
            ">>>> [Epoch: 32] Avg. loss: 0.1073 | Mean IoU: 0.8311\n",
            ">>>> [Epoch: 33] Training\n",
            ">>>> [Epoch: 33] Avg. loss: 0.1035 | Mean IoU: 0.8348\n",
            ">>>> [Epoch: 34] Training\n",
            ">>>> [Epoch: 34] Avg. loss: 0.1021 | Mean IoU: 0.8360\n",
            ">>>> [Epoch: 35] Training\n",
            ">>>> [Epoch: 35] Avg. loss: 0.1011 | Mean IoU: 0.8372\n",
            ">>>> [Epoch: 36] Training\n",
            ">>>> [Epoch: 36] Avg. loss: 0.0997 | Mean IoU: 0.8394\n",
            ">>>> [Epoch: 37] Training\n",
            ">>>> [Epoch: 37] Avg. loss: 0.0975 | Mean IoU: 0.8417\n",
            ">>>> [Epoch: 38] Training\n",
            ">>>> [Epoch: 38] Avg. loss: 0.0980 | Mean IoU: 0.8410\n",
            ">>>> [Epoch: 39] Training\n",
            ">>>> [Epoch: 39] Avg. loss: 0.0974 | Mean IoU: 0.8416\n",
            ">>>> [Epoch: 39] Validation\n",
            ">>>> [Epoch: 39] Avg. loss: 0.4733 | Mean IoU: 0.6944\n",
            ">>>> [Epoch: 40] Training\n",
            ">>>> [Epoch: 40] Avg. loss: 0.0969 | Mean IoU: 0.8432\n",
            ">>>> [Epoch: 41] Training\n",
            ">>>> [Epoch: 41] Avg. loss: 0.0967 | Mean IoU: 0.8437\n",
            ">>>> [Epoch: 42] Training\n",
            ">>>> [Epoch: 42] Avg. loss: 0.0950 | Mean IoU: 0.8430\n",
            ">>>> [Epoch: 43] Training\n",
            ">>>> [Epoch: 43] Avg. loss: 0.0941 | Mean IoU: 0.8446\n",
            ">>>> [Epoch: 44] Training\n",
            ">>>> [Epoch: 44] Avg. loss: 0.0941 | Mean IoU: 0.8443\n",
            ">>>> [Epoch: 45] Training\n",
            ">>>> [Epoch: 45] Avg. loss: 0.0929 | Mean IoU: 0.8460\n",
            ">>>> [Epoch: 46] Training\n",
            ">>>> [Epoch: 46] Avg. loss: 0.0945 | Mean IoU: 0.8453\n",
            ">>>> [Epoch: 47] Training\n",
            ">>>> [Epoch: 47] Avg. loss: 0.0935 | Mean IoU: 0.8462\n",
            ">>>> [Epoch: 48] Training\n",
            ">>>> [Epoch: 48] Avg. loss: 0.0939 | Mean IoU: 0.8452\n",
            ">>>> [Epoch: 49] Training\n",
            ">>>> [Epoch: 49] Avg. loss: 0.3746 | Mean IoU: 0.6399\n",
            ">>>> [Epoch: 49] Validation\n",
            ">>>> [Epoch: 49] Avg. loss: 1099.0282 | Mean IoU: 0.0177\n",
            ">>>> [Epoch: 50] Training\n",
            ">>>> [Epoch: 50] Avg. loss: 0.5568 | Mean IoU: 0.5327\n",
            ">>>> [Epoch: 51] Training\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 337, in <module>\n",
            "    model = train(train_loader, val_loader, w_class, class_encoding)\n",
            "  File \"main.py\", line 223, in train\n",
            "    epoch_loss, (iou, miou) = train.run_epoch(args.print_step)\n",
            "  File \"/content/drive/MyDrive/Enet/train.py\", line 47, in run_epoch\n",
            "    labels = batch_data[1].to(self.device)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -m test --save-dir save/ --dataset camvid --dataset-dir ../CamVid2/ --name BiSeNet1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scnVAVyPaPqF",
        "outputId": "a4e607f9-f450-431d-b86a-1f3833c90d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: ../CamVid2/\n",
            "Save directory: save/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 640, 480])\n",
            "Label size: torch.Size([10, 640, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0252,  3.4468, 15.9117,  9.0204, 32.0129, 32.4791,\n",
            "        13.2076, 38.3884, 44.1342,  0.0000], device='cuda:0')\n",
            "################################save/BiSeNet1#####################\n",
            "BiSeNetV1(\n",
            "  (cp): ContextPath(\n",
            "    (resnet): Resnet18(\n",
            "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (layer1): Sequential(\n",
            "        (0): BasicBlock(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): BasicBlock(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer2): Sequential(\n",
            "        (0): BasicBlock(\n",
            "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BasicBlock(\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer3): Sequential(\n",
            "        (0): BasicBlock(\n",
            "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BasicBlock(\n",
            "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer4): Sequential(\n",
            "        (0): BasicBlock(\n",
            "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): BasicBlock(\n",
            "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (arm16): AttentionRefinementModule(\n",
            "      (conv): ConvBNReLU(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv_atten): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn_atten): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (arm32): AttentionRefinementModule(\n",
            "      (conv): ConvBNReLU(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv_atten): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn_atten): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_head32): ConvBNReLU(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (conv_head16): ConvBNReLU(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (conv_avg): ConvBNReLU(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (up32): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (up16): Upsample(scale_factor=2.0, mode=nearest)\n",
            "  )\n",
            "  (sp): SpatialPath(\n",
            "    (conv1): ConvBNReLU(\n",
            "      (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (conv2): ConvBNReLU(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (conv3): ConvBNReLU(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (conv_out): ConvBNReLU(\n",
            "      (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (ffm): FeatureFusionModule(\n",
            "    (convblk): ConvBNReLU(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv_out): BiSeNetOutput(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (conv_out): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (up): Upsample(scale_factor=8.0, mode=bilinear)\n",
            "  )\n",
            "  (conv_out16): BiSeNetOutput(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (conv_out): Conv2d(64, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (up): Upsample(scale_factor=8.0, mode=bilinear)\n",
            "  )\n",
            "  (conv_out32): BiSeNetOutput(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (conv_out): Conv2d(64, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (up): Upsample(scale_factor=16.0, mode=bilinear)\n",
            "  )\n",
            ")\n",
            "\n",
            "Testing...\n",
            "\n",
            ">>>> Running test dataset\n",
            ">>>> Avg. loss: 0.7223 | Mean IoU: 0.6067\n",
            "sky: 0.9013\n",
            "building: 0.7881\n",
            "pole: 0.2028\n",
            "road: 0.9301\n",
            "pavement: 0.7716\n",
            "tree: 0.7479\n",
            "sign_symbol: 0.3862\n",
            "fence: 0.3707\n",
            "car: 0.7610\n",
            "pedestrian: 0.4202\n",
            "bicyclist: 0.3943\n",
            "unlabeled: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py -m train --save-dir save/ --dataset camvid --dataset-dir ../CamVid2/ --name BiSeNet2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ8APEQRaaQP",
        "outputId": "c863f466-bb0d-4d9d-91f4-28caa76d5588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: ../CamVid2/\n",
            "Save directory: save/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 640, 480])\n",
            "Label size: torch.Size([10, 640, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0252,  3.4468, 15.9117,  9.0204, 32.0129, 32.4791,\n",
            "        13.2076, 38.3884, 44.1342,  0.0000], device='cuda:0')\n",
            "\n",
            "Training...\n",
            "\n",
            "Downloading: \"https://github.com/CoinCheung/BiSeNet/releases/download/0.0.0/backbone_v2.pth\" to /root/.cache/torch/hub/checkpoints/backbone_v2.pth\n",
            "100% 8.34M/8.34M [00:00<00:00, 38.7MB/s]\n",
            "\n",
            ">>>> [Epoch: 0] Training\n",
            ">>>> [Epoch: 0] Avg. loss: 3.3346 | Mean IoU: 0.3929\n",
            ">>>> [Epoch: 1] Training\n",
            ">>>> [Epoch: 1] Avg. loss: 0.7606 | Mean IoU: 0.4984\n",
            ">>>> [Epoch: 2] Training\n",
            ">>>> [Epoch: 2] Avg. loss: 0.4944 | Mean IoU: 0.5725\n",
            ">>>> [Epoch: 3] Training\n",
            ">>>> [Epoch: 3] Avg. loss: 0.4248 | Mean IoU: 0.6096\n",
            ">>>> [Epoch: 4] Training\n",
            ">>>> [Epoch: 4] Avg. loss: 0.3919 | Mean IoU: 0.6244\n",
            ">>>> [Epoch: 5] Training\n",
            ">>>> [Epoch: 5] Avg. loss: 0.3587 | Mean IoU: 0.6467\n",
            ">>>> [Epoch: 6] Training\n",
            ">>>> [Epoch: 6] Avg. loss: 0.3271 | Mean IoU: 0.6646\n",
            ">>>> [Epoch: 7] Training\n",
            ">>>> [Epoch: 7] Avg. loss: 0.3106 | Mean IoU: 0.6756\n",
            ">>>> [Epoch: 8] Training\n",
            ">>>> [Epoch: 8] Avg. loss: 0.2962 | Mean IoU: 0.6860\n",
            ">>>> [Epoch: 9] Training\n",
            ">>>> [Epoch: 9] Avg. loss: 0.2841 | Mean IoU: 0.6930\n",
            ">>>> [Epoch: 9] Validation\n",
            ">>>> [Epoch: 9] Avg. loss: 0.4096 | Mean IoU: 0.6519\n",
            "sky: 0.9360\n",
            "building: 0.8398\n",
            "pole: 0.0880\n",
            "road: 0.9495\n",
            "pavement: 0.8160\n",
            "tree: 0.8958\n",
            "sign_symbol: 0.3818\n",
            "fence: 0.6034\n",
            "car: 0.8062\n",
            "pedestrian: 0.2847\n",
            "bicyclist: 0.5696\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 10] Training\n",
            ">>>> [Epoch: 10] Avg. loss: 0.2668 | Mean IoU: 0.7037\n",
            ">>>> [Epoch: 11] Training\n",
            ">>>> [Epoch: 11] Avg. loss: 0.2567 | Mean IoU: 0.7135\n",
            ">>>> [Epoch: 12] Training\n",
            ">>>> [Epoch: 12] Avg. loss: 0.2475 | Mean IoU: 0.7201\n",
            ">>>> [Epoch: 13] Training\n",
            ">>>> [Epoch: 13] Avg. loss: 0.2388 | Mean IoU: 0.7262\n",
            ">>>> [Epoch: 14] Training\n",
            ">>>> [Epoch: 14] Avg. loss: 0.2257 | Mean IoU: 0.7348\n",
            ">>>> [Epoch: 15] Training\n",
            ">>>> [Epoch: 15] Avg. loss: 0.2195 | Mean IoU: 0.7414\n",
            ">>>> [Epoch: 16] Training\n",
            ">>>> [Epoch: 16] Avg. loss: 0.2083 | Mean IoU: 0.7500\n",
            ">>>> [Epoch: 17] Training\n",
            ">>>> [Epoch: 17] Avg. loss: 0.2053 | Mean IoU: 0.7506\n",
            ">>>> [Epoch: 18] Training\n",
            ">>>> [Epoch: 18] Avg. loss: 0.1962 | Mean IoU: 0.7602\n",
            ">>>> [Epoch: 19] Training\n",
            ">>>> [Epoch: 19] Avg. loss: 0.1920 | Mean IoU: 0.7606\n",
            ">>>> [Epoch: 19] Validation\n",
            ">>>> [Epoch: 19] Avg. loss: 0.3833 | Mean IoU: 0.6816\n",
            "sky: 0.9370\n",
            "building: 0.8643\n",
            "pole: 0.1224\n",
            "road: 0.9500\n",
            "pavement: 0.8133\n",
            "tree: 0.9055\n",
            "sign_symbol: 0.4340\n",
            "fence: 0.6413\n",
            "car: 0.8122\n",
            "pedestrian: 0.3753\n",
            "bicyclist: 0.6423\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 20] Training\n",
            ">>>> [Epoch: 20] Avg. loss: 0.1863 | Mean IoU: 0.7664\n",
            ">>>> [Epoch: 21] Training\n",
            ">>>> [Epoch: 21] Avg. loss: 0.1812 | Mean IoU: 0.7695\n",
            ">>>> [Epoch: 22] Training\n",
            ">>>> [Epoch: 22] Avg. loss: 0.1763 | Mean IoU: 0.7734\n",
            ">>>> [Epoch: 23] Training\n",
            ">>>> [Epoch: 23] Avg. loss: 0.1736 | Mean IoU: 0.7768\n",
            ">>>> [Epoch: 24] Training\n",
            ">>>> [Epoch: 24] Avg. loss: 0.1724 | Mean IoU: 0.7763\n",
            ">>>> [Epoch: 25] Training\n",
            ">>>> [Epoch: 25] Avg. loss: 0.1634 | Mean IoU: 0.7848\n",
            ">>>> [Epoch: 26] Training\n",
            ">>>> [Epoch: 26] Avg. loss: 0.1592 | Mean IoU: 0.7866\n",
            ">>>> [Epoch: 27] Training\n",
            ">>>> [Epoch: 27] Avg. loss: 0.1583 | Mean IoU: 0.7891\n",
            ">>>> [Epoch: 28] Training\n",
            ">>>> [Epoch: 28] Avg. loss: 0.1550 | Mean IoU: 0.7895\n",
            ">>>> [Epoch: 29] Training\n",
            ">>>> [Epoch: 29] Avg. loss: 0.1509 | Mean IoU: 0.7949\n",
            ">>>> [Epoch: 29] Validation\n",
            ">>>> [Epoch: 29] Avg. loss: 0.4065 | Mean IoU: 0.6918\n",
            "sky: 0.9350\n",
            "building: 0.8737\n",
            "pole: 0.1222\n",
            "road: 0.9583\n",
            "pavement: 0.8429\n",
            "tree: 0.9054\n",
            "sign_symbol: 0.4702\n",
            "fence: 0.6606\n",
            "car: 0.8278\n",
            "pedestrian: 0.3819\n",
            "bicyclist: 0.6314\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 30] Training\n",
            ">>>> [Epoch: 30] Avg. loss: 0.1482 | Mean IoU: 0.7966\n",
            ">>>> [Epoch: 31] Training\n",
            ">>>> [Epoch: 31] Avg. loss: 0.1446 | Mean IoU: 0.7996\n",
            ">>>> [Epoch: 32] Training\n",
            ">>>> [Epoch: 32] Avg. loss: 0.1436 | Mean IoU: 0.8013\n",
            ">>>> [Epoch: 33] Training\n",
            ">>>> [Epoch: 33] Avg. loss: 0.1408 | Mean IoU: 0.8049\n",
            ">>>> [Epoch: 34] Training\n",
            ">>>> [Epoch: 34] Avg. loss: 0.1381 | Mean IoU: 0.8055\n",
            ">>>> [Epoch: 35] Training\n",
            ">>>> [Epoch: 35] Avg. loss: 0.1359 | Mean IoU: 0.8074\n",
            ">>>> [Epoch: 36] Training\n",
            ">>>> [Epoch: 36] Avg. loss: 0.1334 | Mean IoU: 0.8102\n",
            ">>>> [Epoch: 37] Training\n",
            ">>>> [Epoch: 37] Avg. loss: 0.1323 | Mean IoU: 0.8105\n",
            ">>>> [Epoch: 38] Training\n",
            ">>>> [Epoch: 38] Avg. loss: 0.1335 | Mean IoU: 0.8113\n",
            ">>>> [Epoch: 39] Training\n",
            ">>>> [Epoch: 39] Avg. loss: 0.1294 | Mean IoU: 0.8139\n",
            ">>>> [Epoch: 39] Validation\n",
            ">>>> [Epoch: 39] Avg. loss: 0.4204 | Mean IoU: 0.7046\n",
            "sky: 0.9342\n",
            "building: 0.8844\n",
            "pole: 0.1334\n",
            "road: 0.9639\n",
            "pavement: 0.8548\n",
            "tree: 0.9088\n",
            "sign_symbol: 0.4875\n",
            "fence: 0.6982\n",
            "car: 0.8142\n",
            "pedestrian: 0.4126\n",
            "bicyclist: 0.6584\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 40] Training\n",
            ">>>> [Epoch: 40] Avg. loss: 0.1272 | Mean IoU: 0.8156\n",
            ">>>> [Epoch: 41] Training\n",
            ">>>> [Epoch: 41] Avg. loss: 0.1279 | Mean IoU: 0.8145\n",
            ">>>> [Epoch: 42] Training\n",
            ">>>> [Epoch: 42] Avg. loss: 0.1260 | Mean IoU: 0.8168\n",
            ">>>> [Epoch: 43] Training\n",
            ">>>> [Epoch: 43] Avg. loss: 0.1237 | Mean IoU: 0.8183\n",
            ">>>> [Epoch: 44] Training\n",
            ">>>> [Epoch: 44] Avg. loss: 0.1192 | Mean IoU: 0.8226\n",
            ">>>> [Epoch: 45] Training\n",
            ">>>> [Epoch: 45] Avg. loss: 0.1180 | Mean IoU: 0.8244\n",
            ">>>> [Epoch: 46] Training\n",
            ">>>> [Epoch: 46] Avg. loss: 0.1191 | Mean IoU: 0.8244\n",
            ">>>> [Epoch: 47] Training\n",
            ">>>> [Epoch: 47] Avg. loss: 0.1164 | Mean IoU: 0.8261\n",
            ">>>> [Epoch: 48] Training\n",
            ">>>> [Epoch: 48] Avg. loss: 0.1144 | Mean IoU: 0.8285\n",
            ">>>> [Epoch: 49] Training\n",
            ">>>> [Epoch: 49] Avg. loss: 0.1129 | Mean IoU: 0.8293\n",
            ">>>> [Epoch: 49] Validation\n",
            ">>>> [Epoch: 49] Avg. loss: 0.5089 | Mean IoU: 0.6955\n",
            ">>>> [Epoch: 50] Training\n",
            ">>>> [Epoch: 50] Avg. loss: 0.1110 | Mean IoU: 0.8322\n",
            ">>>> [Epoch: 51] Training\n",
            ">>>> [Epoch: 51] Avg. loss: 0.1119 | Mean IoU: 0.8306\n",
            ">>>> [Epoch: 52] Training\n",
            ">>>> [Epoch: 52] Avg. loss: 0.1110 | Mean IoU: 0.8309\n",
            ">>>> [Epoch: 53] Training\n",
            ">>>> [Epoch: 53] Avg. loss: 0.1151 | Mean IoU: 0.8250\n",
            ">>>> [Epoch: 54] Training\n",
            ">>>> [Epoch: 54] Avg. loss: 0.1185 | Mean IoU: 0.8223\n",
            ">>>> [Epoch: 55] Training\n",
            ">>>> [Epoch: 55] Avg. loss: 0.1116 | Mean IoU: 0.8311\n",
            ">>>> [Epoch: 56] Training\n",
            ">>>> [Epoch: 56] Avg. loss: 0.1107 | Mean IoU: 0.8325\n",
            ">>>> [Epoch: 57] Training\n",
            ">>>> [Epoch: 57] Avg. loss: 0.1090 | Mean IoU: 0.8333\n",
            ">>>> [Epoch: 58] Training\n",
            ">>>> [Epoch: 58] Avg. loss: 0.1067 | Mean IoU: 0.8351\n",
            ">>>> [Epoch: 59] Training\n",
            ">>>> [Epoch: 59] Avg. loss: 0.1054 | Mean IoU: 0.8374\n",
            ">>>> [Epoch: 59] Validation\n",
            ">>>> [Epoch: 59] Avg. loss: 0.4606 | Mean IoU: 0.7070\n",
            "sky: 0.9375\n",
            "building: 0.8813\n",
            "pole: 0.1373\n",
            "road: 0.9628\n",
            "pavement: 0.8367\n",
            "tree: 0.9081\n",
            "sign_symbol: 0.4520\n",
            "fence: 0.7311\n",
            "car: 0.8339\n",
            "pedestrian: 0.4250\n",
            "bicyclist: 0.6717\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 60] Training\n",
            ">>>> [Epoch: 60] Avg. loss: 0.1082 | Mean IoU: 0.8349\n",
            ">>>> [Epoch: 61] Training\n",
            ">>>> [Epoch: 61] Avg. loss: 0.1095 | Mean IoU: 0.8334\n",
            ">>>> [Epoch: 62] Training\n",
            ">>>> [Epoch: 62] Avg. loss: 0.1093 | Mean IoU: 0.8336\n",
            ">>>> [Epoch: 63] Training\n",
            ">>>> [Epoch: 63] Avg. loss: 0.1100 | Mean IoU: 0.8332\n",
            ">>>> [Epoch: 64] Training\n",
            ">>>> [Epoch: 64] Avg. loss: 0.1098 | Mean IoU: 0.8322\n",
            ">>>> [Epoch: 65] Training\n",
            ">>>> [Epoch: 65] Avg. loss: 0.1035 | Mean IoU: 0.8387\n",
            ">>>> [Epoch: 66] Training\n",
            ">>>> [Epoch: 66] Avg. loss: 0.0996 | Mean IoU: 0.8426\n",
            ">>>> [Epoch: 67] Training\n",
            ">>>> [Epoch: 67] Avg. loss: 0.0998 | Mean IoU: 0.8422\n",
            ">>>> [Epoch: 68] Training\n",
            ">>>> [Epoch: 68] Avg. loss: 0.0991 | Mean IoU: 0.8445\n",
            ">>>> [Epoch: 69] Training\n",
            ">>>> [Epoch: 69] Avg. loss: 0.0992 | Mean IoU: 0.8426\n",
            ">>>> [Epoch: 69] Validation\n",
            ">>>> [Epoch: 69] Avg. loss: 0.4779 | Mean IoU: 0.7034\n",
            ">>>> [Epoch: 70] Training\n",
            ">>>> [Epoch: 70] Avg. loss: 0.0990 | Mean IoU: 0.8438\n",
            ">>>> [Epoch: 71] Training\n",
            ">>>> [Epoch: 71] Avg. loss: 0.0972 | Mean IoU: 0.8451\n",
            ">>>> [Epoch: 72] Training\n",
            ">>>> [Epoch: 72] Avg. loss: 0.0939 | Mean IoU: 0.8490\n",
            ">>>> [Epoch: 73] Training\n",
            ">>>> [Epoch: 73] Avg. loss: 0.0918 | Mean IoU: 0.8518\n",
            ">>>> [Epoch: 74] Training\n",
            ">>>> [Epoch: 74] Avg. loss: 0.0918 | Mean IoU: 0.8509\n",
            ">>>> [Epoch: 75] Training\n",
            ">>>> [Epoch: 75] Avg. loss: 0.0919 | Mean IoU: 0.8514\n",
            ">>>> [Epoch: 76] Training\n",
            ">>>> [Epoch: 76] Avg. loss: 0.0935 | Mean IoU: 0.8498\n",
            ">>>> [Epoch: 77] Training\n",
            ">>>> [Epoch: 77] Avg. loss: 0.0927 | Mean IoU: 0.8508\n",
            ">>>> [Epoch: 78] Training\n",
            ">>>> [Epoch: 78] Avg. loss: 0.0941 | Mean IoU: 0.8497\n",
            ">>>> [Epoch: 79] Training\n",
            ">>>> [Epoch: 79] Avg. loss: 0.0988 | Mean IoU: 0.8449\n",
            ">>>> [Epoch: 79] Validation\n",
            ">>>> [Epoch: 79] Avg. loss: 0.4307 | Mean IoU: 0.7189\n",
            "sky: 0.9394\n",
            "building: 0.8875\n",
            "pole: 0.1307\n",
            "road: 0.9649\n",
            "pavement: 0.8699\n",
            "tree: 0.9196\n",
            "sign_symbol: 0.5022\n",
            "fence: 0.7363\n",
            "car: 0.8325\n",
            "pedestrian: 0.4474\n",
            "bicyclist: 0.6777\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 80] Training\n",
            ">>>> [Epoch: 80] Avg. loss: 0.0995 | Mean IoU: 0.8429\n",
            ">>>> [Epoch: 81] Training\n",
            ">>>> [Epoch: 81] Avg. loss: 0.1019 | Mean IoU: 0.8409\n",
            ">>>> [Epoch: 82] Training\n",
            ">>>> [Epoch: 82] Avg. loss: 0.1000 | Mean IoU: 0.8429\n",
            ">>>> [Epoch: 83] Training\n",
            ">>>> [Epoch: 83] Avg. loss: 0.0946 | Mean IoU: 0.8481\n",
            ">>>> [Epoch: 84] Training\n",
            ">>>> [Epoch: 84] Avg. loss: 0.0919 | Mean IoU: 0.8515\n",
            ">>>> [Epoch: 85] Training\n",
            ">>>> [Epoch: 85] Avg. loss: 0.0920 | Mean IoU: 0.8518\n",
            ">>>> [Epoch: 86] Training\n",
            ">>>> [Epoch: 86] Avg. loss: 0.0910 | Mean IoU: 0.8519\n",
            ">>>> [Epoch: 87] Training\n",
            ">>>> [Epoch: 87] Avg. loss: 0.0892 | Mean IoU: 0.8538\n",
            ">>>> [Epoch: 88] Training\n",
            ">>>> [Epoch: 88] Avg. loss: 0.0883 | Mean IoU: 0.8544\n",
            ">>>> [Epoch: 89] Training\n",
            ">>>> [Epoch: 89] Avg. loss: 0.0899 | Mean IoU: 0.8543\n",
            ">>>> [Epoch: 89] Validation\n",
            ">>>> [Epoch: 89] Avg. loss: 0.5173 | Mean IoU: 0.7130\n",
            ">>>> [Epoch: 90] Training\n",
            ">>>> [Epoch: 90] Avg. loss: 0.0934 | Mean IoU: 0.8505\n",
            ">>>> [Epoch: 91] Training\n",
            ">>>> [Epoch: 91] Avg. loss: 0.0953 | Mean IoU: 0.8480\n",
            ">>>> [Epoch: 92] Training\n",
            ">>>> [Epoch: 92] Avg. loss: 0.0995 | Mean IoU: 0.8440\n",
            ">>>> [Epoch: 93] Training\n",
            ">>>> [Epoch: 93] Avg. loss: 0.0989 | Mean IoU: 0.8434\n",
            ">>>> [Epoch: 94] Training\n",
            ">>>> [Epoch: 94] Avg. loss: 0.1931 | Mean IoU: 0.7628\n",
            ">>>> [Epoch: 95] Training\n",
            ">>>> [Epoch: 95] Avg. loss: 0.3848 | Mean IoU: 0.6209\n",
            ">>>> [Epoch: 96] Training\n",
            ">>>> [Epoch: 96] Avg. loss: 0.2211 | Mean IoU: 0.7332\n",
            ">>>> [Epoch: 97] Training\n",
            ">>>> [Epoch: 97] Avg. loss: 0.1600 | Mean IoU: 0.7837\n",
            ">>>> [Epoch: 98] Training\n",
            ">>>> [Epoch: 98] Avg. loss: 0.1329 | Mean IoU: 0.8102\n",
            ">>>> [Epoch: 99] Training\n",
            ">>>> [Epoch: 99] Avg. loss: 0.1174 | Mean IoU: 0.8241\n",
            ">>>> [Epoch: 99] Validation\n",
            ">>>> [Epoch: 99] Avg. loss: 0.4411 | Mean IoU: 0.7119\n",
            ">>>> [Epoch: 100] Training\n",
            ">>>> [Epoch: 100] Avg. loss: 0.1053 | Mean IoU: 0.8363\n",
            ">>>> [Epoch: 101] Training\n",
            ">>>> [Epoch: 101] Avg. loss: 0.1021 | Mean IoU: 0.8407\n",
            ">>>> [Epoch: 102] Training\n",
            ">>>> [Epoch: 102] Avg. loss: 0.1006 | Mean IoU: 0.8416\n",
            ">>>> [Epoch: 103] Training\n",
            ">>>> [Epoch: 103] Avg. loss: 0.1000 | Mean IoU: 0.8428\n",
            ">>>> [Epoch: 104] Training\n",
            ">>>> [Epoch: 104] Avg. loss: 0.0985 | Mean IoU: 0.8444\n",
            ">>>> [Epoch: 105] Training\n",
            ">>>> [Epoch: 105] Avg. loss: 0.0984 | Mean IoU: 0.8449\n",
            ">>>> [Epoch: 106] Training\n",
            ">>>> [Epoch: 106] Avg. loss: 0.0967 | Mean IoU: 0.8464\n",
            ">>>> [Epoch: 107] Training\n",
            ">>>> [Epoch: 107] Avg. loss: 0.0963 | Mean IoU: 0.8470\n",
            ">>>> [Epoch: 108] Training\n",
            ">>>> [Epoch: 108] Avg. loss: 0.0956 | Mean IoU: 0.8475\n",
            ">>>> [Epoch: 109] Training\n",
            ">>>> [Epoch: 109] Avg. loss: 0.0943 | Mean IoU: 0.8488\n",
            ">>>> [Epoch: 109] Validation\n",
            ">>>> [Epoch: 109] Avg. loss: 0.4548 | Mean IoU: 0.7206\n",
            "sky: 0.9382\n",
            "building: 0.8864\n",
            "pole: 0.1429\n",
            "road: 0.9691\n",
            "pavement: 0.8626\n",
            "tree: 0.9176\n",
            "sign_symbol: 0.5218\n",
            "fence: 0.7640\n",
            "car: 0.8101\n",
            "pedestrian: 0.4345\n",
            "bicyclist: 0.6800\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 110] Training\n",
            ">>>> [Epoch: 110] Avg. loss: 0.0939 | Mean IoU: 0.8494\n",
            ">>>> [Epoch: 111] Training\n",
            ">>>> [Epoch: 111] Avg. loss: 0.0934 | Mean IoU: 0.8503\n",
            ">>>> [Epoch: 112] Training\n",
            ">>>> [Epoch: 112] Avg. loss: 0.0929 | Mean IoU: 0.8506\n",
            ">>>> [Epoch: 113] Training\n",
            ">>>> [Epoch: 113] Avg. loss: 0.0919 | Mean IoU: 0.8521\n",
            ">>>> [Epoch: 114] Training\n",
            ">>>> [Epoch: 114] Avg. loss: 0.0910 | Mean IoU: 0.8523\n",
            ">>>> [Epoch: 115] Training\n",
            ">>>> [Epoch: 115] Avg. loss: 0.0906 | Mean IoU: 0.8529\n",
            ">>>> [Epoch: 116] Training\n",
            ">>>> [Epoch: 116] Avg. loss: 0.0901 | Mean IoU: 0.8537\n",
            ">>>> [Epoch: 117] Training\n",
            ">>>> [Epoch: 117] Avg. loss: 0.0891 | Mean IoU: 0.8550\n",
            ">>>> [Epoch: 118] Training\n",
            ">>>> [Epoch: 118] Avg. loss: 0.0890 | Mean IoU: 0.8551\n",
            ">>>> [Epoch: 119] Training\n",
            ">>>> [Epoch: 119] Avg. loss: 0.0886 | Mean IoU: 0.8557\n",
            ">>>> [Epoch: 119] Validation\n",
            ">>>> [Epoch: 119] Avg. loss: 0.4699 | Mean IoU: 0.7204\n",
            ">>>> [Epoch: 120] Training\n",
            ">>>> [Epoch: 120] Avg. loss: 0.0882 | Mean IoU: 0.8561\n",
            ">>>> [Epoch: 121] Training\n",
            ">>>> [Epoch: 121] Avg. loss: 0.0875 | Mean IoU: 0.8571\n",
            ">>>> [Epoch: 122] Training\n",
            ">>>> [Epoch: 122] Avg. loss: 0.0868 | Mean IoU: 0.8571\n",
            ">>>> [Epoch: 123] Training\n",
            ">>>> [Epoch: 123] Avg. loss: 0.0866 | Mean IoU: 0.8576\n",
            ">>>> [Epoch: 124] Training\n",
            ">>>> [Epoch: 124] Avg. loss: 0.0870 | Mean IoU: 0.8581\n",
            ">>>> [Epoch: 125] Training\n",
            ">>>> [Epoch: 125] Avg. loss: 0.0852 | Mean IoU: 0.8595\n",
            ">>>> [Epoch: 126] Training\n",
            ">>>> [Epoch: 126] Avg. loss: 0.0848 | Mean IoU: 0.8604\n",
            ">>>> [Epoch: 127] Training\n",
            ">>>> [Epoch: 127] Avg. loss: 0.0852 | Mean IoU: 0.8592\n",
            ">>>> [Epoch: 128] Training\n",
            ">>>> [Epoch: 128] Avg. loss: 0.0844 | Mean IoU: 0.8610\n",
            ">>>> [Epoch: 129] Training\n",
            ">>>> [Epoch: 129] Avg. loss: 0.0834 | Mean IoU: 0.8619\n",
            ">>>> [Epoch: 129] Validation\n",
            ">>>> [Epoch: 129] Avg. loss: 0.4913 | Mean IoU: 0.7204\n",
            ">>>> [Epoch: 130] Training\n",
            ">>>> [Epoch: 130] Avg. loss: 0.0828 | Mean IoU: 0.8618\n",
            ">>>> [Epoch: 131] Training\n",
            ">>>> [Epoch: 131] Avg. loss: 0.0827 | Mean IoU: 0.8629\n",
            ">>>> [Epoch: 132] Training\n",
            ">>>> [Epoch: 132] Avg. loss: 0.0820 | Mean IoU: 0.8637\n",
            ">>>> [Epoch: 133] Training\n",
            ">>>> [Epoch: 133] Avg. loss: 0.0817 | Mean IoU: 0.8632\n",
            ">>>> [Epoch: 134] Training\n",
            ">>>> [Epoch: 134] Avg. loss: 0.0813 | Mean IoU: 0.8640\n",
            ">>>> [Epoch: 135] Training\n",
            ">>>> [Epoch: 135] Avg. loss: 0.0811 | Mean IoU: 0.8647\n",
            ">>>> [Epoch: 136] Training\n",
            ">>>> [Epoch: 136] Avg. loss: 0.0808 | Mean IoU: 0.8643\n",
            ">>>> [Epoch: 137] Training\n",
            ">>>> [Epoch: 137] Avg. loss: 0.0807 | Mean IoU: 0.8649\n",
            ">>>> [Epoch: 138] Training\n",
            ">>>> [Epoch: 138] Avg. loss: 0.0802 | Mean IoU: 0.8659\n",
            ">>>> [Epoch: 139] Training\n",
            ">>>> [Epoch: 139] Avg. loss: 0.0802 | Mean IoU: 0.8660\n",
            ">>>> [Epoch: 139] Validation\n",
            ">>>> [Epoch: 139] Avg. loss: 0.4983 | Mean IoU: 0.7218\n",
            "sky: 0.9376\n",
            "building: 0.8855\n",
            "pole: 0.1397\n",
            "road: 0.9679\n",
            "pavement: 0.8615\n",
            "tree: 0.9157\n",
            "sign_symbol: 0.5210\n",
            "fence: 0.7606\n",
            "car: 0.8001\n",
            "pedestrian: 0.4588\n",
            "bicyclist: 0.6909\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 140] Training\n",
            ">>>> [Epoch: 140] Avg. loss: 0.0790 | Mean IoU: 0.8666\n",
            ">>>> [Epoch: 141] Training\n",
            ">>>> [Epoch: 141] Avg. loss: 0.0791 | Mean IoU: 0.8671\n",
            ">>>> [Epoch: 142] Training\n",
            ">>>> [Epoch: 142] Avg. loss: 0.0783 | Mean IoU: 0.8679\n",
            ">>>> [Epoch: 143] Training\n",
            ">>>> [Epoch: 143] Avg. loss: 0.0783 | Mean IoU: 0.8678\n",
            ">>>> [Epoch: 144] Training\n",
            ">>>> [Epoch: 144] Avg. loss: 0.0784 | Mean IoU: 0.8677\n",
            ">>>> [Epoch: 145] Training\n",
            ">>>> [Epoch: 145] Avg. loss: 0.0777 | Mean IoU: 0.8681\n",
            ">>>> [Epoch: 146] Training\n",
            ">>>> [Epoch: 146] Avg. loss: 0.0780 | Mean IoU: 0.8687\n",
            ">>>> [Epoch: 147] Training\n",
            ">>>> [Epoch: 147] Avg. loss: 0.0770 | Mean IoU: 0.8695\n",
            ">>>> [Epoch: 148] Training\n",
            ">>>> [Epoch: 148] Avg. loss: 0.0765 | Mean IoU: 0.8700\n",
            ">>>> [Epoch: 149] Training\n",
            ">>>> [Epoch: 149] Avg. loss: 0.0758 | Mean IoU: 0.8705\n",
            ">>>> [Epoch: 149] Validation\n",
            ">>>> [Epoch: 149] Avg. loss: 0.5252 | Mean IoU: 0.7214\n",
            ">>>> [Epoch: 150] Training\n",
            ">>>> [Epoch: 150] Avg. loss: 0.0762 | Mean IoU: 0.8709\n",
            ">>>> [Epoch: 151] Training\n",
            ">>>> [Epoch: 151] Avg. loss: 0.0759 | Mean IoU: 0.8706\n",
            ">>>> [Epoch: 152] Training\n",
            ">>>> [Epoch: 152] Avg. loss: 0.0756 | Mean IoU: 0.8714\n",
            ">>>> [Epoch: 153] Training\n",
            ">>>> [Epoch: 153] Avg. loss: 0.0751 | Mean IoU: 0.8717\n",
            ">>>> [Epoch: 154] Training\n",
            ">>>> [Epoch: 154] Avg. loss: 0.0748 | Mean IoU: 0.8722\n",
            ">>>> [Epoch: 155] Training\n",
            ">>>> [Epoch: 155] Avg. loss: 0.0744 | Mean IoU: 0.8725\n",
            ">>>> [Epoch: 156] Training\n",
            ">>>> [Epoch: 156] Avg. loss: 0.0741 | Mean IoU: 0.8728\n",
            ">>>> [Epoch: 157] Training\n",
            ">>>> [Epoch: 157] Avg. loss: 0.0737 | Mean IoU: 0.8736\n",
            ">>>> [Epoch: 158] Training\n",
            ">>>> [Epoch: 158] Avg. loss: 0.0739 | Mean IoU: 0.8731\n",
            ">>>> [Epoch: 159] Training\n",
            ">>>> [Epoch: 159] Avg. loss: 0.0736 | Mean IoU: 0.8734\n",
            ">>>> [Epoch: 159] Validation\n",
            ">>>> [Epoch: 159] Avg. loss: 0.5326 | Mean IoU: 0.7207\n",
            ">>>> [Epoch: 160] Training\n",
            ">>>> [Epoch: 160] Avg. loss: 0.0733 | Mean IoU: 0.8737\n",
            ">>>> [Epoch: 161] Training\n",
            ">>>> [Epoch: 161] Avg. loss: 0.0726 | Mean IoU: 0.8749\n",
            ">>>> [Epoch: 162] Training\n",
            ">>>> [Epoch: 162] Avg. loss: 0.0724 | Mean IoU: 0.8754\n",
            ">>>> [Epoch: 163] Training\n",
            ">>>> [Epoch: 163] Avg. loss: 0.0725 | Mean IoU: 0.8751\n",
            ">>>> [Epoch: 164] Training\n",
            ">>>> [Epoch: 164] Avg. loss: 0.0720 | Mean IoU: 0.8751\n",
            ">>>> [Epoch: 165] Training\n",
            ">>>> [Epoch: 165] Avg. loss: 0.0721 | Mean IoU: 0.8755\n",
            ">>>> [Epoch: 166] Training\n",
            ">>>> [Epoch: 166] Avg. loss: 0.0717 | Mean IoU: 0.8762\n",
            ">>>> [Epoch: 167] Training\n",
            ">>>> [Epoch: 167] Avg. loss: 0.0719 | Mean IoU: 0.8758\n",
            ">>>> [Epoch: 168] Training\n",
            ">>>> [Epoch: 168] Avg. loss: 0.0718 | Mean IoU: 0.8762\n",
            ">>>> [Epoch: 169] Training\n",
            ">>>> [Epoch: 169] Avg. loss: 0.0719 | Mean IoU: 0.8758\n",
            ">>>> [Epoch: 169] Validation\n",
            ">>>> [Epoch: 169] Avg. loss: 0.5539 | Mean IoU: 0.7240\n",
            "sky: 0.9371\n",
            "building: 0.8929\n",
            "pole: 0.1392\n",
            "road: 0.9671\n",
            "pavement: 0.8691\n",
            "tree: 0.9179\n",
            "sign_symbol: 0.5206\n",
            "fence: 0.7600\n",
            "car: 0.8096\n",
            "pedestrian: 0.4620\n",
            "bicyclist: 0.6888\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 170] Training\n",
            ">>>> [Epoch: 170] Avg. loss: 0.0709 | Mean IoU: 0.8768\n",
            ">>>> [Epoch: 171] Training\n",
            ">>>> [Epoch: 171] Avg. loss: 0.0705 | Mean IoU: 0.8775\n",
            ">>>> [Epoch: 172] Training\n",
            ">>>> [Epoch: 172] Avg. loss: 0.0705 | Mean IoU: 0.8773\n",
            ">>>> [Epoch: 173] Training\n",
            ">>>> [Epoch: 173] Avg. loss: 0.0707 | Mean IoU: 0.8773\n",
            ">>>> [Epoch: 174] Training\n",
            ">>>> [Epoch: 174] Avg. loss: 0.0700 | Mean IoU: 0.8785\n",
            ">>>> [Epoch: 175] Training\n",
            ">>>> [Epoch: 175] Avg. loss: 0.0703 | Mean IoU: 0.8781\n",
            ">>>> [Epoch: 176] Training\n",
            ">>>> [Epoch: 176] Avg. loss: 0.0699 | Mean IoU: 0.8781\n",
            ">>>> [Epoch: 177] Training\n",
            ">>>> [Epoch: 177] Avg. loss: 0.0694 | Mean IoU: 0.8787\n",
            ">>>> [Epoch: 178] Training\n",
            ">>>> [Epoch: 178] Avg. loss: 0.0697 | Mean IoU: 0.8789\n",
            ">>>> [Epoch: 179] Training\n",
            ">>>> [Epoch: 179] Avg. loss: 0.0696 | Mean IoU: 0.8784\n",
            ">>>> [Epoch: 179] Validation\n",
            ">>>> [Epoch: 179] Avg. loss: 0.5584 | Mean IoU: 0.7192\n",
            ">>>> [Epoch: 180] Training\n",
            ">>>> [Epoch: 180] Avg. loss: 0.0688 | Mean IoU: 0.8800\n",
            ">>>> [Epoch: 181] Training\n",
            ">>>> [Epoch: 181] Avg. loss: 0.0692 | Mean IoU: 0.8788\n",
            ">>>> [Epoch: 182] Training\n",
            ">>>> [Epoch: 182] Avg. loss: 0.0690 | Mean IoU: 0.8799\n",
            ">>>> [Epoch: 183] Training\n",
            ">>>> [Epoch: 183] Avg. loss: 0.0685 | Mean IoU: 0.8800\n",
            ">>>> [Epoch: 184] Training\n",
            ">>>> [Epoch: 184] Avg. loss: 0.0686 | Mean IoU: 0.8803\n",
            ">>>> [Epoch: 185] Training\n",
            ">>>> [Epoch: 185] Avg. loss: 0.0681 | Mean IoU: 0.8806\n",
            ">>>> [Epoch: 186] Training\n",
            ">>>> [Epoch: 186] Avg. loss: 0.0681 | Mean IoU: 0.8801\n",
            ">>>> [Epoch: 187] Training\n",
            ">>>> [Epoch: 187] Avg. loss: 0.0681 | Mean IoU: 0.8807\n",
            ">>>> [Epoch: 188] Training\n",
            ">>>> [Epoch: 188] Avg. loss: 0.0676 | Mean IoU: 0.8812\n",
            ">>>> [Epoch: 189] Training\n",
            ">>>> [Epoch: 189] Avg. loss: 0.0673 | Mean IoU: 0.8819\n",
            ">>>> [Epoch: 189] Validation\n",
            ">>>> [Epoch: 189] Avg. loss: 0.5811 | Mean IoU: 0.7210\n",
            ">>>> [Epoch: 190] Training\n",
            ">>>> [Epoch: 190] Avg. loss: 0.0675 | Mean IoU: 0.8814\n",
            ">>>> [Epoch: 191] Training\n",
            ">>>> [Epoch: 191] Avg. loss: 0.0675 | Mean IoU: 0.8818\n",
            ">>>> [Epoch: 192] Training\n",
            ">>>> [Epoch: 192] Avg. loss: 0.0668 | Mean IoU: 0.8820\n",
            ">>>> [Epoch: 193] Training\n",
            ">>>> [Epoch: 193] Avg. loss: 0.0669 | Mean IoU: 0.8821\n",
            ">>>> [Epoch: 194] Training\n",
            ">>>> [Epoch: 194] Avg. loss: 0.0664 | Mean IoU: 0.8828\n",
            ">>>> [Epoch: 195] Training\n",
            ">>>> [Epoch: 195] Avg. loss: 0.0667 | Mean IoU: 0.8821\n",
            ">>>> [Epoch: 196] Training\n",
            ">>>> [Epoch: 196] Avg. loss: 0.0670 | Mean IoU: 0.8823\n",
            ">>>> [Epoch: 197] Training\n",
            ">>>> [Epoch: 197] Avg. loss: 0.0669 | Mean IoU: 0.8824\n",
            ">>>> [Epoch: 198] Training\n",
            ">>>> [Epoch: 198] Avg. loss: 0.0667 | Mean IoU: 0.8829\n",
            ">>>> [Epoch: 199] Training\n",
            ">>>> [Epoch: 199] Avg. loss: 0.0662 | Mean IoU: 0.8834\n",
            ">>>> [Epoch: 199] Validation\n",
            ">>>> [Epoch: 199] Avg. loss: 0.5703 | Mean IoU: 0.7223\n",
            ">>>> [Epoch: 200] Training\n",
            ">>>> [Epoch: 200] Avg. loss: 0.0653 | Mean IoU: 0.8839\n",
            ">>>> [Epoch: 201] Training\n",
            ">>>> [Epoch: 201] Avg. loss: 0.0650 | Mean IoU: 0.8849\n",
            ">>>> [Epoch: 202] Training\n",
            ">>>> [Epoch: 202] Avg. loss: 0.0646 | Mean IoU: 0.8852\n",
            ">>>> [Epoch: 203] Training\n",
            ">>>> [Epoch: 203] Avg. loss: 0.0649 | Mean IoU: 0.8850\n",
            ">>>> [Epoch: 204] Training\n",
            ">>>> [Epoch: 204] Avg. loss: 0.0643 | Mean IoU: 0.8855\n",
            ">>>> [Epoch: 205] Training\n",
            ">>>> [Epoch: 205] Avg. loss: 0.0644 | Mean IoU: 0.8857\n",
            ">>>> [Epoch: 206] Training\n",
            ">>>> [Epoch: 206] Avg. loss: 0.0643 | Mean IoU: 0.8858\n",
            ">>>> [Epoch: 207] Training\n",
            ">>>> [Epoch: 207] Avg. loss: 0.0645 | Mean IoU: 0.8857\n",
            ">>>> [Epoch: 208] Training\n",
            ">>>> [Epoch: 208] Avg. loss: 0.0642 | Mean IoU: 0.8862\n",
            ">>>> [Epoch: 209] Training\n",
            ">>>> [Epoch: 209] Avg. loss: 0.0640 | Mean IoU: 0.8860\n",
            ">>>> [Epoch: 209] Validation\n",
            ">>>> [Epoch: 209] Avg. loss: 0.5907 | Mean IoU: 0.7221\n",
            ">>>> [Epoch: 210] Training\n",
            ">>>> [Epoch: 210] Avg. loss: 0.0639 | Mean IoU: 0.8863\n",
            ">>>> [Epoch: 211] Training\n",
            ">>>> [Epoch: 211] Avg. loss: 0.0642 | Mean IoU: 0.8862\n",
            ">>>> [Epoch: 212] Training\n",
            ">>>> [Epoch: 212] Avg. loss: 0.0639 | Mean IoU: 0.8864\n",
            ">>>> [Epoch: 213] Training\n",
            ">>>> [Epoch: 213] Avg. loss: 0.0639 | Mean IoU: 0.8864\n",
            ">>>> [Epoch: 214] Training\n",
            ">>>> [Epoch: 214] Avg. loss: 0.0639 | Mean IoU: 0.8861\n",
            ">>>> [Epoch: 215] Training\n",
            ">>>> [Epoch: 215] Avg. loss: 0.0637 | Mean IoU: 0.8864\n",
            ">>>> [Epoch: 216] Training\n",
            ">>>> [Epoch: 216] Avg. loss: 0.0637 | Mean IoU: 0.8863\n",
            ">>>> [Epoch: 217] Training\n",
            ">>>> [Epoch: 217] Avg. loss: 0.0639 | Mean IoU: 0.8868\n",
            ">>>> [Epoch: 218] Training\n",
            ">>>> [Epoch: 218] Avg. loss: 0.0636 | Mean IoU: 0.8865\n",
            ">>>> [Epoch: 219] Training\n",
            ">>>> [Epoch: 219] Avg. loss: 0.0639 | Mean IoU: 0.8863\n",
            ">>>> [Epoch: 219] Validation\n",
            ">>>> [Epoch: 219] Avg. loss: 0.5856 | Mean IoU: 0.7216\n",
            ">>>> [Epoch: 220] Training\n",
            ">>>> [Epoch: 220] Avg. loss: 0.0635 | Mean IoU: 0.8868\n",
            ">>>> [Epoch: 221] Training\n",
            ">>>> [Epoch: 221] Avg. loss: 0.0639 | Mean IoU: 0.8864\n",
            ">>>> [Epoch: 222] Training\n",
            ">>>> [Epoch: 222] Avg. loss: 0.0635 | Mean IoU: 0.8866\n",
            ">>>> [Epoch: 223] Training\n",
            ">>>> [Epoch: 223] Avg. loss: 0.0635 | Mean IoU: 0.8866\n",
            ">>>> [Epoch: 224] Training\n",
            ">>>> [Epoch: 224] Avg. loss: 0.0638 | Mean IoU: 0.8866\n",
            ">>>> [Epoch: 225] Training\n",
            ">>>> [Epoch: 225] Avg. loss: 0.0638 | Mean IoU: 0.8868\n",
            ">>>> [Epoch: 226] Training\n",
            ">>>> [Epoch: 226] Avg. loss: 0.0634 | Mean IoU: 0.8870\n",
            ">>>> [Epoch: 227] Training\n",
            ">>>> [Epoch: 227] Avg. loss: 0.0635 | Mean IoU: 0.8871\n",
            ">>>> [Epoch: 228] Training\n",
            ">>>> [Epoch: 228] Avg. loss: 0.0637 | Mean IoU: 0.8868\n",
            ">>>> [Epoch: 229] Training\n",
            ">>>> [Epoch: 229] Avg. loss: 0.0634 | Mean IoU: 0.8869\n",
            ">>>> [Epoch: 229] Validation\n",
            ">>>> [Epoch: 229] Avg. loss: 0.5986 | Mean IoU: 0.7199\n",
            ">>>> [Epoch: 230] Training\n",
            ">>>> [Epoch: 230] Avg. loss: 0.0639 | Mean IoU: 0.8862\n",
            ">>>> [Epoch: 231] Training\n",
            ">>>> [Epoch: 231] Avg. loss: 0.0635 | Mean IoU: 0.8868\n",
            ">>>> [Epoch: 232] Training\n",
            ">>>> [Epoch: 232] Avg. loss: 0.0635 | Mean IoU: 0.8873\n",
            ">>>> [Epoch: 233] Training\n",
            ">>>> [Epoch: 233] Avg. loss: 0.0635 | Mean IoU: 0.8868\n",
            ">>>> [Epoch: 234] Training\n",
            ">>>> [Epoch: 234] Avg. loss: 0.0634 | Mean IoU: 0.8871\n",
            ">>>> [Epoch: 235] Training\n",
            ">>>> [Epoch: 235] Avg. loss: 0.0633 | Mean IoU: 0.8869\n",
            ">>>> [Epoch: 236] Training\n",
            ">>>> [Epoch: 236] Avg. loss: 0.0633 | Mean IoU: 0.8871\n",
            ">>>> [Epoch: 237] Training\n",
            ">>>> [Epoch: 237] Avg. loss: 0.0634 | Mean IoU: 0.8875\n",
            ">>>> [Epoch: 238] Training\n",
            ">>>> [Epoch: 238] Avg. loss: 0.0633 | Mean IoU: 0.8872\n",
            ">>>> [Epoch: 239] Training\n",
            ">>>> [Epoch: 239] Avg. loss: 0.0632 | Mean IoU: 0.8874\n",
            ">>>> [Epoch: 239] Validation\n",
            ">>>> [Epoch: 239] Avg. loss: 0.5937 | Mean IoU: 0.7207\n",
            ">>>> [Epoch: 240] Training\n",
            ">>>> [Epoch: 240] Avg. loss: 0.0634 | Mean IoU: 0.8870\n",
            ">>>> [Epoch: 241] Training\n",
            ">>>> [Epoch: 241] Avg. loss: 0.0633 | Mean IoU: 0.8869\n",
            ">>>> [Epoch: 242] Training\n",
            ">>>> [Epoch: 242] Avg. loss: 0.0632 | Mean IoU: 0.8877\n",
            ">>>> [Epoch: 243] Training\n",
            ">>>> [Epoch: 243] Avg. loss: 0.0634 | Mean IoU: 0.8872\n",
            ">>>> [Epoch: 244] Training\n",
            ">>>> [Epoch: 244] Avg. loss: 0.0634 | Mean IoU: 0.8870\n",
            ">>>> [Epoch: 245] Training\n",
            ">>>> [Epoch: 245] Avg. loss: 0.0632 | Mean IoU: 0.8872\n",
            ">>>> [Epoch: 246] Training\n",
            ">>>> [Epoch: 246] Avg. loss: 0.0635 | Mean IoU: 0.8871\n",
            ">>>> [Epoch: 247] Training\n",
            ">>>> [Epoch: 247] Avg. loss: 0.0632 | Mean IoU: 0.8876\n",
            ">>>> [Epoch: 248] Training\n",
            ">>>> [Epoch: 248] Avg. loss: 0.0628 | Mean IoU: 0.8877\n",
            ">>>> [Epoch: 249] Training\n",
            ">>>> [Epoch: 249] Avg. loss: 0.0628 | Mean IoU: 0.8882\n",
            ">>>> [Epoch: 249] Validation\n",
            ">>>> [Epoch: 249] Avg. loss: 0.6098 | Mean IoU: 0.7204\n",
            ">>>> [Epoch: 250] Training\n",
            ">>>> [Epoch: 250] Avg. loss: 0.0632 | Mean IoU: 0.8873\n",
            ">>>> [Epoch: 251] Training\n",
            ">>>> [Epoch: 251] Avg. loss: 0.0629 | Mean IoU: 0.8877\n",
            ">>>> [Epoch: 252] Training\n",
            ">>>> [Epoch: 252] Avg. loss: 0.0630 | Mean IoU: 0.8879\n",
            ">>>> [Epoch: 253] Training\n",
            ">>>> [Epoch: 253] Avg. loss: 0.0626 | Mean IoU: 0.8876\n",
            ">>>> [Epoch: 254] Training\n",
            ">>>> [Epoch: 254] Avg. loss: 0.0631 | Mean IoU: 0.8876\n",
            ">>>> [Epoch: 255] Training\n",
            ">>>> [Epoch: 255] Avg. loss: 0.0628 | Mean IoU: 0.8877\n",
            ">>>> [Epoch: 256] Training\n",
            ">>>> [Epoch: 256] Avg. loss: 0.0629 | Mean IoU: 0.8876\n",
            ">>>> [Epoch: 257] Training\n",
            ">>>> [Epoch: 257] Avg. loss: 0.0628 | Mean IoU: 0.8878\n",
            ">>>> [Epoch: 258] Training\n",
            ">>>> [Epoch: 258] Avg. loss: 0.0629 | Mean IoU: 0.8879\n",
            ">>>> [Epoch: 259] Training\n",
            ">>>> [Epoch: 259] Avg. loss: 0.0630 | Mean IoU: 0.8875\n",
            ">>>> [Epoch: 259] Validation\n",
            ">>>> [Epoch: 259] Avg. loss: 0.6026 | Mean IoU: 0.7216\n",
            ">>>> [Epoch: 260] Training\n",
            ">>>> [Epoch: 260] Avg. loss: 0.0626 | Mean IoU: 0.8880\n",
            ">>>> [Epoch: 261] Training\n",
            ">>>> [Epoch: 261] Avg. loss: 0.0627 | Mean IoU: 0.8880\n",
            ">>>> [Epoch: 262] Training\n",
            ">>>> [Epoch: 262] Avg. loss: 0.0629 | Mean IoU: 0.8880\n",
            ">>>> [Epoch: 263] Training\n",
            ">>>> [Epoch: 263] Avg. loss: 0.0625 | Mean IoU: 0.8878\n",
            ">>>> [Epoch: 264] Training\n",
            ">>>> [Epoch: 264] Avg. loss: 0.0625 | Mean IoU: 0.8881\n",
            ">>>> [Epoch: 265] Training\n",
            ">>>> [Epoch: 265] Avg. loss: 0.0629 | Mean IoU: 0.8880\n",
            ">>>> [Epoch: 266] Training\n",
            ">>>> [Epoch: 266] Avg. loss: 0.0626 | Mean IoU: 0.8881\n",
            ">>>> [Epoch: 267] Training\n",
            ">>>> [Epoch: 267] Avg. loss: 0.0628 | Mean IoU: 0.8879\n",
            ">>>> [Epoch: 268] Training\n",
            ">>>> [Epoch: 268] Avg. loss: 0.0627 | Mean IoU: 0.8881\n",
            ">>>> [Epoch: 269] Training\n",
            ">>>> [Epoch: 269] Avg. loss: 0.0625 | Mean IoU: 0.8879\n",
            ">>>> [Epoch: 269] Validation\n",
            ">>>> [Epoch: 269] Avg. loss: 0.6097 | Mean IoU: 0.7202\n",
            ">>>> [Epoch: 270] Training\n",
            ">>>> [Epoch: 270] Avg. loss: 0.0627 | Mean IoU: 0.8886\n",
            ">>>> [Epoch: 271] Training\n",
            ">>>> [Epoch: 271] Avg. loss: 0.0629 | Mean IoU: 0.8875\n",
            ">>>> [Epoch: 272] Training\n",
            ">>>> [Epoch: 272] Avg. loss: 0.0624 | Mean IoU: 0.8885\n",
            ">>>> [Epoch: 273] Training\n",
            ">>>> [Epoch: 273] Avg. loss: 0.0626 | Mean IoU: 0.8882\n",
            ">>>> [Epoch: 274] Training\n",
            ">>>> [Epoch: 274] Avg. loss: 0.0625 | Mean IoU: 0.8880\n",
            ">>>> [Epoch: 275] Training\n",
            ">>>> [Epoch: 275] Avg. loss: 0.0624 | Mean IoU: 0.8883\n",
            ">>>> [Epoch: 276] Training\n",
            ">>>> [Epoch: 276] Avg. loss: 0.0623 | Mean IoU: 0.8886\n",
            ">>>> [Epoch: 277] Training\n",
            ">>>> [Epoch: 277] Avg. loss: 0.0623 | Mean IoU: 0.8883\n",
            ">>>> [Epoch: 278] Training\n",
            ">>>> [Epoch: 278] Avg. loss: 0.0628 | Mean IoU: 0.8884\n",
            ">>>> [Epoch: 279] Training\n",
            ">>>> [Epoch: 279] Avg. loss: 0.0624 | Mean IoU: 0.8884\n",
            ">>>> [Epoch: 279] Validation\n",
            ">>>> [Epoch: 279] Avg. loss: 0.6081 | Mean IoU: 0.7202\n",
            ">>>> [Epoch: 280] Training\n",
            ">>>> [Epoch: 280] Avg. loss: 0.0622 | Mean IoU: 0.8885\n",
            ">>>> [Epoch: 281] Training\n",
            ">>>> [Epoch: 281] Avg. loss: 0.0622 | Mean IoU: 0.8887\n",
            ">>>> [Epoch: 282] Training\n",
            ">>>> [Epoch: 282] Avg. loss: 0.0623 | Mean IoU: 0.8885\n",
            ">>>> [Epoch: 283] Training\n",
            ">>>> [Epoch: 283] Avg. loss: 0.0624 | Mean IoU: 0.8883\n",
            ">>>> [Epoch: 284] Training\n",
            ">>>> [Epoch: 284] Avg. loss: 0.0625 | Mean IoU: 0.8884\n",
            ">>>> [Epoch: 285] Training\n",
            ">>>> [Epoch: 285] Avg. loss: 0.0621 | Mean IoU: 0.8886\n",
            ">>>> [Epoch: 286] Training\n",
            ">>>> [Epoch: 286] Avg. loss: 0.0623 | Mean IoU: 0.8884\n",
            ">>>> [Epoch: 287] Training\n",
            ">>>> [Epoch: 287] Avg. loss: 0.0623 | Mean IoU: 0.8885\n",
            ">>>> [Epoch: 288] Training\n",
            ">>>> [Epoch: 288] Avg. loss: 0.0623 | Mean IoU: 0.8888\n",
            ">>>> [Epoch: 289] Training\n",
            ">>>> [Epoch: 289] Avg. loss: 0.0620 | Mean IoU: 0.8887\n",
            ">>>> [Epoch: 289] Validation\n",
            ">>>> [Epoch: 289] Avg. loss: 0.6175 | Mean IoU: 0.7187\n",
            ">>>> [Epoch: 290] Training\n",
            ">>>> [Epoch: 290] Avg. loss: 0.0620 | Mean IoU: 0.8887\n",
            ">>>> [Epoch: 291] Training\n",
            ">>>> [Epoch: 291] Avg. loss: 0.0625 | Mean IoU: 0.8884\n",
            ">>>> [Epoch: 292] Training\n",
            ">>>> [Epoch: 292] Avg. loss: 0.0620 | Mean IoU: 0.8888\n",
            ">>>> [Epoch: 293] Training\n",
            ">>>> [Epoch: 293] Avg. loss: 0.0622 | Mean IoU: 0.8886\n",
            ">>>> [Epoch: 294] Training\n",
            ">>>> [Epoch: 294] Avg. loss: 0.0624 | Mean IoU: 0.8883\n",
            ">>>> [Epoch: 295] Training\n",
            ">>>> [Epoch: 295] Avg. loss: 0.0620 | Mean IoU: 0.8889\n",
            ">>>> [Epoch: 296] Training\n",
            ">>>> [Epoch: 296] Avg. loss: 0.0620 | Mean IoU: 0.8890\n",
            ">>>> [Epoch: 297] Training\n",
            ">>>> [Epoch: 297] Avg. loss: 0.0623 | Mean IoU: 0.8888\n",
            ">>>> [Epoch: 298] Training\n",
            ">>>> [Epoch: 298] Avg. loss: 0.0623 | Mean IoU: 0.8881\n",
            ">>>> [Epoch: 299] Training\n",
            ">>>> [Epoch: 299] Avg. loss: 0.0624 | Mean IoU: 0.8886\n",
            ">>>> [Epoch: 299] Validation\n",
            ">>>> [Epoch: 299] Avg. loss: 0.6205 | Mean IoU: 0.7177\n",
            "sky: 0.9343\n",
            "building: 0.8857\n",
            "pole: 0.1375\n",
            "road: 0.9679\n",
            "pavement: 0.8674\n",
            "tree: 0.9147\n",
            "sign_symbol: 0.5097\n",
            "fence: 0.7540\n",
            "car: 0.7942\n",
            "pedestrian: 0.4533\n",
            "bicyclist: 0.6767\n",
            "unlabeled: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -m test --save-dir save/ --dataset camvid --dataset-dir ../CamVid2/ --name BiSeNet2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr3k6lM9S4-b",
        "outputId": "be71835a-b17e-4a95-e568-e2d4b05085e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: ../CamVid2/\n",
            "Save directory: save/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 640, 480])\n",
            "Label size: torch.Size([10, 640, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0252,  3.4468, 15.9117,  9.0204, 32.0129, 32.4791,\n",
            "        13.2076, 38.3884, 44.1342,  0.0000], device='cuda:0')\n",
            "################################save/BiSeNet2#####################\n",
            "BiSeNetV2(\n",
            "  (detail): DetailBranch(\n",
            "    (S1): Sequential(\n",
            "      (0): ConvBNReLU(\n",
            "        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): ConvBNReLU(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S2): Sequential(\n",
            "      (0): ConvBNReLU(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): ConvBNReLU(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): ConvBNReLU(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S3): Sequential(\n",
            "      (0): ConvBNReLU(\n",
            "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): ConvBNReLU(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): ConvBNReLU(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (segment): SegmentBranch(\n",
            "    (S1S2): StemBlock(\n",
            "      (conv): ConvBNReLU(\n",
            "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (left): Sequential(\n",
            "        (0): ConvBNReLU(\n",
            "          (conv): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvBNReLU(\n",
            "          (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (right): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (fuse): ConvBNReLU(\n",
            "        (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S3): Sequential(\n",
            "      (0): GELayerS2(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv1): Sequential(\n",
            "          (0): Conv2d(16, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (dwconv2): Sequential(\n",
            "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
            "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): GELayerS1(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv): Sequential(\n",
            "          (0): Conv2d(32, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S4): Sequential(\n",
            "      (0): GELayerS2(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv1): Sequential(\n",
            "          (0): Conv2d(32, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (dwconv2): Sequential(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): GELayerS1(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv): Sequential(\n",
            "          (0): Conv2d(64, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S5_4): Sequential(\n",
            "      (0): GELayerS2(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv1): Sequential(\n",
            "          (0): Conv2d(64, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (dwconv2): Sequential(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): GELayerS1(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv): Sequential(\n",
            "          (0): Conv2d(128, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): GELayerS1(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv): Sequential(\n",
            "          (0): Conv2d(128, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): GELayerS1(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv): Sequential(\n",
            "          (0): Conv2d(128, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S5_5): CEBlock(\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv_gap): ConvBNReLU(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv_last): ConvBNReLU(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (bga): BGALayer(\n",
            "    (left1): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (left2): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "    )\n",
            "    (right1): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (right2): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (up1): Upsample(scale_factor=4.0, mode=nearest)\n",
            "    (up2): Upsample(scale_factor=4.0, mode=nearest)\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (head): SegmentHead(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(128, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (conv_out): Sequential(\n",
            "      (0): Identity()\n",
            "      (1): Conv2d(1024, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Upsample(scale_factor=8.0, mode=bilinear)\n",
            "    )\n",
            "  )\n",
            "  (aux2): SegmentHead(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (conv_out): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "        (1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Conv2d(16, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "    )\n",
            "  )\n",
            "  (aux3): SegmentHead(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (conv_out): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "        (1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Conv2d(64, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Upsample(scale_factor=4.0, mode=bilinear)\n",
            "    )\n",
            "  )\n",
            "  (aux4): SegmentHead(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (conv_out): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "        (1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Upsample(scale_factor=8.0, mode=bilinear)\n",
            "    )\n",
            "  )\n",
            "  (aux5_4): SegmentHead(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (conv_out): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "        (1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Conv2d(1024, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Upsample(scale_factor=16.0, mode=bilinear)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "Testing...\n",
            "\n",
            ">>>> Running test dataset\n",
            ">>>> Avg. loss: 1.1579 | Mean IoU: 0.6143\n",
            "sky: 0.9053\n",
            "building: 0.7994\n",
            "pole: 0.2184\n",
            "road: 0.9367\n",
            "pavement: 0.8040\n",
            "tree: 0.7435\n",
            "sign_symbol: 0.3628\n",
            "fence: 0.3844\n",
            "car: 0.7733\n",
            "pedestrian: 0.4286\n",
            "bicyclist: 0.4008\n",
            "unlabeled: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -m test --save-dir save/ --dataset camvid --dataset-dir CamVid2/ --name BiSeNet2v170 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YR_LC5NnaJ3",
        "outputId": "c3732d96-6f60-48cd-955c-46494ff7d5e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: CamVid2/\n",
            "Save directory: save/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 640, 480])\n",
            "Label size: torch.Size([10, 640, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0252,  3.4468, 15.9117,  9.0204, 32.0129, 32.4791,\n",
            "        13.2076, 38.3884, 44.1342,  0.0000], device='cuda:0')\n",
            "Downloading: \"https://github.com/CoinCheung/BiSeNet/releases/download/0.0.0/backbone_v2.pth\" to /root/.cache/torch/hub/checkpoints/backbone_v2.pth\n",
            "100% 8.34M/8.34M [00:00<00:00, 10.5MB/s]\n",
            "################################save/BiSeNet2v170#####################\n",
            "BiSeNetV2(\n",
            "  (detail): DetailBranch(\n",
            "    (S1): Sequential(\n",
            "      (0): ConvBNReLU(\n",
            "        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): ConvBNReLU(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S2): Sequential(\n",
            "      (0): ConvBNReLU(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): ConvBNReLU(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): ConvBNReLU(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S3): Sequential(\n",
            "      (0): ConvBNReLU(\n",
            "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): ConvBNReLU(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): ConvBNReLU(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (segment): SegmentBranch(\n",
            "    (S1S2): StemBlock(\n",
            "      (conv): ConvBNReLU(\n",
            "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (left): Sequential(\n",
            "        (0): ConvBNReLU(\n",
            "          (conv): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvBNReLU(\n",
            "          (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (right): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (fuse): ConvBNReLU(\n",
            "        (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S3): Sequential(\n",
            "      (0): GELayerS2(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv1): Sequential(\n",
            "          (0): Conv2d(16, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (dwconv2): Sequential(\n",
            "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
            "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): GELayerS1(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv): Sequential(\n",
            "          (0): Conv2d(32, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S4): Sequential(\n",
            "      (0): GELayerS2(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv1): Sequential(\n",
            "          (0): Conv2d(32, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (dwconv2): Sequential(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): GELayerS1(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv): Sequential(\n",
            "          (0): Conv2d(64, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S5_4): Sequential(\n",
            "      (0): GELayerS2(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv1): Sequential(\n",
            "          (0): Conv2d(64, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (dwconv2): Sequential(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): GELayerS1(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv): Sequential(\n",
            "          (0): Conv2d(128, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): GELayerS1(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv): Sequential(\n",
            "          (0): Conv2d(128, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): GELayerS1(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv): Sequential(\n",
            "          (0): Conv2d(128, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S5_5): CEBlock(\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv_gap): ConvBNReLU(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv_last): ConvBNReLU(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (bga): BGALayer(\n",
            "    (left1): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (left2): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "    )\n",
            "    (right1): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (right2): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (up1): Upsample(scale_factor=4.0, mode=nearest)\n",
            "    (up2): Upsample(scale_factor=4.0, mode=nearest)\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (head): SegmentHead(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(128, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (conv_out): Sequential(\n",
            "      (0): Identity()\n",
            "      (1): Conv2d(1024, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Upsample(scale_factor=8.0, mode=bilinear)\n",
            "    )\n",
            "  )\n",
            "  (aux2): SegmentHead(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (conv_out): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "        (1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Conv2d(16, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "    )\n",
            "  )\n",
            "  (aux3): SegmentHead(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (conv_out): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "        (1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Conv2d(64, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Upsample(scale_factor=4.0, mode=bilinear)\n",
            "    )\n",
            "  )\n",
            "  (aux4): SegmentHead(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (conv_out): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "        (1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Upsample(scale_factor=8.0, mode=bilinear)\n",
            "    )\n",
            "  )\n",
            "  (aux5_4): SegmentHead(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (conv_out): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "        (1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Conv2d(1024, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Upsample(scale_factor=16.0, mode=bilinear)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "Testing...\n",
            "\n",
            ">>>> Running test dataset\n",
            ">>>> Avg. loss: 1.1579 | Mean IoU: 0.6143\n",
            "sky: 0.9053\n",
            "building: 0.7994\n",
            "pole: 0.2184\n",
            "road: 0.9367\n",
            "pavement: 0.8040\n",
            "tree: 0.7435\n",
            "sign_symbol: 0.3628\n",
            "fence: 0.3844\n",
            "car: 0.7733\n",
            "pedestrian: 0.4286\n",
            "bicyclist: 0.4008\n",
            "unlabeled: nan\n",
            "A batch of predictions from the test set...\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<Figure size 1500x700 with 2 Axes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py -m train --save-dir save/ --dataset camvid --dataset-dir CamVid2/ --name BiSeNet2 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lyd458FLaaES",
        "outputId": "7f290115-28f3-478b-f757-a084189580a1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: CamVid2/\n",
            "Save directory: save/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 640, 480])\n",
            "Label size: torch.Size([10, 640, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0252,  3.4468, 15.9117,  9.0204, 32.0129, 32.4791,\n",
            "        13.2076, 38.3884, 44.1342,  0.0000], device='cuda:0')\n",
            "\n",
            "Training...\n",
            "\n",
            "Downloading: \"https://github.com/CoinCheung/BiSeNet/releases/download/0.0.0/backbone_v2.pth\" to /root/.cache/torch/hub/checkpoints/backbone_v2.pth\n",
            "100% 8.34M/8.34M [00:00<00:00, 71.6MB/s]\n",
            "################################save/BiSeNet2#####################\n",
            "Resuming from model: Start epoch = 50 | Best mean IoU = 0.6364\n",
            "\n",
            ">>>> [Epoch: 50] Training\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            ">>>> [Epoch: 50] Avg. loss: 0.1853 | Mean IoU: 0.7291\n",
            ">>>> [Epoch: 51] Training\n",
            ">>>> [Epoch: 51] Avg. loss: 0.1606 | Mean IoU: 0.7326\n",
            ">>>> [Epoch: 52] Training\n",
            ">>>> [Epoch: 52] Avg. loss: 0.1569 | Mean IoU: 0.7328\n",
            ">>>> [Epoch: 53] Training\n",
            ">>>> [Epoch: 53] Avg. loss: 0.1647 | Mean IoU: 0.7326\n",
            ">>>> [Epoch: 54] Training\n",
            ">>>> [Epoch: 54] Avg. loss: 0.1509 | Mean IoU: 0.7367\n",
            ">>>> [Epoch: 55] Training\n",
            ">>>> [Epoch: 55] Avg. loss: 0.1667 | Mean IoU: 0.7353\n",
            ">>>> [Epoch: 56] Training\n",
            ">>>> [Epoch: 56] Avg. loss: 0.1658 | Mean IoU: 0.7395\n",
            ">>>> [Epoch: 57] Training\n",
            ">>>> [Epoch: 57] Avg. loss: 0.1688 | Mean IoU: 0.7343\n",
            ">>>> [Epoch: 58] Training\n",
            ">>>> [Epoch: 58] Avg. loss: 0.1531 | Mean IoU: 0.7402\n",
            ">>>> [Epoch: 59] Training\n",
            ">>>> [Epoch: 59] Avg. loss: 0.1583 | Mean IoU: 0.7419\n",
            ">>>> [Epoch: 59] Validation\n",
            ">>>> [Epoch: 59] Avg. loss: 0.5805 | Mean IoU: 0.6347\n",
            ">>>> [Epoch: 60] Training\n",
            ">>>> [Epoch: 60] Avg. loss: 0.1653 | Mean IoU: 0.7425\n",
            ">>>> [Epoch: 61] Training\n",
            ">>>> [Epoch: 61] Avg. loss: 0.1660 | Mean IoU: 0.7448\n",
            ">>>> [Epoch: 62] Training\n",
            ">>>> [Epoch: 62] Avg. loss: 0.1573 | Mean IoU: 0.7439\n",
            ">>>> [Epoch: 63] Training\n",
            ">>>> [Epoch: 63] Avg. loss: 0.1601 | Mean IoU: 0.7457\n",
            ">>>> [Epoch: 64] Training\n",
            ">>>> [Epoch: 64] Avg. loss: 0.1559 | Mean IoU: 0.7481\n",
            ">>>> [Epoch: 65] Training\n",
            ">>>> [Epoch: 65] Avg. loss: 0.1462 | Mean IoU: 0.7486\n",
            ">>>> [Epoch: 66] Training\n",
            ">>>> [Epoch: 66] Avg. loss: 0.1577 | Mean IoU: 0.7490\n",
            ">>>> [Epoch: 67] Training\n",
            ">>>> [Epoch: 67] Avg. loss: 0.1774 | Mean IoU: 0.7489\n",
            ">>>> [Epoch: 68] Training\n",
            ">>>> [Epoch: 68] Avg. loss: 0.1697 | Mean IoU: 0.7495\n",
            ">>>> [Epoch: 69] Training\n",
            ">>>> [Epoch: 69] Avg. loss: 0.1562 | Mean IoU: 0.7514\n",
            ">>>> [Epoch: 69] Validation\n",
            ">>>> [Epoch: 69] Avg. loss: 0.5574 | Mean IoU: 0.6446\n",
            "sky: 0.9369\n",
            "building: 0.8596\n",
            "pole: 0.0348\n",
            "road: 0.9539\n",
            "pavement: 0.8282\n",
            "tree: 0.8846\n",
            "sign_symbol: 0.3992\n",
            "fence: 0.5541\n",
            "car: 0.7827\n",
            "pedestrian: 0.3414\n",
            "bicyclist: 0.5156\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 70] Training\n",
            ">>>> [Epoch: 70] Avg. loss: 0.1550 | Mean IoU: 0.7571\n",
            ">>>> [Epoch: 71] Training\n",
            ">>>> [Epoch: 71] Avg. loss: 0.1639 | Mean IoU: 0.7540\n",
            ">>>> [Epoch: 72] Training\n",
            ">>>> [Epoch: 72] Avg. loss: 0.1522 | Mean IoU: 0.7581\n",
            ">>>> [Epoch: 73] Training\n",
            ">>>> [Epoch: 73] Avg. loss: 0.1519 | Mean IoU: 0.7545\n",
            ">>>> [Epoch: 74] Training\n",
            ">>>> [Epoch: 74] Avg. loss: 0.1505 | Mean IoU: 0.7529\n",
            ">>>> [Epoch: 75] Training\n",
            ">>>> [Epoch: 75] Avg. loss: 0.1536 | Mean IoU: 0.7590\n",
            ">>>> [Epoch: 76] Training\n",
            ">>>> [Epoch: 76] Avg. loss: 0.1479 | Mean IoU: 0.7585\n",
            ">>>> [Epoch: 77] Training\n",
            ">>>> [Epoch: 77] Avg. loss: 0.1553 | Mean IoU: 0.7610\n",
            ">>>> [Epoch: 78] Training\n",
            ">>>> [Epoch: 78] Avg. loss: 0.1498 | Mean IoU: 0.7618\n",
            ">>>> [Epoch: 79] Training\n",
            ">>>> [Epoch: 79] Avg. loss: 0.1506 | Mean IoU: 0.7639\n",
            ">>>> [Epoch: 79] Validation\n",
            ">>>> [Epoch: 79] Avg. loss: 0.5567 | Mean IoU: 0.6478\n",
            "sky: 0.9383\n",
            "building: 0.8714\n",
            "pole: 0.0383\n",
            "road: 0.9556\n",
            "pavement: 0.8387\n",
            "tree: 0.8903\n",
            "sign_symbol: 0.4104\n",
            "fence: 0.5834\n",
            "car: 0.7899\n",
            "pedestrian: 0.3350\n",
            "bicyclist: 0.4741\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 80] Training\n",
            ">>>> [Epoch: 80] Avg. loss: 0.1562 | Mean IoU: 0.7613\n",
            ">>>> [Epoch: 81] Training\n",
            ">>>> [Epoch: 81] Avg. loss: 0.1483 | Mean IoU: 0.7626\n",
            ">>>> [Epoch: 82] Training\n",
            ">>>> [Epoch: 82] Avg. loss: 0.1719 | Mean IoU: 0.7627\n",
            ">>>> [Epoch: 83] Training\n",
            ">>>> [Epoch: 83] Avg. loss: 0.1525 | Mean IoU: 0.7663\n",
            ">>>> [Epoch: 84] Training\n",
            ">>>> [Epoch: 84] Avg. loss: 0.1701 | Mean IoU: 0.7651\n",
            ">>>> [Epoch: 85] Training\n",
            ">>>> [Epoch: 85] Avg. loss: 0.1594 | Mean IoU: 0.7683\n",
            ">>>> [Epoch: 86] Training\n",
            ">>>> [Epoch: 86] Avg. loss: 0.1401 | Mean IoU: 0.7670\n",
            ">>>> [Epoch: 87] Training\n",
            ">>>> [Epoch: 87] Avg. loss: 0.1581 | Mean IoU: 0.7682\n",
            ">>>> [Epoch: 88] Training\n",
            ">>>> [Epoch: 88] Avg. loss: 0.1557 | Mean IoU: 0.7678\n",
            ">>>> [Epoch: 89] Training\n",
            ">>>> [Epoch: 89] Avg. loss: 0.1674 | Mean IoU: 0.7699\n",
            ">>>> [Epoch: 89] Validation\n",
            ">>>> [Epoch: 89] Avg. loss: 0.5733 | Mean IoU: 0.6442\n",
            ">>>> [Epoch: 90] Training\n",
            ">>>> [Epoch: 90] Avg. loss: 0.1433 | Mean IoU: 0.7686\n",
            ">>>> [Epoch: 91] Training\n",
            ">>>> [Epoch: 91] Avg. loss: 0.1466 | Mean IoU: 0.7691\n",
            ">>>> [Epoch: 92] Training\n",
            ">>>> [Epoch: 92] Avg. loss: 0.1477 | Mean IoU: 0.7711\n",
            ">>>> [Epoch: 93] Training\n",
            ">>>> [Epoch: 93] Avg. loss: 0.1518 | Mean IoU: 0.7721\n",
            ">>>> [Epoch: 94] Training\n",
            ">>>> [Epoch: 94] Avg. loss: 0.1506 | Mean IoU: 0.7721\n",
            ">>>> [Epoch: 95] Training\n",
            ">>>> [Epoch: 95] Avg. loss: 0.1592 | Mean IoU: 0.7736\n",
            ">>>> [Epoch: 96] Training\n",
            ">>>> [Epoch: 96] Avg. loss: 0.1549 | Mean IoU: 0.7736\n",
            ">>>> [Epoch: 97] Training\n",
            ">>>> [Epoch: 97] Avg. loss: 0.1526 | Mean IoU: 0.7719\n",
            ">>>> [Epoch: 98] Training\n",
            ">>>> [Epoch: 98] Avg. loss: 0.1446 | Mean IoU: 0.7739\n",
            ">>>> [Epoch: 99] Training\n",
            ">>>> [Epoch: 99] Avg. loss: 0.1549 | Mean IoU: 0.7791\n",
            ">>>> [Epoch: 99] Validation\n",
            ">>>> [Epoch: 99] Avg. loss: 0.5779 | Mean IoU: 0.6435\n",
            ">>>> [Epoch: 100] Training\n",
            ">>>> [Epoch: 100] Avg. loss: 0.1566 | Mean IoU: 0.7786\n",
            ">>>> [Epoch: 101] Training\n",
            ">>>> [Epoch: 101] Avg. loss: 0.1552 | Mean IoU: 0.7804\n",
            ">>>> [Epoch: 102] Training\n",
            ">>>> [Epoch: 102] Avg. loss: 0.1532 | Mean IoU: 0.7775\n",
            ">>>> [Epoch: 103] Training\n",
            ">>>> [Epoch: 103] Avg. loss: 0.1470 | Mean IoU: 0.7795\n",
            ">>>> [Epoch: 104] Training\n",
            ">>>> [Epoch: 104] Avg. loss: 0.1463 | Mean IoU: 0.7762\n",
            ">>>> [Epoch: 105] Training\n",
            ">>>> [Epoch: 105] Avg. loss: 0.1541 | Mean IoU: 0.7806\n",
            ">>>> [Epoch: 106] Training\n",
            ">>>> [Epoch: 106] Avg. loss: 0.1536 | Mean IoU: 0.7812\n",
            ">>>> [Epoch: 107] Training\n",
            ">>>> [Epoch: 107] Avg. loss: 0.1531 | Mean IoU: 0.7826\n",
            ">>>> [Epoch: 108] Training\n",
            ">>>> [Epoch: 108] Avg. loss: 0.1539 | Mean IoU: 0.7819\n",
            ">>>> [Epoch: 109] Training\n",
            ">>>> [Epoch: 109] Avg. loss: 0.1470 | Mean IoU: 0.7833\n",
            ">>>> [Epoch: 109] Validation\n",
            ">>>> [Epoch: 109] Avg. loss: 0.5747 | Mean IoU: 0.6411\n",
            ">>>> [Epoch: 110] Training\n",
            ">>>> [Epoch: 110] Avg. loss: 0.1554 | Mean IoU: 0.7825\n",
            ">>>> [Epoch: 111] Training\n",
            ">>>> [Epoch: 111] Avg. loss: 0.1489 | Mean IoU: 0.7773\n",
            ">>>> [Epoch: 112] Training\n",
            ">>>> [Epoch: 112] Avg. loss: 0.1449 | Mean IoU: 0.7833\n",
            ">>>> [Epoch: 113] Training\n",
            ">>>> [Epoch: 113] Avg. loss: 0.1491 | Mean IoU: 0.7839\n",
            ">>>> [Epoch: 114] Training\n",
            ">>>> [Epoch: 114] Avg. loss: 0.1556 | Mean IoU: 0.7843\n",
            ">>>> [Epoch: 115] Training\n",
            ">>>> [Epoch: 115] Avg. loss: 0.1521 | Mean IoU: 0.7870\n",
            ">>>> [Epoch: 116] Training\n",
            ">>>> [Epoch: 116] Avg. loss: 0.1426 | Mean IoU: 0.7842\n",
            ">>>> [Epoch: 117] Training\n",
            ">>>> [Epoch: 117] Avg. loss: 0.1607 | Mean IoU: 0.7844\n",
            ">>>> [Epoch: 118] Training\n",
            ">>>> [Epoch: 118] Avg. loss: 0.1651 | Mean IoU: 0.7904\n",
            ">>>> [Epoch: 119] Training\n",
            ">>>> [Epoch: 119] Avg. loss: 0.1494 | Mean IoU: 0.7875\n",
            ">>>> [Epoch: 119] Validation\n",
            ">>>> [Epoch: 119] Avg. loss: 0.5468 | Mean IoU: 0.6531\n",
            "sky: 0.9391\n",
            "building: 0.8688\n",
            "pole: 0.0437\n",
            "road: 0.9535\n",
            "pavement: 0.8273\n",
            "tree: 0.8875\n",
            "sign_symbol: 0.4169\n",
            "fence: 0.5674\n",
            "car: 0.8189\n",
            "pedestrian: 0.3487\n",
            "bicyclist: 0.5127\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 120] Training\n",
            ">>>> [Epoch: 120] Avg. loss: 0.1481 | Mean IoU: 0.7819\n",
            ">>>> [Epoch: 121] Training\n",
            ">>>> [Epoch: 121] Avg. loss: 0.1416 | Mean IoU: 0.7891\n",
            ">>>> [Epoch: 122] Training\n",
            ">>>> [Epoch: 122] Avg. loss: 0.1564 | Mean IoU: 0.7893\n",
            ">>>> [Epoch: 123] Training\n",
            ">>>> [Epoch: 123] Avg. loss: 0.1525 | Mean IoU: 0.7890\n",
            ">>>> [Epoch: 124] Training\n",
            ">>>> [Epoch: 124] Avg. loss: 0.1526 | Mean IoU: 0.7912\n",
            ">>>> [Epoch: 125] Training\n",
            ">>>> [Epoch: 125] Avg. loss: 0.1468 | Mean IoU: 0.7894\n",
            ">>>> [Epoch: 126] Training\n",
            ">>>> [Epoch: 126] Avg. loss: 0.1617 | Mean IoU: 0.7923\n",
            ">>>> [Epoch: 127] Training\n",
            ">>>> [Epoch: 127] Avg. loss: 0.1576 | Mean IoU: 0.7913\n",
            ">>>> [Epoch: 128] Training\n",
            ">>>> [Epoch: 128] Avg. loss: 0.1523 | Mean IoU: 0.7897\n",
            ">>>> [Epoch: 129] Training\n",
            ">>>> [Epoch: 129] Avg. loss: 0.1496 | Mean IoU: 0.7922\n",
            ">>>> [Epoch: 129] Validation\n",
            ">>>> [Epoch: 129] Avg. loss: 0.5386 | Mean IoU: 0.6541\n",
            "sky: 0.9380\n",
            "building: 0.8644\n",
            "pole: 0.0439\n",
            "road: 0.9531\n",
            "pavement: 0.8322\n",
            "tree: 0.8748\n",
            "sign_symbol: 0.4305\n",
            "fence: 0.5561\n",
            "car: 0.7914\n",
            "pedestrian: 0.3676\n",
            "bicyclist: 0.5430\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 130] Training\n",
            ">>>> [Epoch: 130] Avg. loss: 0.1542 | Mean IoU: 0.7921\n",
            ">>>> [Epoch: 131] Training\n",
            ">>>> [Epoch: 131] Avg. loss: 0.1452 | Mean IoU: 0.7927\n",
            ">>>> [Epoch: 132] Training\n",
            ">>>> [Epoch: 132] Avg. loss: 0.1501 | Mean IoU: 0.7934\n",
            ">>>> [Epoch: 133] Training\n",
            ">>>> [Epoch: 133] Avg. loss: 0.1521 | Mean IoU: 0.7944\n",
            ">>>> [Epoch: 134] Training\n",
            ">>>> [Epoch: 134] Avg. loss: 0.1524 | Mean IoU: 0.7919\n",
            ">>>> [Epoch: 135] Training\n",
            ">>>> [Epoch: 135] Avg. loss: 0.1459 | Mean IoU: 0.7948\n",
            ">>>> [Epoch: 136] Training\n",
            ">>>> [Epoch: 136] Avg. loss: 0.1587 | Mean IoU: 0.7943\n",
            ">>>> [Epoch: 137] Training\n",
            ">>>> [Epoch: 137] Avg. loss: 0.1527 | Mean IoU: 0.7968\n",
            ">>>> [Epoch: 138] Training\n",
            ">>>> [Epoch: 138] Avg. loss: 0.1516 | Mean IoU: 0.7951\n",
            ">>>> [Epoch: 139] Training\n",
            ">>>> [Epoch: 139] Avg. loss: 0.1398 | Mean IoU: 0.7939\n",
            ">>>> [Epoch: 139] Validation\n",
            ">>>> [Epoch: 139] Avg. loss: 0.5832 | Mean IoU: 0.6504\n",
            ">>>> [Epoch: 140] Training\n",
            ">>>> [Epoch: 140] Avg. loss: 0.1565 | Mean IoU: 0.7951\n",
            ">>>> [Epoch: 141] Training\n",
            ">>>> [Epoch: 141] Avg. loss: 0.1612 | Mean IoU: 0.7975\n",
            ">>>> [Epoch: 142] Training\n",
            ">>>> [Epoch: 142] Avg. loss: 0.1579 | Mean IoU: 0.7990\n",
            ">>>> [Epoch: 143] Training\n",
            ">>>> [Epoch: 143] Avg. loss: 0.1385 | Mean IoU: 0.7996\n",
            ">>>> [Epoch: 144] Training\n",
            ">>>> [Epoch: 144] Avg. loss: 0.1480 | Mean IoU: 0.8005\n",
            ">>>> [Epoch: 145] Training\n",
            ">>>> [Epoch: 145] Avg. loss: 0.1463 | Mean IoU: 0.8005\n",
            ">>>> [Epoch: 146] Training\n",
            ">>>> [Epoch: 146] Avg. loss: 0.1458 | Mean IoU: 0.7931\n",
            ">>>> [Epoch: 147] Training\n",
            ">>>> [Epoch: 147] Avg. loss: 0.1540 | Mean IoU: 0.8001\n",
            ">>>> [Epoch: 148] Training\n",
            ">>>> [Epoch: 148] Avg. loss: 0.1505 | Mean IoU: 0.7983\n",
            ">>>> [Epoch: 149] Training\n",
            ">>>> [Epoch: 149] Avg. loss: 0.1462 | Mean IoU: 0.8004\n",
            ">>>> [Epoch: 149] Validation\n",
            ">>>> [Epoch: 149] Avg. loss: 0.5694 | Mean IoU: 0.6565\n",
            "sky: 0.9393\n",
            "building: 0.8693\n",
            "pole: 0.0298\n",
            "road: 0.9594\n",
            "pavement: 0.8451\n",
            "tree: 0.8853\n",
            "sign_symbol: 0.4085\n",
            "fence: 0.5835\n",
            "car: 0.8244\n",
            "pedestrian: 0.3687\n",
            "bicyclist: 0.5086\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 150] Training\n",
            ">>>> [Epoch: 150] Avg. loss: 0.1492 | Mean IoU: 0.8021\n",
            ">>>> [Epoch: 151] Training\n",
            ">>>> [Epoch: 151] Avg. loss: 0.1535 | Mean IoU: 0.8024\n",
            ">>>> [Epoch: 152] Training\n",
            ">>>> [Epoch: 152] Avg. loss: 0.1471 | Mean IoU: 0.7987\n",
            ">>>> [Epoch: 153] Training\n",
            ">>>> [Epoch: 153] Avg. loss: 0.1490 | Mean IoU: 0.8005\n",
            ">>>> [Epoch: 154] Training\n",
            ">>>> [Epoch: 154] Avg. loss: 0.1436 | Mean IoU: 0.8050\n",
            ">>>> [Epoch: 155] Training\n",
            ">>>> [Epoch: 155] Avg. loss: 0.1495 | Mean IoU: 0.8020\n",
            ">>>> [Epoch: 156] Training\n",
            ">>>> [Epoch: 156] Avg. loss: 0.1520 | Mean IoU: 0.8036\n",
            ">>>> [Epoch: 157] Training\n",
            ">>>> [Epoch: 157] Avg. loss: 0.1427 | Mean IoU: 0.8047\n",
            ">>>> [Epoch: 158] Training\n",
            ">>>> [Epoch: 158] Avg. loss: 0.1469 | Mean IoU: 0.8038\n",
            ">>>> [Epoch: 159] Training\n",
            ">>>> [Epoch: 159] Avg. loss: 0.1568 | Mean IoU: 0.8018\n",
            ">>>> [Epoch: 159] Validation\n",
            ">>>> [Epoch: 159] Avg. loss: 0.5781 | Mean IoU: 0.6560\n",
            ">>>> [Epoch: 160] Training\n",
            ">>>> [Epoch: 160] Avg. loss: 0.1568 | Mean IoU: 0.8032\n",
            ">>>> [Epoch: 161] Training\n",
            ">>>> [Epoch: 161] Avg. loss: 0.1714 | Mean IoU: 0.8047\n",
            ">>>> [Epoch: 162] Training\n",
            ">>>> [Epoch: 162] Avg. loss: 0.1468 | Mean IoU: 0.8069\n",
            ">>>> [Epoch: 163] Training\n",
            ">>>> [Epoch: 163] Avg. loss: 0.1472 | Mean IoU: 0.8066\n",
            ">>>> [Epoch: 164] Training\n",
            ">>>> [Epoch: 164] Avg. loss: 0.1567 | Mean IoU: 0.8006\n",
            ">>>> [Epoch: 165] Training\n",
            ">>>> [Epoch: 165] Avg. loss: 0.1528 | Mean IoU: 0.8075\n",
            ">>>> [Epoch: 166] Training\n",
            ">>>> [Epoch: 166] Avg. loss: 0.1580 | Mean IoU: 0.8068\n",
            ">>>> [Epoch: 167] Training\n",
            ">>>> [Epoch: 167] Avg. loss: 0.1474 | Mean IoU: 0.8077\n",
            ">>>> [Epoch: 168] Training\n",
            ">>>> [Epoch: 168] Avg. loss: 0.1500 | Mean IoU: 0.8094\n",
            ">>>> [Epoch: 169] Training\n",
            ">>>> [Epoch: 169] Avg. loss: 0.1573 | Mean IoU: 0.8091\n",
            ">>>> [Epoch: 169] Validation\n",
            ">>>> [Epoch: 169] Avg. loss: 0.5591 | Mean IoU: 0.6514\n",
            ">>>> [Epoch: 170] Training\n",
            ">>>> [Epoch: 170] Avg. loss: 0.1472 | Mean IoU: 0.8102\n",
            ">>>> [Epoch: 171] Training\n",
            ">>>> [Epoch: 171] Avg. loss: 0.1579 | Mean IoU: 0.8076\n",
            ">>>> [Epoch: 172] Training\n",
            ">>>> [Epoch: 172] Avg. loss: 0.1476 | Mean IoU: 0.8074\n",
            ">>>> [Epoch: 173] Training\n",
            ">>>> [Epoch: 173] Avg. loss: 0.1464 | Mean IoU: 0.8083\n",
            ">>>> [Epoch: 174] Training\n",
            ">>>> [Epoch: 174] Avg. loss: 0.1441 | Mean IoU: 0.8086\n",
            ">>>> [Epoch: 175] Training\n",
            ">>>> [Epoch: 175] Avg. loss: 0.1468 | Mean IoU: 0.8110\n",
            ">>>> [Epoch: 176] Training\n",
            ">>>> [Epoch: 176] Avg. loss: 0.1457 | Mean IoU: 0.8081\n",
            ">>>> [Epoch: 177] Training\n",
            ">>>> [Epoch: 177] Avg. loss: 0.1506 | Mean IoU: 0.8119\n",
            ">>>> [Epoch: 178] Training\n",
            ">>>> [Epoch: 178] Avg. loss: 0.1454 | Mean IoU: 0.8098\n",
            ">>>> [Epoch: 179] Training\n",
            ">>>> [Epoch: 179] Avg. loss: 0.1398 | Mean IoU: 0.8085\n",
            ">>>> [Epoch: 179] Validation\n",
            ">>>> [Epoch: 179] Avg. loss: 0.5596 | Mean IoU: 0.6589\n",
            "sky: 0.9377\n",
            "building: 0.8737\n",
            "pole: 0.0494\n",
            "road: 0.9585\n",
            "pavement: 0.8440\n",
            "tree: 0.8869\n",
            "sign_symbol: 0.4162\n",
            "fence: 0.5805\n",
            "car: 0.8169\n",
            "pedestrian: 0.3649\n",
            "bicyclist: 0.5186\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 180] Training\n",
            ">>>> [Epoch: 180] Avg. loss: 0.1460 | Mean IoU: 0.8112\n",
            ">>>> [Epoch: 181] Training\n",
            ">>>> [Epoch: 181] Avg. loss: 0.1443 | Mean IoU: 0.8124\n",
            ">>>> [Epoch: 182] Training\n",
            ">>>> [Epoch: 182] Avg. loss: 0.1522 | Mean IoU: 0.8077\n",
            ">>>> [Epoch: 183] Training\n",
            ">>>> [Epoch: 183] Avg. loss: 0.1474 | Mean IoU: 0.8120\n",
            ">>>> [Epoch: 184] Training\n",
            ">>>> [Epoch: 184] Avg. loss: 0.1475 | Mean IoU: 0.8125\n",
            ">>>> [Epoch: 185] Training\n",
            ">>>> [Epoch: 185] Avg. loss: 0.1619 | Mean IoU: 0.8082\n",
            ">>>> [Epoch: 186] Training\n",
            ">>>> [Epoch: 186] Avg. loss: 0.1676 | Mean IoU: 0.8121\n",
            ">>>> [Epoch: 187] Training\n",
            ">>>> [Epoch: 187] Avg. loss: 0.1546 | Mean IoU: 0.8115\n",
            ">>>> [Epoch: 188] Training\n",
            ">>>> [Epoch: 188] Avg. loss: 0.1431 | Mean IoU: 0.8124\n",
            ">>>> [Epoch: 189] Training\n",
            ">>>> [Epoch: 189] Avg. loss: 0.1496 | Mean IoU: 0.8148\n",
            ">>>> [Epoch: 189] Validation\n",
            ">>>> [Epoch: 189] Avg. loss: 0.5546 | Mean IoU: 0.6566\n",
            ">>>> [Epoch: 190] Training\n",
            ">>>> [Epoch: 190] Avg. loss: 0.1472 | Mean IoU: 0.8157\n",
            ">>>> [Epoch: 191] Training\n",
            ">>>> [Epoch: 191] Avg. loss: 0.1464 | Mean IoU: 0.8133\n",
            ">>>> [Epoch: 192] Training\n",
            ">>>> [Epoch: 192] Avg. loss: 0.1405 | Mean IoU: 0.8129\n",
            ">>>> [Epoch: 193] Training\n",
            ">>>> [Epoch: 193] Avg. loss: 0.1410 | Mean IoU: 0.8110\n",
            ">>>> [Epoch: 194] Training\n",
            ">>>> [Epoch: 194] Avg. loss: 0.1474 | Mean IoU: 0.8144\n",
            ">>>> [Epoch: 195] Training\n",
            ">>>> [Epoch: 195] Avg. loss: 0.1537 | Mean IoU: 0.8148\n",
            ">>>> [Epoch: 196] Training\n",
            ">>>> [Epoch: 196] Avg. loss: 0.1504 | Mean IoU: 0.8161\n",
            ">>>> [Epoch: 197] Training\n",
            ">>>> [Epoch: 197] Avg. loss: 0.1527 | Mean IoU: 0.8163\n",
            ">>>> [Epoch: 198] Training\n",
            ">>>> [Epoch: 198] Avg. loss: 0.1488 | Mean IoU: 0.8141\n",
            ">>>> [Epoch: 199] Training\n",
            ">>>> [Epoch: 199] Avg. loss: 0.1540 | Mean IoU: 0.8154\n",
            ">>>> [Epoch: 199] Validation\n",
            ">>>> [Epoch: 199] Avg. loss: 0.5500 | Mean IoU: 0.6648\n",
            "sky: 0.9384\n",
            "building: 0.8760\n",
            "pole: 0.0485\n",
            "road: 0.9599\n",
            "pavement: 0.8525\n",
            "tree: 0.8941\n",
            "sign_symbol: 0.4446\n",
            "fence: 0.6171\n",
            "car: 0.7863\n",
            "pedestrian: 0.3735\n",
            "bicyclist: 0.5224\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 200] Training\n",
            ">>>> [Epoch: 200] Avg. loss: 0.1415 | Mean IoU: 0.8157\n",
            ">>>> [Epoch: 201] Training\n",
            ">>>> [Epoch: 201] Avg. loss: 0.1459 | Mean IoU: 0.8152\n",
            ">>>> [Epoch: 202] Training\n",
            ">>>> [Epoch: 202] Avg. loss: 0.1400 | Mean IoU: 0.8183\n",
            ">>>> [Epoch: 203] Training\n",
            ">>>> [Epoch: 203] Avg. loss: 0.1449 | Mean IoU: 0.8180\n",
            ">>>> [Epoch: 204] Training\n",
            ">>>> [Epoch: 204] Avg. loss: 0.1455 | Mean IoU: 0.8178\n",
            ">>>> [Epoch: 205] Training\n",
            ">>>> [Epoch: 205] Avg. loss: 0.1504 | Mean IoU: 0.8181\n",
            ">>>> [Epoch: 206] Training\n",
            ">>>> [Epoch: 206] Avg. loss: 0.1378 | Mean IoU: 0.8180\n",
            ">>>> [Epoch: 207] Training\n",
            ">>>> [Epoch: 207] Avg. loss: 0.1360 | Mean IoU: 0.8171\n",
            ">>>> [Epoch: 208] Training\n",
            ">>>> [Epoch: 208] Avg. loss: 0.1471 | Mean IoU: 0.8174\n",
            ">>>> [Epoch: 209] Training\n",
            ">>>> [Epoch: 209] Avg. loss: 0.1508 | Mean IoU: 0.8206\n",
            ">>>> [Epoch: 209] Validation\n",
            ">>>> [Epoch: 209] Avg. loss: 0.5560 | Mean IoU: 0.6568\n",
            ">>>> [Epoch: 210] Training\n",
            ">>>> [Epoch: 210] Avg. loss: 0.1428 | Mean IoU: 0.8207\n",
            ">>>> [Epoch: 211] Training\n",
            ">>>> [Epoch: 211] Avg. loss: 0.1523 | Mean IoU: 0.8180\n",
            ">>>> [Epoch: 212] Training\n",
            ">>>> [Epoch: 212] Avg. loss: 0.1603 | Mean IoU: 0.8186\n",
            ">>>> [Epoch: 213] Training\n",
            ">>>> [Epoch: 213] Avg. loss: 0.1403 | Mean IoU: 0.8171\n",
            ">>>> [Epoch: 214] Training\n",
            ">>>> [Epoch: 214] Avg. loss: 0.1448 | Mean IoU: 0.8216\n",
            ">>>> [Epoch: 215] Training\n",
            ">>>> [Epoch: 215] Avg. loss: 0.1420 | Mean IoU: 0.8185\n",
            ">>>> [Epoch: 216] Training\n",
            ">>>> [Epoch: 216] Avg. loss: 0.1501 | Mean IoU: 0.8173\n",
            ">>>> [Epoch: 217] Training\n",
            ">>>> [Epoch: 217] Avg. loss: 0.1387 | Mean IoU: 0.8208\n",
            ">>>> [Epoch: 218] Training\n",
            ">>>> [Epoch: 218] Avg. loss: 0.1412 | Mean IoU: 0.8222\n",
            ">>>> [Epoch: 219] Training\n",
            ">>>> [Epoch: 219] Avg. loss: 0.1435 | Mean IoU: 0.8219\n",
            ">>>> [Epoch: 219] Validation\n",
            ">>>> [Epoch: 219] Avg. loss: 0.5225 | Mean IoU: 0.6631\n",
            ">>>> [Epoch: 220] Training\n",
            ">>>> [Epoch: 220] Avg. loss: 0.1574 | Mean IoU: 0.8190\n",
            ">>>> [Epoch: 221] Training\n",
            ">>>> [Epoch: 221] Avg. loss: 0.1381 | Mean IoU: 0.8225\n",
            ">>>> [Epoch: 222] Training\n",
            ">>>> [Epoch: 222] Avg. loss: 0.1436 | Mean IoU: 0.8196\n",
            ">>>> [Epoch: 223] Training\n",
            ">>>> [Epoch: 223] Avg. loss: 0.1368 | Mean IoU: 0.8222\n",
            ">>>> [Epoch: 224] Training\n",
            ">>>> [Epoch: 224] Avg. loss: 0.1387 | Mean IoU: 0.8210\n",
            ">>>> [Epoch: 225] Training\n",
            ">>>> [Epoch: 225] Avg. loss: 0.1486 | Mean IoU: 0.8209\n",
            ">>>> [Epoch: 226] Training\n",
            ">>>> [Epoch: 226] Avg. loss: 0.1428 | Mean IoU: 0.8216\n",
            ">>>> [Epoch: 227] Training\n",
            ">>>> [Epoch: 227] Avg. loss: 0.1430 | Mean IoU: 0.8232\n",
            ">>>> [Epoch: 228] Training\n",
            ">>>> [Epoch: 228] Avg. loss: 0.1503 | Mean IoU: 0.8225\n",
            ">>>> [Epoch: 229] Training\n",
            ">>>> [Epoch: 229] Avg. loss: 0.1497 | Mean IoU: 0.8206\n",
            ">>>> [Epoch: 229] Validation\n",
            ">>>> [Epoch: 229] Avg. loss: 0.5658 | Mean IoU: 0.6503\n",
            ">>>> [Epoch: 230] Training\n",
            ">>>> [Epoch: 230] Avg. loss: 0.1441 | Mean IoU: 0.8217\n",
            ">>>> [Epoch: 231] Training\n",
            ">>>> [Epoch: 231] Avg. loss: 0.1433 | Mean IoU: 0.8212\n",
            ">>>> [Epoch: 232] Training\n",
            ">>>> [Epoch: 232] Avg. loss: 0.1373 | Mean IoU: 0.8216\n",
            ">>>> [Epoch: 233] Training\n",
            ">>>> [Epoch: 233] Avg. loss: 0.1398 | Mean IoU: 0.8253\n",
            ">>>> [Epoch: 234] Training\n",
            ">>>> [Epoch: 234] Avg. loss: 0.1417 | Mean IoU: 0.8226\n",
            ">>>> [Epoch: 235] Training\n",
            ">>>> [Epoch: 235] Avg. loss: 0.1472 | Mean IoU: 0.8252\n",
            ">>>> [Epoch: 236] Training\n",
            ">>>> [Epoch: 236] Avg. loss: 0.1548 | Mean IoU: 0.8230\n",
            ">>>> [Epoch: 237] Training\n",
            ">>>> [Epoch: 237] Avg. loss: 0.1361 | Mean IoU: 0.8223\n",
            ">>>> [Epoch: 238] Training\n",
            ">>>> [Epoch: 238] Avg. loss: 0.1493 | Mean IoU: 0.8252\n",
            ">>>> [Epoch: 239] Training\n",
            ">>>> [Epoch: 239] Avg. loss: 0.1589 | Mean IoU: 0.8251\n",
            ">>>> [Epoch: 239] Validation\n",
            ">>>> [Epoch: 239] Avg. loss: 0.5266 | Mean IoU: 0.6643\n",
            ">>>> [Epoch: 240] Training\n",
            ">>>> [Epoch: 240] Avg. loss: 0.1409 | Mean IoU: 0.8247\n",
            ">>>> [Epoch: 241] Training\n",
            ">>>> [Epoch: 241] Avg. loss: 0.1407 | Mean IoU: 0.8246\n",
            ">>>> [Epoch: 242] Training\n",
            ">>>> [Epoch: 242] Avg. loss: 0.1331 | Mean IoU: 0.8263\n",
            ">>>> [Epoch: 243] Training\n",
            ">>>> [Epoch: 243] Avg. loss: 0.1548 | Mean IoU: 0.8253\n",
            ">>>> [Epoch: 244] Training\n",
            ">>>> [Epoch: 244] Avg. loss: 0.1459 | Mean IoU: 0.8263\n",
            ">>>> [Epoch: 245] Training\n",
            ">>>> [Epoch: 245] Avg. loss: 0.1423 | Mean IoU: 0.8257\n",
            ">>>> [Epoch: 246] Training\n",
            ">>>> [Epoch: 246] Avg. loss: 0.1408 | Mean IoU: 0.8266\n",
            ">>>> [Epoch: 247] Training\n",
            ">>>> [Epoch: 247] Avg. loss: 0.1416 | Mean IoU: 0.8232\n",
            ">>>> [Epoch: 248] Training\n",
            ">>>> [Epoch: 248] Avg. loss: 0.1528 | Mean IoU: 0.8257\n",
            ">>>> [Epoch: 249] Training\n",
            ">>>> [Epoch: 249] Avg. loss: 0.1464 | Mean IoU: 0.8267\n",
            ">>>> [Epoch: 249] Validation\n",
            ">>>> [Epoch: 249] Avg. loss: 0.5497 | Mean IoU: 0.6614\n",
            ">>>> [Epoch: 250] Training\n",
            ">>>> [Epoch: 250] Avg. loss: 0.1462 | Mean IoU: 0.8280\n",
            ">>>> [Epoch: 251] Training\n",
            ">>>> [Epoch: 251] Avg. loss: 0.1518 | Mean IoU: 0.8277\n",
            ">>>> [Epoch: 252] Training\n",
            ">>>> [Epoch: 252] Avg. loss: 0.1420 | Mean IoU: 0.8254\n",
            ">>>> [Epoch: 253] Training\n",
            ">>>> [Epoch: 253] Avg. loss: 0.1486 | Mean IoU: 0.8273\n",
            ">>>> [Epoch: 254] Training\n",
            ">>>> [Epoch: 254] Avg. loss: 0.1363 | Mean IoU: 0.8271\n",
            ">>>> [Epoch: 255] Training\n",
            ">>>> [Epoch: 255] Avg. loss: 0.1370 | Mean IoU: 0.8241\n",
            ">>>> [Epoch: 256] Training\n",
            ">>>> [Epoch: 256] Avg. loss: 0.1502 | Mean IoU: 0.8276\n",
            ">>>> [Epoch: 257] Training\n",
            ">>>> [Epoch: 257] Avg. loss: 0.1447 | Mean IoU: 0.8271\n",
            ">>>> [Epoch: 258] Training\n",
            ">>>> [Epoch: 258] Avg. loss: 0.1409 | Mean IoU: 0.8300\n",
            ">>>> [Epoch: 259] Training\n",
            ">>>> [Epoch: 259] Avg. loss: 0.1446 | Mean IoU: 0.8301\n",
            ">>>> [Epoch: 259] Validation\n",
            ">>>> [Epoch: 259] Avg. loss: 0.5328 | Mean IoU: 0.6619\n",
            ">>>> [Epoch: 260] Training\n",
            ">>>> [Epoch: 260] Avg. loss: 0.1433 | Mean IoU: 0.8287\n",
            ">>>> [Epoch: 261] Training\n",
            ">>>> [Epoch: 261] Avg. loss: 0.1528 | Mean IoU: 0.8282\n",
            ">>>> [Epoch: 262] Training\n",
            ">>>> [Epoch: 262] Avg. loss: 0.1466 | Mean IoU: 0.8292\n",
            ">>>> [Epoch: 263] Training\n",
            ">>>> [Epoch: 263] Avg. loss: 0.1489 | Mean IoU: 0.8294\n",
            ">>>> [Epoch: 264] Training\n",
            ">>>> [Epoch: 264] Avg. loss: 0.1409 | Mean IoU: 0.8273\n",
            ">>>> [Epoch: 265] Training\n",
            ">>>> [Epoch: 265] Avg. loss: 0.1446 | Mean IoU: 0.8286\n",
            ">>>> [Epoch: 266] Training\n",
            ">>>> [Epoch: 266] Avg. loss: 0.1345 | Mean IoU: 0.8308\n",
            ">>>> [Epoch: 267] Training\n",
            ">>>> [Epoch: 267] Avg. loss: 0.1480 | Mean IoU: 0.8274\n",
            ">>>> [Epoch: 268] Training\n",
            ">>>> [Epoch: 268] Avg. loss: 0.1478 | Mean IoU: 0.8288\n",
            ">>>> [Epoch: 269] Training\n",
            ">>>> [Epoch: 269] Avg. loss: 0.1395 | Mean IoU: 0.8309\n",
            ">>>> [Epoch: 269] Validation\n",
            ">>>> [Epoch: 269] Avg. loss: 0.5287 | Mean IoU: 0.6637\n",
            ">>>> [Epoch: 270] Training\n",
            ">>>> [Epoch: 270] Avg. loss: 0.1448 | Mean IoU: 0.8264\n",
            ">>>> [Epoch: 271] Training\n",
            ">>>> [Epoch: 271] Avg. loss: 0.1554 | Mean IoU: 0.8285\n",
            ">>>> [Epoch: 272] Training\n",
            ">>>> [Epoch: 272] Avg. loss: 0.1382 | Mean IoU: 0.8307\n",
            ">>>> [Epoch: 273] Training\n",
            ">>>> [Epoch: 273] Avg. loss: 0.1450 | Mean IoU: 0.8302\n",
            ">>>> [Epoch: 274] Training\n",
            ">>>> [Epoch: 274] Avg. loss: 0.1380 | Mean IoU: 0.8312\n",
            ">>>> [Epoch: 275] Training\n",
            ">>>> [Epoch: 275] Avg. loss: 0.1442 | Mean IoU: 0.8292\n",
            ">>>> [Epoch: 276] Training\n",
            ">>>> [Epoch: 276] Avg. loss: 0.1471 | Mean IoU: 0.8304\n",
            ">>>> [Epoch: 277] Training\n",
            ">>>> [Epoch: 277] Avg. loss: 0.1398 | Mean IoU: 0.8326\n",
            ">>>> [Epoch: 278] Training\n",
            ">>>> [Epoch: 278] Avg. loss: 0.1455 | Mean IoU: 0.8320\n",
            ">>>> [Epoch: 279] Training\n",
            ">>>> [Epoch: 279] Avg. loss: 0.1369 | Mean IoU: 0.8318\n",
            ">>>> [Epoch: 279] Validation\n",
            ">>>> [Epoch: 279] Avg. loss: 0.5663 | Mean IoU: 0.6488\n",
            ">>>> [Epoch: 280] Training\n",
            ">>>> [Epoch: 280] Avg. loss: 0.1420 | Mean IoU: 0.8332\n",
            ">>>> [Epoch: 281] Training\n",
            ">>>> [Epoch: 281] Avg. loss: 0.1370 | Mean IoU: 0.8332\n",
            ">>>> [Epoch: 282] Training\n",
            ">>>> [Epoch: 282] Avg. loss: 0.1421 | Mean IoU: 0.8318\n",
            ">>>> [Epoch: 283] Training\n",
            ">>>> [Epoch: 283] Avg. loss: 0.1452 | Mean IoU: 0.8335\n",
            ">>>> [Epoch: 284] Training\n",
            ">>>> [Epoch: 284] Avg. loss: 0.1401 | Mean IoU: 0.8336\n",
            ">>>> [Epoch: 285] Training\n",
            ">>>> [Epoch: 285] Avg. loss: 0.1523 | Mean IoU: 0.8289\n",
            ">>>> [Epoch: 286] Training\n",
            ">>>> [Epoch: 286] Avg. loss: 0.1429 | Mean IoU: 0.8300\n",
            ">>>> [Epoch: 287] Training\n",
            ">>>> [Epoch: 287] Avg. loss: 0.1459 | Mean IoU: 0.8334\n",
            ">>>> [Epoch: 288] Training\n",
            ">>>> [Epoch: 288] Avg. loss: 0.1487 | Mean IoU: 0.8323\n",
            ">>>> [Epoch: 289] Training\n",
            ">>>> [Epoch: 289] Avg. loss: 0.1455 | Mean IoU: 0.8341\n",
            ">>>> [Epoch: 289] Validation\n",
            ">>>> [Epoch: 289] Avg. loss: 0.5257 | Mean IoU: 0.6639\n",
            ">>>> [Epoch: 290] Training\n",
            ">>>> [Epoch: 290] Avg. loss: 0.1481 | Mean IoU: 0.8337\n",
            ">>>> [Epoch: 291] Training\n",
            ">>>> [Epoch: 291] Avg. loss: 0.1444 | Mean IoU: 0.8347\n",
            ">>>> [Epoch: 292] Training\n",
            ">>>> [Epoch: 292] Avg. loss: 0.1362 | Mean IoU: 0.8326\n",
            ">>>> [Epoch: 293] Training\n",
            ">>>> [Epoch: 293] Avg. loss: 0.1405 | Mean IoU: 0.8351\n",
            ">>>> [Epoch: 294] Training\n",
            ">>>> [Epoch: 294] Avg. loss: 0.1551 | Mean IoU: 0.8333\n",
            ">>>> [Epoch: 295] Training\n",
            ">>>> [Epoch: 295] Avg. loss: 0.1419 | Mean IoU: 0.8365\n",
            ">>>> [Epoch: 296] Training\n",
            ">>>> [Epoch: 296] Avg. loss: 0.1376 | Mean IoU: 0.8332\n",
            ">>>> [Epoch: 297] Training\n",
            ">>>> [Epoch: 297] Avg. loss: 0.1478 | Mean IoU: 0.8345\n",
            ">>>> [Epoch: 298] Training\n",
            ">>>> [Epoch: 298] Avg. loss: 0.1437 | Mean IoU: 0.8348\n",
            ">>>> [Epoch: 299] Training\n",
            ">>>> [Epoch: 299] Avg. loss: 0.1365 | Mean IoU: 0.8333\n",
            ">>>> [Epoch: 299] Validation\n",
            ">>>> [Epoch: 299] Avg. loss: 0.5595 | Mean IoU: 0.6641\n",
            "sky: 0.9376\n",
            "building: 0.8806\n",
            "pole: 0.0597\n",
            "road: 0.9602\n",
            "pavement: 0.8577\n",
            "tree: 0.8893\n",
            "sign_symbol: 0.4501\n",
            "fence: 0.5861\n",
            "car: 0.7623\n",
            "pedestrian: 0.3773\n",
            "bicyclist: 0.5444\n",
            "unlabeled: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -m test --save-dir save/ --dataset camvid --dataset-dir CamVid2/ --name BiSeNet2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwkhbYf3V-dM",
        "outputId": "21c1adac-868c-4198-d355-f6a9a7c5bc62"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: CamVid2/\n",
            "Save directory: save/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 640, 480])\n",
            "Label size: torch.Size([10, 640, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0252,  3.4468, 15.9117,  9.0204, 32.0129, 32.4791,\n",
            "        13.2076, 38.3884, 44.1342,  0.0000], device='cuda:0')\n",
            "################################save/BiSeNet2#####################\n",
            "BiSeNetV2(\n",
            "  (detail): DetailBranch(\n",
            "    (S1): Sequential(\n",
            "      (0): ConvBNReLU(\n",
            "        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): ConvBNReLU(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S2): Sequential(\n",
            "      (0): ConvBNReLU(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): ConvBNReLU(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): ConvBNReLU(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S3): Sequential(\n",
            "      (0): ConvBNReLU(\n",
            "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): ConvBNReLU(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): ConvBNReLU(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (segment): SegmentBranch(\n",
            "    (S1S2): StemBlock(\n",
            "      (conv): ConvBNReLU(\n",
            "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (left): Sequential(\n",
            "        (0): ConvBNReLU(\n",
            "          (conv): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvBNReLU(\n",
            "          (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (right): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (fuse): ConvBNReLU(\n",
            "        (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S3): Sequential(\n",
            "      (0): GELayerS2(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv1): Sequential(\n",
            "          (0): Conv2d(16, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (dwconv2): Sequential(\n",
            "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
            "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): GELayerS1(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv): Sequential(\n",
            "          (0): Conv2d(32, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S4): Sequential(\n",
            "      (0): GELayerS2(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv1): Sequential(\n",
            "          (0): Conv2d(32, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (dwconv2): Sequential(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): GELayerS1(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv): Sequential(\n",
            "          (0): Conv2d(64, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S5_4): Sequential(\n",
            "      (0): GELayerS2(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv1): Sequential(\n",
            "          (0): Conv2d(64, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (dwconv2): Sequential(\n",
            "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (shortcut): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): GELayerS1(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv): Sequential(\n",
            "          (0): Conv2d(128, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): GELayerS1(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv): Sequential(\n",
            "          (0): Conv2d(128, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): GELayerS1(\n",
            "        (conv1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (dwconv): Sequential(\n",
            "          (0): Conv2d(128, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (S5_5): CEBlock(\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv_gap): ConvBNReLU(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv_last): ConvBNReLU(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (bga): BGALayer(\n",
            "    (left1): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (left2): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "    )\n",
            "    (right1): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (right2): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (up1): Upsample(scale_factor=4.0, mode=nearest)\n",
            "    (up2): Upsample(scale_factor=4.0, mode=nearest)\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (head): SegmentHead(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(128, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (conv_out): Sequential(\n",
            "      (0): Identity()\n",
            "      (1): Conv2d(1024, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Upsample(scale_factor=8.0, mode=bilinear)\n",
            "    )\n",
            "  )\n",
            "  (aux2): SegmentHead(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (conv_out): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "        (1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Conv2d(16, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "    )\n",
            "  )\n",
            "  (aux3): SegmentHead(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (conv_out): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "        (1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Conv2d(64, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Upsample(scale_factor=4.0, mode=bilinear)\n",
            "    )\n",
            "  )\n",
            "  (aux4): SegmentHead(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (conv_out): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "        (1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Upsample(scale_factor=8.0, mode=bilinear)\n",
            "    )\n",
            "  )\n",
            "  (aux5_4): SegmentHead(\n",
            "    (conv): ConvBNReLU(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (conv_out): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
            "        (1): ConvBNReLU(\n",
            "          (conv): Conv2d(128, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Conv2d(1024, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Upsample(scale_factor=16.0, mode=bilinear)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "Testing...\n",
            "\n",
            ">>>> Running test dataset\n",
            ">>>> Avg. loss: 0.7698 | Mean IoU: 0.5734\n",
            "sky: 0.8989\n",
            "building: 0.8025\n",
            "pole: 0.1296\n",
            "road: 0.9151\n",
            "pavement: 0.7623\n",
            "tree: 0.7372\n",
            "sign_symbol: 0.3323\n",
            "fence: 0.2865\n",
            "car: 0.7671\n",
            "pedestrian: 0.3799\n",
            "bicyclist: 0.2958\n",
            "unlabeled: nan\n",
            "A batch of predictions from the test set...\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "<Figure size 1500x700 with 2 Axes>\n"
          ]
        }
      ]
    }
  ]
}